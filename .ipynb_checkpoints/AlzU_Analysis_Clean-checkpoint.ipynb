{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/travisallen/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime as DT\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import math\n",
    "from __future__ import division\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import nltk\n",
    "import re\n",
    "from collections import Counter\n",
    "import string\n",
    "import pprint\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import vaderSentiment.vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# vaderSentiment.vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. AlzU Survey Data Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ALZU_RESPONSES_FILE_PATH = '../Data_Folder/2018.09.18_AlzU_ANU-DRI + Responses_Numerical.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine first two rows to generate column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "two_header_rows = pd.read_csv(ALZU_RESPONSES_FILE_PATH, header=None, nrows = 2, delimiter = \",\", keep_default_na=False)\n",
    "\n",
    "transformed_header_row = []\n",
    "\n",
    "most_recent_col_first_row = None\n",
    "for column in two_header_rows:\n",
    "    primary_header = two_header_rows[column][0]\n",
    "    sub_header = two_header_rows[column][1]\n",
    "#     print(primary_header + \": \" + sub_header)\n",
    "    if(primary_header != \"\"):\n",
    "        most_recent_col_first_row = primary_header\n",
    "    transformed_header_row.append(most_recent_col_first_row + \"_\" + sub_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data with column names\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alzu_survey_data = pd.read_csv(ALZU_RESPONSES_FILE_PATH, header=None, skiprows = [0,1], delimiter = \",\", keep_default_na=False, names=transformed_header_row)\n",
    "\n",
    "# alzu_survey_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1458, 129)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alzu_survey_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Respondent ID_\n",
      "1 : Collector ID_\n",
      "2 : Start Date_\n",
      "3 : End Date_\n",
      "4 : IP Address_\n",
      "5 : Email Address_\n",
      "6 : First Name_\n",
      "7 : Last Name_\n",
      "8 : Custom Data 1_\n",
      "9 : How many lessons did you complete on AlzU.org?_Response\n",
      "10 : Please select the reasons why you have not yet completed the full 10 lesson course on AlzU.org. Select ALL that apply_Response\n",
      "11 : Please select the reasons why you have not yet completed the full 10 lesson course on AlzU.org. Select ALL that apply_Other (please specify)\n",
      "12 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Saw a doctor to discuss ways to lower AD risk?\n",
      "13 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Participated in an AD prevention research study other than this one?\n",
      "14 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Saw a doctor to be evaluated for memory loss?\n",
      "15 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Saw a doctor to discuss ways to prevent memory loss?\n",
      "16 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Saw a doctor to discuss an AD research study for a family member or friend?\n",
      "17 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Was screened for, or enrolled in, an AD prevention clinical trial?\n",
      "18 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Was screened for, or enrolled in, the Early Study AD prevention clinical trial?\n",
      "19 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Was screened for, or enrolled in, the Generation Study AD prevention clinical trial?\n",
      "20 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Joined the AD prevention registry endALZnow.org?\n",
      "21 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Joined the AD prevention registry BrainHealthRegistry.org?\n",
      "22 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Joined the Global Alzheimer's Platform \"TRC PAD\" AD prevention registry?\n",
      "23 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Made a dietary change to improve my brain health?\n",
      "24 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Increased exercise to improve my brain health?\n",
      "25 : What would you be willing to do or to undergo in order to learn about your risk for developing AD someday in the future?_Take tests of my thinking and memory.\n",
      "26 : What would you be willing to do or to undergo in order to learn about your risk for developing AD someday in the future?_Get a blood test.\n",
      "27 : What would you be willing to do or to undergo in order to learn about your risk for developing AD someday in the future?_Get a brain scan (picture of the brain, like an MRI or cat scan).\n",
      "28 : What would you be willing to do or to undergo in order to learn about your risk for developing AD someday in the future?_Get a genetic test to determine whether I have an Alzheimer’s risk gene.\n",
      "29 : Please rate how likely it is that you would participate in the following types of AD research studies:_Requires answering questions on a computer and taking tests of memory skills?\n",
      "30 : Please rate how likely it is that you would participate in the following types of AD research studies:_Randomly assigns half to receive a medicine and the other half to receive an inactive version?\n",
      "31 : Please rate how likely it is that you would participate in the following types of AD research studies:_Randomly assigns half to make a dietary and exercise change, and the other half to continue as usual?\n",
      "32 : Please rate how helpful or harmful each of the following would be._Seeing your doctor to discuss ways to lower AD risk\n",
      "33 : Please rate how helpful or harmful each of the following would be._Participate in an AD prevention research study\n",
      "34 : Please rate your level of agreement with the following questions._There is a strong possibility that I will develop AD\n",
      "35 : Please rate your level of agreement with the following questions._Changing my lifestyle and health habits can help me reduce my chance of developing AD\n",
      "36 : Please rate your level of agreement with the following questions._I have a lot to gain by changing my lifestyle and health behavior\n",
      "37 : Please rate your level of agreement with the following questions._I feel that my chances of developing AD in the future are high\n",
      "38 : Please rate your level of agreement with the following questions._I am too busy to change my lifestyle and health habits\n",
      "39 : Please rate your level of agreement with the following questions._Family responsibilities make it hard for me to change my lifestyle and behavior\n",
      "40 : Please rate your level of agreement with the following questions._When I think about AD my heart beats faster\n",
      "41 : Please rate your level of agreement with the following questions._When I think about AD I feel nauseous\n",
      "42 : Please rate your level of agreement with the following questions._The thought of AD scares me\n",
      "43 : Please rate your level of agreement with the following questions._Changing lifestyle and behavior interferes with my schedule\n",
      "44 : Please rate your level of agreement with the following questions._My chances of developing AD are great.\n",
      "45 : Please rate your level of agreement with the following questions._I am certain that I can change my lifestyle and behavior so I can reduce the risk of developing AD\n",
      "46 : How much do you weigh without your clothes and shoes in pounds?_Open-Ended Response\n",
      "47 : Have you ever been told by a doctor or other health professional that you have diabetes or have high sugar levels in your blood or urine?_Response\n",
      "48 : Have you ever been told by a doctor or other health professional that you have high cholesterol levels in the past 2 years or your cholesterol level is higher than 240mg/dL?_Response\n",
      "49 : If you recall your most recent cholesterol results, please enter here:_Total Cholesterol\n",
      "50 : If you recall your most recent cholesterol results, please enter here:_LDL (\"bad\" cholesterol)\n",
      "51 : If you recall your most recent cholesterol results, please enter here:_HDL (\"good\" cholesterol)\n",
      "52 : If you recall your most recent cholesterol results, please enter here:_Triglycerides\n",
      "53 : If you recall your most recent blood pressure, please enter here. This is recorded as a two numbers, e.g., 130/80. Please enter the larger number (called Systolic) first, and the smaller number (called Diastolic), second._Systolic Blood Pressure\n",
      "54 : If you recall your most recent blood pressure, please enter here. This is recorded as a two numbers, e.g., 130/80. Please enter the larger number (called Systolic) first, and the smaller number (called Diastolic), second._Diastolic Blood Pressure\n",
      "55 : Have you ever had a head injury where you lost consciousness for more than 15 minutes?_Response\n",
      "56 : Check best answer for each description._I was bothered by things that usually don’t bother me.\n",
      "57 : Check best answer for each description._I had trouble keeping my mind on what I was doing.\n",
      "58 : Check best answer for each description._I felt depressed.\n",
      "59 : Check best answer for each description._I felt that everything I did was an effort.\n",
      "60 : Check best answer for each description._I felt hopeful about the future.\n",
      "61 : Check best answer for each description._I felt fearful.\n",
      "62 : Check best answer for each description._My sleep was restless.\n",
      "63 : Check best answer for each description._I was happy.\n",
      "64 : Check best answer for each description._I felt lonely.\n",
      "65 : Check best answer for each description._I could not “get going”\n",
      "66 : During the last 7 days, on how many days did you do vigorous physical activities like heavy lifting, digging, aerobics, or fast bicycling? Think about only those physical activities that you did for at least 10 minutes at a time. Please answer in days per week._Open-Ended Response\n",
      "67 : How much time in total did you usually spend on one of those days doing vigorous physical activities? Please answer in minutes per day._Open-Ended Response\n",
      "68 : Again, think only about those physical activities that you did for at least 10 minutes at a time. During the last 7 days, on how many days did you do moderate physical activities like carrying light loads, bicycling at a regular pace, or double tennis? Please do not include walking, and please answer in days per week._Open-Ended Response\n",
      "69 : How much time in total did you usually spend on one of those days doing moderate physical activities? Please answer in minutes per day._Open-Ended Response\n",
      "70 : During the last 7 days, on how many days did you walk for at least 10 minutes at a time? This includes walking at work and at home, walking to travel from place to place, and any other walking that you did solely for recreation, sport, exercise or leisure. Please answer in days per week._Open-Ended Response\n",
      "71 : How much time in total did you usually spend walking on one of those days? Please answer in minutes per day._Open-Ended Response\n",
      "72 : These questions ask about the amount and intensity of physical activity that you usually do._I rarely or never do any physical activities\n",
      "73 : These questions ask about the amount and intensity of physical activity that you usually do._I do some light or moderate physical activities, but not every week\n",
      "74 : These questions ask about the amount and intensity of physical activity that you usually do._I do some light physical activity every week\n",
      "75 : These questions ask about the amount and intensity of physical activity that you usually do._I do moderate physical activities every week, but less than 30 minutes a day or 5 days a week\n",
      "76 : These questions ask about the amount and intensity of physical activity that you usually do._I do vigorous physical activities every week, but less than 20 minutes a day or 3 days a week\n",
      "77 : These questions ask about the amount and intensity of physical activity that you usually do._I do 30 minutes or more a day of moderate physical activities, 5 or more days a week\n",
      "78 : These questions ask about the amount and intensity of physical activity that you usually do._I do 20 minutes or more a day of vigorous physical activities, 3 or more days a week\n",
      "79 : These questions ask about the amount and intensity of physical activity that you usually do._I do activities to increase muscle strength, such as lifting weights or calisthenics, once a week or more\n",
      "80 : These questions ask about the amount and intensity of physical activity that you usually do._I do activities to improve flexibility, such as stretching or yoga, once a week or more\n",
      "81 : These questions ask about the amount and intensity of physical activity that you usually do._Other (please specify more comments about any of your answers above)\n",
      "82 : During the past year, how much time did you spend reading each day, including online reading?_hours per day:\n",
      "83 : During the past year, how often were you engaging in..._Reading books (including online)\n",
      "84 : During the past year, how often were you engaging in..._Reading newspaper (including online)\n",
      "85 : During the past year, how often were you engaging in..._Reading magazines (including online)\n",
      "86 : During the past year, how often were you engaging in..._Playing games (word game, checkers, mind teasers, etc)\n",
      "87 : During the past year, how often were you engaging in..._Writing letters or emails\n",
      "88 : During the past year, how often were you engaging in..._Use online social network activities\n",
      "89 : During the past year, how often were you engaging in..._Participating in ‘brain training’ activities\n",
      "90 : During the past year, how often were you engaging in..._Visiting a museum\n",
      "91 : During the past year, how often were you engaging in..._Attending a concert, play or musical\n",
      "92 : During the past year, how often were you engaging in..._Visiting a library\n",
      "93 : How many of your friends do you see or hear from at least once a month?_Response\n",
      "94 : Are you satisfied with your relationships with friends and relatives?_Response\n",
      "95 : How often do you participate in religious services or social, political or community groups?_Response\n",
      "96 : Do you live alone or with other people?_Response\n",
      "97 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Green Leafy Vegetables (1 cup leafy, 1/2 c. for cooked/raw chopped)\n",
      "98 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Other Vegetables (1/2 c, e.g. broccoli, carrots, string beans)\n",
      "99 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Berries (1/2 c, e.g. strawberries, blueberries)\n",
      "100 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Other Fruits (1/2 c)\n",
      "101 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Nuts (handful or 1/4-1/3 c.)\n",
      "102 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Olive oil (1 tbs.)\n",
      "103 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Butter, Cream (1 tablespoon)\n",
      "104 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Regular Cheese (1 oz.)\n",
      "105 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Whole grains (1 slice bread, 3/4 cup pasta/cereal)\n",
      "106 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Fish (3 oz, not fried, not shell)\n",
      "107 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Beans (1/2 c.)\n",
      "108 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Poultry (3 oz, not fried)\n",
      "109 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Red meat (3 oz steak, ham, burgers)\n",
      "110 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Fast foods\n",
      "111 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Pastries & Sweets\n",
      "112 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Wine (glasses per week; 1 glass = 5 oz)\n",
      "113 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Other alcohol (serving = 1.5 oz liquor or 12 oz beer)\n",
      "114 : On average, what percent of your diet is made up of carbohydrates?_Response\n",
      "115 : How many nights per week do you fast (meaning no calories at all) from dinner until breakfast lasting at least ~12 hours? (Please enter a number from 0-7)_Open-Ended Response\n",
      "116 : In the past 12 months, how often did you eat fish or seafood that is not fried?_Response\n",
      "117 : <https://www.alzu.org/assets/images/alcohol-volume.PNG>_Response\n",
      "118 : <https://www.alzu.org/assets/images/alcohol-volume.PNG>_Other (please specify)\n",
      "119 : How many drinks do you have on a typical day when you are drinking?_Response\n",
      "120 : Do you, or have you ever, smoked cigarettes, cigars, pipes or any other tobacco products?_Response\n",
      "121 : Have you ever been involved in occupations that require you to mix, apply or load any pesticides, herbicides, weed killers, fumigants or fungicides?_Response\n",
      "122 : On average, how many hours per night do you sleep?_Open-Ended Response\n",
      "123 : Write a short sketch about a memory from your childhood and why it is memorable or important to you. Feel free to discuss an event with family or friends, a place you traveled, or a significant time in your life.  Please limit your response to no more than 1-2 paragraphs.  This question is optional._Open-Ended Response\n",
      "124 : How does technology and social media impact the daily lives of you and your family?Please limit your response to no more than 1-2 paragraphs.  This question is optional._Open-Ended Response\n",
      "125 : uid_Open-Ended Response\n",
      "126 : joined_Open-Ended Response\n",
      "127 : email_Open-Ended Response\n",
      "128 : lc_Open-Ended Response\n"
     ]
    }
   ],
   "source": [
    "for idx, col in enumerate(alzu_survey_data.columns):\n",
    "    print(str(idx) + \" : \" + str(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num respondents to memory prompt: 373\n",
      "Num respondents to tech prompt: 434\n"
     ]
    }
   ],
   "source": [
    "tech_prompt_idx = 123\n",
    "tec_prompt_idx = 124\n",
    "\n",
    "tech_prompt = alzu_survey_data.columns[tech_prompt_idx]\n",
    "tec_prompt = alzu_survey_data.columns[tec_prompt_idx]\n",
    "\n",
    "print(\"Num respondents to memory prompt: \"+ str(alzu_survey_data[alzu_survey_data[tech_prompt] != ''].shape[0]))\n",
    "print(\"Num respondents to tech prompt: \"+ str(alzu_survey_data[alzu_survey_data[tec_prompt] != ''].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I am exploring how many users have submitted multiple surveys.  After inspecting many of these users responses, I decide to only keep their most recent survey response, because empirically it seems like that one has the richest data -- the other submissions tend to be minutes before and have no responses, making me think they were having technical difficulties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 102 users who submitted multiple surveys.\n"
     ]
    }
   ],
   "source": [
    "val_counts = alzu_survey_data['uid_Open-Ended Response'].value_counts()\n",
    "\n",
    "num_users_multiple_submissions = val_counts[val_counts != 1].shape[0]\n",
    "\n",
    "print(\"There are \" + str(num_users_multiple_submissions) + \" users who submitted multiple surveys.\")\n",
    "# print(val_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alzu_survey_data.drop_duplicates('uid_Open-Ended Response', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CFT Data Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CFT_FILE_PATH = '../Data_Folder/2018.09_CFT_all.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cft_data = pd.read_csv(CFT_FILE_PATH, delimiter = \",\", keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cft_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9309, 45)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cft_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploration of Dr. Isaacson's Questions about how many times people have taken the CFT for those that have registered between August 22nd and March 7th.\n",
    "\n",
    "- Do we use \"RegDate\" in the CFT dataset as the reference date, or do we have to look into the User list for that?\n",
    "- Do we care about those that registered or do we need a Final Score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3957 users have registered for the CFT between Aug 22 2017 and Mar 05 2018\n"
     ]
    }
   ],
   "source": [
    "cft_data['RegDate'] = pd.to_datetime(cft_data['RegDate'])\n",
    "\n",
    "from datetime import datetime\n",
    "start_string = 'Aug 22 2017'\n",
    "end_string = 'Mar 05 2018'\n",
    "start_date = datetime.strptime(start_string, '%b %d %Y')\n",
    "end_date = datetime.strptime(end_string, '%b %d %Y')\n",
    "mask = (cft_data['RegDate'] > start_date) & (cft_data['RegDate'] <= end_date)\n",
    "# Select the sub-DataFrame:\n",
    "\n",
    "cft_btwn_dates = cft_data.loc[mask]\n",
    "\n",
    "print (str(cft_btwn_dates.shape[0]) + \" users have registered for the CFT between \" + start_string + \" and \" + end_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserID\n",
       "1    3377\n",
       "2     245\n",
       "3      23\n",
       "4       3\n",
       "9       1\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cft_btwn_dates.groupby('EmailAddress').count().groupby('UserID').count().ix[:, 2]\n",
    "# for idx, row in cft_data.groupby('EmailAddress').count().groupby('UserID').count():\n",
    "#     print idx, row['FirstName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'UserID', u'FirstName', u'EmailAddress', u'DoB', u'Gender', u'RegDate', u'Country', u'Postcode', u'Source', u'Ethnicy', u'MouseScore', u'Interrupted', u'Functioned', u'FastInternet', u'ScreenClear', u'FinalScore', u'DateTaken', u'Homoscyteine', u'MaritalStatus', u'Dependents', u'Occupation', u'PrimaryIncome', u'HouseholdIncome', u'PrimaryIncomeOccupation', u'FirstPriority', u'SecondPriority', u'OtherPriority', u'FullTime', u'PartTime', u'Working', u'CompUser', u'MemConcern', u'ForgetFriends', u'PutThings', u'ForgetWords', u'LoseWay', u'IsMemoryWorse', u'FamilyHistory', u'FamilyHistoryAge', u'Supplements', u'DeviceUsed', u'ass', u'combocs', u'recallscore', u'placescore'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cft_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CFT Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tests taken: 9309\n",
      "Number of unique users: 8242\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>EmailAddress</th>\n",
       "      <th>DoB</th>\n",
       "      <th>RegDate</th>\n",
       "      <th>Country</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Source</th>\n",
       "      <th>Ethnicy</th>\n",
       "      <th>MouseScore</th>\n",
       "      <th>Interrupted</th>\n",
       "      <th>Functioned</th>\n",
       "      <th>FastInternet</th>\n",
       "      <th>ScreenClear</th>\n",
       "      <th>FinalScore</th>\n",
       "      <th>DateTaken</th>\n",
       "      <th>Homoscyteine</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>PrimaryIncome</th>\n",
       "      <th>HouseholdIncome</th>\n",
       "      <th>PrimaryIncomeOccupation</th>\n",
       "      <th>FirstPriority</th>\n",
       "      <th>SecondPriority</th>\n",
       "      <th>OtherPriority</th>\n",
       "      <th>FullTime</th>\n",
       "      <th>PartTime</th>\n",
       "      <th>Working</th>\n",
       "      <th>CompUser</th>\n",
       "      <th>MemConcern</th>\n",
       "      <th>ForgetFriends</th>\n",
       "      <th>PutThings</th>\n",
       "      <th>ForgetWords</th>\n",
       "      <th>LoseWay</th>\n",
       "      <th>IsMemoryWorse</th>\n",
       "      <th>FamilyHistory</th>\n",
       "      <th>FamilyHistoryAge</th>\n",
       "      <th>Supplements</th>\n",
       "      <th>DeviceUsed</th>\n",
       "      <th>ass</th>\n",
       "      <th>combocs</th>\n",
       "      <th>recallscore</th>\n",
       "      <th>placescore</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "      <td>7024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "      <td>1218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        UserID  FirstName  EmailAddress   DoB  RegDate  Country  Postcode  Source  Ethnicy  MouseScore  Interrupted  Functioned  FastInternet  ScreenClear  FinalScore  DateTaken  Homoscyteine  MaritalStatus  Dependents  Occupation  PrimaryIncome  HouseholdIncome  PrimaryIncomeOccupation  FirstPriority  SecondPriority  OtherPriority  FullTime  PartTime  Working  CompUser  MemConcern  ForgetFriends  PutThings  ForgetWords  LoseWay  IsMemoryWorse  FamilyHistory  FamilyHistoryAge  Supplements  DeviceUsed   ass  combocs  recallscore  placescore\n",
       "Gender                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "F         7024       7024          7024  7024     7024     7024      7024    7024     7024        7024         7024        7024          7024         7024        7024       7024          7024           7024        7024        7024           7024             7024                     7024           7024            7024           7024      7024      7024     7024      7024        7024           7024       7024         7024     7024           7024           7024              7024         7024        7024  7024     7024         7024        7024\n",
       "M         1218       1218          1218  1218     1218     1218      1218    1218     1218        1218         1218        1218          1218         1218        1218       1218          1218           1218        1218        1218           1218             1218                     1218           1218            1218           1218      1218      1218     1218      1218        1218           1218       1218         1218     1218           1218           1218              1218         1218        1218  1218     1218         1218        1218"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_cft = cft_data.drop_duplicates('EmailAddress', keep='first') # takes the first (oldest) score\n",
    "\n",
    "print(\"Number of tests taken: \" + str(cft_data.shape[0]))\n",
    "print(\"Number of unique users: \" + str(unique_cft.shape[0]))\n",
    "\n",
    "unique_cft.groupby('Gender').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserID\n",
      "FirstName\n",
      "EmailAddress\n",
      "DoB\n",
      "Gender\n",
      "RegDate\n",
      "Country\n",
      "Postcode\n",
      "Source\n",
      "Ethnicy\n",
      "MouseScore\n",
      "Interrupted\n",
      "Functioned\n",
      "FastInternet\n",
      "ScreenClear\n",
      "FinalScore\n",
      "DateTaken\n",
      "Homoscyteine\n",
      "MaritalStatus\n",
      "Dependents\n",
      "Occupation\n",
      "PrimaryIncome\n",
      "HouseholdIncome\n",
      "PrimaryIncomeOccupation\n",
      "FirstPriority\n",
      "SecondPriority\n",
      "OtherPriority\n",
      "FullTime\n",
      "PartTime\n",
      "Working\n",
      "CompUser\n",
      "MemConcern\n",
      "ForgetFriends\n",
      "PutThings\n",
      "ForgetWords\n",
      "LoseWay\n",
      "IsMemoryWorse\n",
      "FamilyHistory\n",
      "FamilyHistoryAge\n",
      "Supplements\n",
      "DeviceUsed\n",
      "ass\n",
      "combocs\n",
      "recallscore\n",
      "placescore\n"
     ]
    }
   ],
   "source": [
    "for cft_col in unique_cft.columns:\n",
    "    print(cft_col)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Email-UserID Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ALZU_USERS_FILE_PATH = '../Data_Folder/2018.09_alzu_users.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_data = pd.read_csv(ALZU_USERS_FILE_PATH, delimiter = \",\", keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# user_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations + Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75005, 9)\n",
      "(74779, 9)\n"
     ]
    }
   ],
   "source": [
    "user_data['Joined'] = pd.to_datetime(user_data['Joined'])\n",
    "print(user_data.shape)\n",
    "user_data = user_data.drop_duplicates('Email', keep='last')\n",
    "print(user_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total users: 74779\n",
      "Number of male users: 12885\n",
      "Number of female users: 61894\n",
      "Male:Female Ratio ≈ 1:4.80357004269\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of total users: \" + str(user_data.shape[0]))\n",
    "gender_grouping = user_data['Gender'].value_counts()\n",
    "num_females = gender_grouping['F']\n",
    "num_males = gender_grouping['M']\n",
    "\n",
    "print(\"Number of male users: \" + str(num_males))\n",
    "print(\"Number of female users: \" + str(num_females))\n",
    "print(\"Male:Female Ratio ≈ 1:\" + str(num_females / num_males))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj0AAAG0CAYAAADZxpaMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a151c2ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "date_indexed = user_data.set_index(user_data[\"Joined\"])\n",
    "date_indexed['count'] = 1\n",
    "counts = date_indexed['count'].resample('M').sum().dropna()\n",
    "\n",
    "counts = counts[2:] #get rid of 2 obviously incorrect ones dating way back\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "cumulative_counts = counts.cumsum()\n",
    "cumulative_counts.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JOIN DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/travisallen/anaconda/lib/python2.7/site-packages/pandas/core/frame.py:2834: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  **kwargs)\n"
     ]
    }
   ],
   "source": [
    "unique_cft.rename(index=str, columns={\"EmailAddress\": \"Email\"}, inplace=True)\n",
    "alzu_survey_data.rename(index=str, columns={\"uid_Open-Ended Response\": \"User ID\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users_joined_cognitive = user_data.merge(unique_cft, on=\"Email\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(users_joined_cognitive.shape)\n",
    "# users_joined_cognitive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data = users_joined_cognitive.merge(alzu_survey_data, on=\"User ID\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74779, 181)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Exploration of Combined Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Joined\n",
      "1 : User ID\n",
      "2 : First Name\n",
      "3 : Email\n",
      "4 : Gender_x\n",
      "5 : Lesson Group\n",
      "6 : Lesson Count\n",
      "7 : Activ. Start\n",
      "8 : Activ. Compl.\n",
      "9 : UserID\n",
      "10 : FirstName\n",
      "11 : DoB\n",
      "12 : Gender_y\n",
      "13 : RegDate\n",
      "14 : Country\n",
      "15 : Postcode\n",
      "16 : Source\n",
      "17 : Ethnicy\n",
      "18 : MouseScore\n",
      "19 : Interrupted\n",
      "20 : Functioned\n",
      "21 : FastInternet\n",
      "22 : ScreenClear\n",
      "23 : FinalScore\n",
      "24 : DateTaken\n",
      "25 : Homoscyteine\n",
      "26 : MaritalStatus\n",
      "27 : Dependents\n",
      "28 : Occupation\n",
      "29 : PrimaryIncome\n",
      "30 : HouseholdIncome\n",
      "31 : PrimaryIncomeOccupation\n",
      "32 : FirstPriority\n",
      "33 : SecondPriority\n",
      "34 : OtherPriority\n",
      "35 : FullTime\n",
      "36 : PartTime\n",
      "37 : Working\n",
      "38 : CompUser\n",
      "39 : MemConcern\n",
      "40 : ForgetFriends\n",
      "41 : PutThings\n",
      "42 : ForgetWords\n",
      "43 : LoseWay\n",
      "44 : IsMemoryWorse\n",
      "45 : FamilyHistory\n",
      "46 : FamilyHistoryAge\n",
      "47 : Supplements\n",
      "48 : DeviceUsed\n",
      "49 : ass\n",
      "50 : combocs\n",
      "51 : recallscore\n",
      "52 : placescore\n",
      "53 : Respondent ID_\n",
      "54 : Collector ID_\n",
      "55 : Start Date_\n",
      "56 : End Date_\n",
      "57 : IP Address_\n",
      "58 : Email Address_\n",
      "59 : First Name_\n",
      "60 : Last Name_\n",
      "61 : Custom Data 1_\n",
      "62 : How many lessons did you complete on AlzU.org?_Response\n",
      "63 : Please select the reasons why you have not yet completed the full 10 lesson course on AlzU.org. Select ALL that apply_Response\n",
      "64 : Please select the reasons why you have not yet completed the full 10 lesson course on AlzU.org. Select ALL that apply_Other (please specify)\n",
      "65 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Saw a doctor to discuss ways to lower AD risk?\n",
      "66 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Participated in an AD prevention research study other than this one?\n",
      "67 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Saw a doctor to be evaluated for memory loss?\n",
      "68 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Saw a doctor to discuss ways to prevent memory loss?\n",
      "69 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Saw a doctor to discuss an AD research study for a family member or friend?\n",
      "70 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Was screened for, or enrolled in, an AD prevention clinical trial?\n",
      "71 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Was screened for, or enrolled in, the Early Study AD prevention clinical trial?\n",
      "72 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Was screened for, or enrolled in, the Generation Study AD prevention clinical trial?\n",
      "73 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Joined the AD prevention registry endALZnow.org?\n",
      "74 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Joined the AD prevention registry BrainHealthRegistry.org?\n",
      "75 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Joined the Global Alzheimer's Platform \"TRC PAD\" AD prevention registry?\n",
      "76 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Made a dietary change to improve my brain health?\n",
      "77 : Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Increased exercise to improve my brain health?\n",
      "78 : What would you be willing to do or to undergo in order to learn about your risk for developing AD someday in the future?_Take tests of my thinking and memory.\n",
      "79 : What would you be willing to do or to undergo in order to learn about your risk for developing AD someday in the future?_Get a blood test.\n",
      "80 : What would you be willing to do or to undergo in order to learn about your risk for developing AD someday in the future?_Get a brain scan (picture of the brain, like an MRI or cat scan).\n",
      "81 : What would you be willing to do or to undergo in order to learn about your risk for developing AD someday in the future?_Get a genetic test to determine whether I have an Alzheimer’s risk gene.\n",
      "82 : Please rate how likely it is that you would participate in the following types of AD research studies:_Requires answering questions on a computer and taking tests of memory skills?\n",
      "83 : Please rate how likely it is that you would participate in the following types of AD research studies:_Randomly assigns half to receive a medicine and the other half to receive an inactive version?\n",
      "84 : Please rate how likely it is that you would participate in the following types of AD research studies:_Randomly assigns half to make a dietary and exercise change, and the other half to continue as usual?\n",
      "85 : Please rate how helpful or harmful each of the following would be._Seeing your doctor to discuss ways to lower AD risk\n",
      "86 : Please rate how helpful or harmful each of the following would be._Participate in an AD prevention research study\n",
      "87 : Please rate your level of agreement with the following questions._There is a strong possibility that I will develop AD\n",
      "88 : Please rate your level of agreement with the following questions._Changing my lifestyle and health habits can help me reduce my chance of developing AD\n",
      "89 : Please rate your level of agreement with the following questions._I have a lot to gain by changing my lifestyle and health behavior\n",
      "90 : Please rate your level of agreement with the following questions._I feel that my chances of developing AD in the future are high\n",
      "91 : Please rate your level of agreement with the following questions._I am too busy to change my lifestyle and health habits\n",
      "92 : Please rate your level of agreement with the following questions._Family responsibilities make it hard for me to change my lifestyle and behavior\n",
      "93 : Please rate your level of agreement with the following questions._When I think about AD my heart beats faster\n",
      "94 : Please rate your level of agreement with the following questions._When I think about AD I feel nauseous\n",
      "95 : Please rate your level of agreement with the following questions._The thought of AD scares me\n",
      "96 : Please rate your level of agreement with the following questions._Changing lifestyle and behavior interferes with my schedule\n",
      "97 : Please rate your level of agreement with the following questions._My chances of developing AD are great.\n",
      "98 : Please rate your level of agreement with the following questions._I am certain that I can change my lifestyle and behavior so I can reduce the risk of developing AD\n",
      "99 : How much do you weigh without your clothes and shoes in pounds?_Open-Ended Response\n",
      "100 : Have you ever been told by a doctor or other health professional that you have diabetes or have high sugar levels in your blood or urine?_Response\n",
      "101 : Have you ever been told by a doctor or other health professional that you have high cholesterol levels in the past 2 years or your cholesterol level is higher than 240mg/dL?_Response\n",
      "102 : If you recall your most recent cholesterol results, please enter here:_Total Cholesterol\n",
      "103 : If you recall your most recent cholesterol results, please enter here:_LDL (\"bad\" cholesterol)\n",
      "104 : If you recall your most recent cholesterol results, please enter here:_HDL (\"good\" cholesterol)\n",
      "105 : If you recall your most recent cholesterol results, please enter here:_Triglycerides\n",
      "106 : If you recall your most recent blood pressure, please enter here. This is recorded as a two numbers, e.g., 130/80. Please enter the larger number (called Systolic) first, and the smaller number (called Diastolic), second._Systolic Blood Pressure\n",
      "107 : If you recall your most recent blood pressure, please enter here. This is recorded as a two numbers, e.g., 130/80. Please enter the larger number (called Systolic) first, and the smaller number (called Diastolic), second._Diastolic Blood Pressure\n",
      "108 : Have you ever had a head injury where you lost consciousness for more than 15 minutes?_Response\n",
      "109 : Check best answer for each description._I was bothered by things that usually don’t bother me.\n",
      "110 : Check best answer for each description._I had trouble keeping my mind on what I was doing.\n",
      "111 : Check best answer for each description._I felt depressed.\n",
      "112 : Check best answer for each description._I felt that everything I did was an effort.\n",
      "113 : Check best answer for each description._I felt hopeful about the future.\n",
      "114 : Check best answer for each description._I felt fearful.\n",
      "115 : Check best answer for each description._My sleep was restless.\n",
      "116 : Check best answer for each description._I was happy.\n",
      "117 : Check best answer for each description._I felt lonely.\n",
      "118 : Check best answer for each description._I could not “get going”\n",
      "119 : During the last 7 days, on how many days did you do vigorous physical activities like heavy lifting, digging, aerobics, or fast bicycling? Think about only those physical activities that you did for at least 10 minutes at a time. Please answer in days per week._Open-Ended Response\n",
      "120 : How much time in total did you usually spend on one of those days doing vigorous physical activities? Please answer in minutes per day._Open-Ended Response\n",
      "121 : Again, think only about those physical activities that you did for at least 10 minutes at a time. During the last 7 days, on how many days did you do moderate physical activities like carrying light loads, bicycling at a regular pace, or double tennis? Please do not include walking, and please answer in days per week._Open-Ended Response\n",
      "122 : How much time in total did you usually spend on one of those days doing moderate physical activities? Please answer in minutes per day._Open-Ended Response\n",
      "123 : During the last 7 days, on how many days did you walk for at least 10 minutes at a time? This includes walking at work and at home, walking to travel from place to place, and any other walking that you did solely for recreation, sport, exercise or leisure. Please answer in days per week._Open-Ended Response\n",
      "124 : How much time in total did you usually spend walking on one of those days? Please answer in minutes per day._Open-Ended Response\n",
      "125 : These questions ask about the amount and intensity of physical activity that you usually do._I rarely or never do any physical activities\n",
      "126 : These questions ask about the amount and intensity of physical activity that you usually do._I do some light or moderate physical activities, but not every week\n",
      "127 : These questions ask about the amount and intensity of physical activity that you usually do._I do some light physical activity every week\n",
      "128 : These questions ask about the amount and intensity of physical activity that you usually do._I do moderate physical activities every week, but less than 30 minutes a day or 5 days a week\n",
      "129 : These questions ask about the amount and intensity of physical activity that you usually do._I do vigorous physical activities every week, but less than 20 minutes a day or 3 days a week\n",
      "130 : These questions ask about the amount and intensity of physical activity that you usually do._I do 30 minutes or more a day of moderate physical activities, 5 or more days a week\n",
      "131 : These questions ask about the amount and intensity of physical activity that you usually do._I do 20 minutes or more a day of vigorous physical activities, 3 or more days a week\n",
      "132 : These questions ask about the amount and intensity of physical activity that you usually do._I do activities to increase muscle strength, such as lifting weights or calisthenics, once a week or more\n",
      "133 : These questions ask about the amount and intensity of physical activity that you usually do._I do activities to improve flexibility, such as stretching or yoga, once a week or more\n",
      "134 : These questions ask about the amount and intensity of physical activity that you usually do._Other (please specify more comments about any of your answers above)\n",
      "135 : During the past year, how much time did you spend reading each day, including online reading?_hours per day:\n",
      "136 : During the past year, how often were you engaging in..._Reading books (including online)\n",
      "137 : During the past year, how often were you engaging in..._Reading newspaper (including online)\n",
      "138 : During the past year, how often were you engaging in..._Reading magazines (including online)\n",
      "139 : During the past year, how often were you engaging in..._Playing games (word game, checkers, mind teasers, etc)\n",
      "140 : During the past year, how often were you engaging in..._Writing letters or emails\n",
      "141 : During the past year, how often were you engaging in..._Use online social network activities\n",
      "142 : During the past year, how often were you engaging in..._Participating in ‘brain training’ activities\n",
      "143 : During the past year, how often were you engaging in..._Visiting a museum\n",
      "144 : During the past year, how often were you engaging in..._Attending a concert, play or musical\n",
      "145 : During the past year, how often were you engaging in..._Visiting a library\n",
      "146 : How many of your friends do you see or hear from at least once a month?_Response\n",
      "147 : Are you satisfied with your relationships with friends and relatives?_Response\n",
      "148 : How often do you participate in religious services or social, political or community groups?_Response\n",
      "149 : Do you live alone or with other people?_Response\n",
      "150 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Green Leafy Vegetables (1 cup leafy, 1/2 c. for cooked/raw chopped)\n",
      "151 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Other Vegetables (1/2 c, e.g. broccoli, carrots, string beans)\n",
      "152 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Berries (1/2 c, e.g. strawberries, blueberries)\n",
      "153 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Other Fruits (1/2 c)\n",
      "154 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Nuts (handful or 1/4-1/3 c.)\n",
      "155 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Olive oil (1 tbs.)\n",
      "156 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Butter, Cream (1 tablespoon)\n",
      "157 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Regular Cheese (1 oz.)\n",
      "158 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Whole grains (1 slice bread, 3/4 cup pasta/cereal)\n",
      "159 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Fish (3 oz, not fried, not shell)\n",
      "160 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Beans (1/2 c.)\n",
      "161 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Poultry (3 oz, not fried)\n",
      "162 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Red meat (3 oz steak, ham, burgers)\n",
      "163 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Fast foods\n",
      "164 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Pastries & Sweets\n",
      "165 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Wine (glasses per week; 1 glass = 5 oz)\n",
      "166 : How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Other alcohol (serving = 1.5 oz liquor or 12 oz beer)\n",
      "167 : On average, what percent of your diet is made up of carbohydrates?_Response\n",
      "168 : How many nights per week do you fast (meaning no calories at all) from dinner until breakfast lasting at least ~12 hours? (Please enter a number from 0-7)_Open-Ended Response\n",
      "169 : In the past 12 months, how often did you eat fish or seafood that is not fried?_Response\n",
      "170 : <https://www.alzu.org/assets/images/alcohol-volume.PNG>_Response\n",
      "171 : <https://www.alzu.org/assets/images/alcohol-volume.PNG>_Other (please specify)\n",
      "172 : How many drinks do you have on a typical day when you are drinking?_Response\n",
      "173 : Do you, or have you ever, smoked cigarettes, cigars, pipes or any other tobacco products?_Response\n",
      "174 : Have you ever been involved in occupations that require you to mix, apply or load any pesticides, herbicides, weed killers, fumigants or fungicides?_Response\n",
      "175 : On average, how many hours per night do you sleep?_Open-Ended Response\n",
      "176 : Write a short sketch about a memory from your childhood and why it is memorable or important to you. Feel free to discuss an event with family or friends, a place you traveled, or a significant time in your life.  Please limit your response to no more than 1-2 paragraphs.  This question is optional._Open-Ended Response\n",
      "177 : How does technology and social media impact the daily lives of you and your family?Please limit your response to no more than 1-2 paragraphs.  This question is optional._Open-Ended Response\n",
      "178 : joined_Open-Ended Response\n",
      "179 : email_Open-Ended Response\n",
      "180 : lc_Open-Ended Response\n"
     ]
    }
   ],
   "source": [
    "for idx, col in enumerate(cols):\n",
    "    print(str(idx) + \" : \" + str(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "memory_prompt_idx = 176\n",
    "tech_prompt_idx = 177\n",
    "\n",
    "memory_prompt = cols[memory_prompt_idx]\n",
    "tech_prompt = cols[tech_prompt_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peform some General Data Transformations that do not feel model or experiment-specific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop all rows in which they have neither Survey Data or CFT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "survey_and_cft_columns = cols[range(9, 180)]\n",
    "\n",
    "all_data.dropna(how='all', subset=[survey_and_cft_columns], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename gender column and replace with 0 (female) and 1 (male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data.rename(index=str, columns={\"Gender_x\": \"Gender\"}, inplace=True)\n",
    "\n",
    "all_data['Gender'].replace(['F','M'],[0,1],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an Age column based on the DoB column and get some stats on age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "now = pd.Timestamp(DT.datetime.now())\n",
    "\n",
    "\n",
    "dobs = pd.to_datetime(all_data[all_data['DoB'].notnull()]['DoB'])\n",
    "dobs = dobs.where(dobs < now, dobs -  np.timedelta64(100, 'Y'))\n",
    "ages = (now - dobs).astype('<m8[Y]')    # 3\n",
    "\n",
    "all_data['Age'] = ages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "join_dates = pd.to_datetime(all_data[all_data['Joined'].notnull()]['Joined'])\n",
    "\n",
    "join_dates = join_dates.where(join_dates < now, join_dates -  np.timedelta64(100, 'Y'))\n",
    "\n",
    "days_as_member = (now - join_dates).astype('<m8[D]')\n",
    "\n",
    "all_data['Days_As_Member'] = days_as_member"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace NANs in the prompt columns with empty strings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data[memory_prompt].fillna('', inplace=True)\n",
    "all_data[tech_prompt].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format Scores as Numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data['FinalScore'] = pd.to_numeric(all_data['FinalScore'])\n",
    "all_data['MouseScore'] = pd.to_numeric(all_data['FinalScore'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Stats on Transformed \"All Data\" Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9126, 183)\n",
      "Average Age:\n",
      "60.4183276616\n",
      "Median Age:\n",
      "62.0\n",
      "Number of male users: 1355\n",
      "Number of female users: 7771\n",
      "Male:Female Ratio ≈ 1:5.73505535055\n",
      "Average membership Duration:\n",
      "534.895901819\n",
      "451\n"
     ]
    }
   ],
   "source": [
    "print(all_data.shape)\n",
    "print(\"Average Age:\")\n",
    "print(all_data['Age'].mean())\n",
    "print(\"Median Age:\")\n",
    "print(all_data['Age'].median())\n",
    "\n",
    "gender_grouping = all_data['Gender'].value_counts()\n",
    "num_females = gender_grouping[0]\n",
    "num_males = gender_grouping[1]\n",
    "\n",
    "print(\"Number of male users: \" + str(num_males))\n",
    "print(\"Number of female users: \" + str(num_females))\n",
    "print(\"Male:Female Ratio ≈ 1:\" + str(num_females / num_males))\n",
    "\n",
    "print(\"Average membership Duration:\")\n",
    "print(all_data['Days_As_Member'].mean())\n",
    "\n",
    "print(all_data[((all_data[memory_prompt] != \"\") | (all_data[tech_prompt] != \"\"))].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for users with cognitive scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1:  Ignore the written portion and identify best ML model for those with Cognitive Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Summary Stats on those that have taken Cognitive Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num respondents with final cognitive score: 7472\n",
      "Average CFT Score: 43.1248736762\n",
      "Median CFT Score: 43.32902357\n",
      "Standard Deviation of CFT Score: 9.32685473433\n"
     ]
    }
   ],
   "source": [
    "cog_takers = all_data[all_data['FinalScore'].notnull()]\n",
    "print(\"Num respondents with final cognitive score: \" + str(cog_takers.shape[0]))\n",
    "\n",
    "print(\"Average CFT Score: \" + str(cog_takers['FinalScore'].mean()))\n",
    "print(\"Median CFT Score: \" + str(cog_takers['FinalScore'].median()))\n",
    "print(\"Standard Deviation of CFT Score: \" + str(cog_takers['FinalScore'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAGzCAYAAADUo+joAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzs3XtUVXX+//HXQS4aCIgJSF7CdBRTLLUfoFYmJGAXTbrQ\n0JTGV6cCU9BxpFLTLM3JVMzLXBytCXKy1EnnG46Bl28zSEqZ5pCFMYOOAgUeQBTkcn5/9HV/Owc1\njgEH9flYa6/l+Xw+57Pf+0xr8Zq9P3tvk8VisQgAAAAGJ0cXAAAA0NYQkAAAAGwQkAAAAGwQkAAA\nAGwQkAAAAGwQkAAAAGwQkAAAAGwQkAAAAGwQkAAAAGwQkICrhMlk0osvvujoMq5J+/bt07Bhw+Tu\n7i6TyaQDBw44uiQAPxEBCbgCrFq1SiaTSSEhIc0678iRIzVgwIAL9n333Xd2ha6KigrNmzdPgwYN\nkoeHhzp06KABAwbo17/+tU6cOGGMmzBhgkwm0wW3jIwMjRw58qL9P9wuVZftPjw9PTVo0CAtWbJE\nNTU19vxEP6q2tlYPPfSQysrKtHTpUv3pT39Sz549m3UfAFqfs6MLAPDj0tLSdOONN+qTTz5Rfn6+\nevfu7eiSrHzzzTeKiIhQYWGhHnroIU2ePFmurq46ePCg1q5dq82bN+urr74yxru5uekPf/hDo3kG\nDRqk559/Xv/1X/9ltO3bt0+pqal67rnnFBQUZLQHBwdfsqYf7sNsNuv999/XjBkztG/fPm3YsOGn\nHrLh6NGj+ve//63f//73VnUDuLIRkIA2rqCgQP/4xz+0adMm/fKXv1RaWprmzp3r6LIMdXV1Gj9+\nvIqLi7Vr1y6NGDHCqv/ll1/Wq6++atXm7Oysxx577ILzde3a1epz+/btlZqaqrvvvlsjR45scl22\n+3jmmWcUEhKiP//5z3r99dcVEBDQ5LkupKqqSu7u7iopKZEkeXt7/6T5LjQ3AMfhEhvQxqWlpalT\np06655579OCDDyotLe1Hv/Ovf/3rkpenmtP777+vzz//XM8//3yjcCRJnp6eevnll5t1n5fDycnJ\nCFj/+te/jPYvv/xSDz74oHx8fNS+fXsNHTpUH3zwgdV3169fL5PJpN27d+uZZ56Rr6+vunXrpgkT\nJujOO++UJD300EMymUxWIS4rK0u333673N3d5e3trbFjxyovL89q7hdffFEmk0n//Oc/9fOf/1yd\nOnUyfscJEybIw8NDhYWFuvfee+Xh4aEbbrhBK1eulCQdOnRIo0aNkru7u3r27Kn09HSrucvKyjRj\nxgwNHDhQHh4e8vT0VHR0tD7//HOrcbt27ZLJZNK7776rl19+Wd26dVP79u0VHh6u/Pz8Rr9lTk6O\nxowZo06dOsnd3V3BwcFavny51Zim/K5AW8YZJKCNS0tL0/jx4+Xq6qpHH31Uq1ev1r59+3Tbbbdd\n9DtdunTRn/70J6u22tpaJSUlydXVtVnrO/9H7xe/+IVd3/vuu++sPru4uMjLy6vZ6rqQo0ePSpI6\nd+4sSTp8+LCGDx+uG264QbNmzZK7u7veffddjRs3Tu+//74eeOABq+8/88wz6tKli+bMmaOqqird\ncccduuGGG/TKK6/o2Wef1W233SY/Pz9J0kcffaTo6Gj16tVLL774os6ePasVK1Zo+PDh+vTTT3Xj\njTdazf3QQw+pT58+euWVV2SxWIz2+vp6RUdH64477tDixYuVlpamxMREubu76/nnn1dcXJzGjx+v\nNWvW6PHHH1dYWJgCAwMlfX/pc8uWLXrooYcUGBio4uJi/fa3v9Wdd96pf/7zn43Ooi1atEhOTk6a\nMWOGysvLtXjxYsXFxSknJ8cYs2PHDt17773q2rWrpk6dKn9/f+Xl5Wnbtm2aOnXqZf2uQJtkAdBm\n7d+/3yLJsmPHDovFYrE0NDRYunXrZpk6dWqjsZIsc+fOvehczzzzjKVdu3aWrKwso+3OO++03Hzz\nzRcc/+233/7onBaLxXLrrbdavLy8fvxg/tcTTzxhkdRou/POOy84fuPGjRZJlp07d9q1D3d3d8u3\n335r+fbbby35+fmWV155xWIymSzBwcHGuPDwcMvAgQMt1dXVRltDQ4Nl2LBhlj59+hht69ats0iy\njBgxwlJXV2e1r507d1okWTZu3GjVfsstt1h8fX0tpaWlRtvnn39ucXJysjz++ONG29y5cy2SLI8+\n+ugFj0OS5ZVXXjHaTp06ZenQoYPFZDJZNmzYYLR/+eWXjf73qq6uttTX11vNWVBQYHFzc7PMnz+/\n0TEEBQVZampqjPbly5dbJFkOHTpksVgslrq6OktgYKClZ8+ellOnTlnN29DQYPy7qb8r0JZxBglo\nw9LS0uTn56e77rpL0ve38j/yyCN6++23tWTJErVr165J87z11ltatWqVlixZYszVXCoqKtSxY0e7\nvtO+fXtt3brVqq1Tp07NWZaqqqrUpUsXq7Zhw4YZZ9bKysqUlZWl+fPnq7KyUpWVlca4yMhIzZ07\nV//5z390ww03GO2TJk1q0m9+8uRJHThwQDNnzpSPj4/RHhwcrLvvvlv//d//3eg7Tz311EXn++Hi\nb29vb/Xt21f5+fl6+OGHjfa+ffvK29tb33zzjdHm5uZm/Lu+vl5ms1keHh7q27evPv3000b7mThx\notUZxttvv13S92eiBgwYoM8++0wFBQVaunRpozVX5y/dXs7vCrRFBCSgjaqvr9eGDRt01113qaCg\nwGgPCQnRkiVLlJmZqdGjR//oPAcOHNBTTz2lRx99VMnJyXbX8WNrljw9Pa3+KDdFu3btFBERYXct\n9vhhCHNzc1NgYKC6detm9Ofn58tisWj27NmaPXv2BecoKSmx+kN+/tLVj/n3v/8t6fvQYisoKEjb\nt29vtBD7YnO3b9++UdDz8vJSt27dGv1v4+XlpVOnThmfGxoatHz5cq1atUoFBQWqr683+s5fZvyh\nHj16WH0+H1rPz3n+EuXFHg0hXd7vCrRFBCSgjcrKytLJkye1YcOGC96WnpaW9qMB6dSpU4qJidHP\nfvazC95W3759e509e/aC3z1z5owx5lL69eunzz77TMeOHVP37t0vObY1/VgIa2hokCTNmDFDkZGR\nFxxj+ziFDh06NF+BNi4298XOWF2s3fKD9UuvvPKKZs+erSeffFIvvfSSfHx85OTkpGnTphnHb++c\nP+ZyflegLSIgAW1UWlqafH19jTuWfmjTpk3avHmz1qxZc9E/rA0NDYqLi5PZbNZHH32k6667rtGY\nnj17KisrS2fPnm00z5EjR4wxl3LffffpnXfe0dtvv62UlJSmHp7D9erVS9L3i8Ob+2zW+d/s/G/4\nQ19++aWuv/76VrmN/7333tNdd92ltWvXWrWbzWZdf/31ds930003SZK++OKLi/5mLfm7Aq2J2/yB\nNujs2bPatGmT7r33Xj344IONtsTERFVWVl7ytul58+Zp+/bteueddy56+WbMmDGqra3Vb3/7W6v2\nhoYGrV69Wq6urgoPD79krQ8++KAGDhyol19+WdnZ2Y36Kysr9fzzzzfhqFuXr6+vRo4cqd/+9rc6\nefJko/5vv/32sufu2rWrbrnlFr355psym81G+xdffKG//e1vGjNmzGXPbY927do1OvuzceNG/ec/\n/7ms+QYPHqzAwEAtW7bM6rik/zvL1JK/K9CaOIMEtEEffPCBKisrdf/991+wPzQ0VF26dFFaWpoe\neeSRRv2HDh3SSy+9pDvuuEMlJSV6++23rfrPP0Dxvvvu0+jRo5WUlKRPPvlEw4YN05kzZ/TBBx/o\n73//uxYsWNBo/YstFxcXbdq0SREREbrjjjv08MMPa/jw4XJxcdHhw4eVnp6uTp06tYlnIdlauXKl\nRowYoYEDB2rSpEnq1auXiouLlZ2drePHjzd6XpA9fvOb3yg6OlphYWGKj483bvP38vJqtXfm3Xvv\nvZo/f74mTpyoYcOG6dChQ0pLSzPO8tjLyclJq1ev1n333adbbrlFEydOVNeuXfXll1/q8OHD2r59\nu6SW/V2B1kJAAtqgtLQ0tW/fXnffffcF+52cnHTPPfcoLS1NpaWljRbclpaWymKxaPfu3dq9e3ej\n758PSE5OTvrggw+0aNEibdiwQZs2bZKzs7MGDhyot99+W3FxcU2qt3fv3jpw4ICWLl2qzZs3a8uW\nLaqvr1evXr00YcIEJSUl2fkLtI7+/ftr//79mjdvntavX6/S0lL5+vrq1ltv1Zw5c37S3BEREcrI\nyNDcuXM1Z84cubi46M4779Srr77a5MXeP9Vzzz2nqqoqpaen689//rMGDx6sv/71r5o1a9ZlzxkZ\nGamdO3dq3rx5WrJkiRoaGnTTTTdp0qRJxpiW/F2B1mKy2LP6DgAA4BrAGiQAAAAbBCQAAAAbBCQA\nAAAbBCQAAAAbBCQAAAAbBCQAAAAbbeY5SIsWLVJKSoqmTp2qZcuWSfr+yaxz587V73//e5nNZg0f\nPlyrV69Wnz59jO9VV1dr+vTp2rBhg2pqahQZGalVq1bJz8/PGFNWVqYpU6Zo69atcnJyUkxMjJYv\nXy4PD48m19fQ0KATJ06oY8eOP/ryTgAA0DZYLBZVVlYqICBATk52nBeytAGffPKJ5cYbb7QEBwdb\npk6darQvWrTI4uXlZdmyZYvl888/t9x///2WwMBAy9mzZ40xTz31lKV79+6WzMxMy/79+y2hoaGW\nYcOGWc0fFRVlGTRokGXv3r2W//mf/7H07t3b8uijj9pV47FjxyyS2NjY2NjY2K7A7dixY3b93Xf4\ngyJPnz6twYMHa9WqVVqwYIFuueUWLVu2TBaLRQEBAZo+fbpmzJghSSovL5efn5/Wr1+v2NhYlZeX\nq0uXLkpPT9eDDz4o6fsXQQYFBSk7O1uhoaHKy8tT//79tW/fPg0dOlSSlJGRoTFjxuj48eMKCAho\nUp3l5eXy9vbWsWPH5Onp2TI/BgAAaFYVFRXq3r27zGazvLy8mvw9h19iS0hI0D333KOIiAgtWLDA\naC8oKFBRUZHV26C9vLwUEhKi7OxsxcbGKjc3V7W1tVZj+vXrpx49ehgBKTs7W97e3kY4kr5/BYCT\nk5NycnL0wAMPXLCumpoa1dTUGJ8rKyslSZ6engQkAACuMPYuj3FoQNqwYYM+/fRT7du3r1FfUVGR\nJFmtJTr/+XxfUVGRXF1d5e3tfckxvr6+Vv3Ozs7y8fExxlzIwoULNW/ePPsPCgAAXPEcdhfbsWPH\nNHXqVOOlnG1NSkqKysvLje3YsWOOLgkAALQShwWk3NxclZSUaPDgwXJ2dpazs7N2796t1NRUOTs7\nG2eOiouLrb5XXFwsf39/SZK/v7/OnTsns9l8yTElJSVW/XV1dSorKzPGXIibm5txOY3LagAAXFsc\nFpDCw8N16NAhHThwwNiGDh2quLg4HThwQL169ZK/v78yMzON71RUVCgnJ0dhYWGSpCFDhsjFxcVq\nzJEjR1RYWGiMCQsLk9lsVm5urjEmKytLDQ0NCgkJaaWjBQAAVxKHrUHq2LGjBgwYYNXm7u6uzp07\nG+3Tpk3TggUL1KdPHwUGBmr27NkKCAjQuHHjJH2/aDs+Pl7Jycny8fGRp6enpkyZorCwMIWGhkqS\ngoKCFBUVpUmTJmnNmjWqra1VYmKiYmNjm3wHGwAAuLY4/C62S5k5c6aqqqo0efJkmc1mjRgxQhkZ\nGVZrlpYuXWo8/PGHD4r8obS0NCUmJio8PNwYm5qa2tqHAwAArhAOfw7SlaKiokJeXl4qLy9nPRIA\nAFeIy/37zbvYAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbLTp5yABAK4N5dXlOlN7\nxtFlwIGuc7lOXu29HF2GgYAEAHCo8upyvbTnJX135jtHlwIHuv666zX7jtltJiQRkAAADnWm9oy+\nO/OdOjh30HUu1zm6HDjA+f8GztSeISABAPBD17lcp45uHR1dBhzkbN1ZR5dghUXaAAAANghIAAAA\nNghIAAAANghIAAAANghIAAAANghIAAAANghIAAAANghIAAAANghIAAAANghIAAAANghIAAAANghI\nAAAANghIAAAANghIAAAANghIAAAANghIAAAANghIAAAANghIAAAANghIAAAANghIAAAANghIAAAA\nNghIAAAANghIAAAANghIAAAANghIAAAANhwakFavXq3g4GB5enrK09NTYWFh+vDDD43+CRMmyGQy\nWW1RUVFWc1RXVyshIUGdO3eWh4eHYmJiVFxcbDWmrKxMcXFx8vT0lLe3t+Lj43X69OlWOUYAAHDl\ncWhA6tatmxYtWqTc3Fzt379fo0aN0tixY3X48GFjTFRUlE6ePGls77zzjtUcSUlJ2rp1qzZu3Kjd\nu3frxIkTGj9+vNWYuLg4HT58WDt27NC2bdu0Z88eTZ48uVWOEQAAXHmcHbnz++67z+rzyy+/rNWr\nV2vv3r26+eabJUlubm7y9/e/4PfLy8u1du1apaena9SoUZKkdevWKSgoSHv37lVoaKjy8vKUkZGh\nffv2aejQoZKkFStWaMyYMXrttdcUEBDQgkcIAACuRG1mDVJ9fb02bNigqqoqhYWFGe27du2Sr6+v\n+vbtq6efflqlpaVGX25urmpraxUREWG09evXTz169FB2drYkKTs7W97e3kY4kqSIiAg5OTkpJyfn\novXU1NSooqLCagMAANcGh55BkqRDhw4pLCxM1dXV8vDw0ObNm9W/f39J319eGz9+vAIDA3X06FE9\n99xzio6OVnZ2ttq1a6eioiK5urrK29vbak4/Pz8VFRVJkoqKiuTr62vV7+zsLB8fH2PMhSxcuFDz\n5s1r5qMFAABXAocHpL59++rAgQMqLy/Xe++9pyeeeEK7d+9W//79FRsba4wbOHCggoODddNNN2nX\nrl0KDw9v0bpSUlKUnJxsfK6oqFD37t1bdJ8AAKBtcPglNldXV/Xu3VtDhgzRwoULNWjQIC1fvvyC\nY3v16qXrr79e+fn5kiR/f3+dO3dOZrPZalxxcbGxbsnf318lJSVW/XV1dSorK7vo2ibp+7VP5++u\nO78BAIBrg8MDkq2GhgbV1NRcsO/48eMqLS1V165dJUlDhgyRi4uLMjMzjTFHjhxRYWGhsY4pLCxM\nZrNZubm5xpisrCw1NDQoJCSkBY8EAABcqRx6iS0lJUXR0dHq0aOHKisrlZ6erl27dmn79u06ffq0\n5s2bp5iYGPn7++vo0aOaOXOmevfurcjISEmSl5eX4uPjlZycLB8fH3l6emrKlCkKCwtTaGioJCko\nKEhRUVGaNGmS1qxZo9raWiUmJio2NpY72AAAwAU5NCCVlJTo8ccf18mTJ+Xl5aXg4GBt375dd999\nt86ePauDBw/qzTfflNlsVkBAgEaPHq2XXnpJbm5uxhxLly6Vk5OTYmJiVFNTo8jISK1atcpqP2lp\naUpMTFR4eLgxNjU1tbUPFwAAXCFMFovF4ugirgQVFRXy8vJSeXk565EAoBmdrDyplMwUde7QWR3d\nOjq6HDhAZU2lSs+WamH4QnXt2LVZ577cv99tbg0SAACAoxGQAAAAbBCQAAAAbBCQAAAAbBCQAAAA\nbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQ\nAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAA\nbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQ\nAAAAbBCQAAAAbDg0IK1evVrBwcHy9PSUp6enwsLC9OGHHxr9FotFc+bMUdeuXdWhQwdFRETo66+/\ntpqjurpaCQkJ6ty5szw8PBQTE6Pi4mKrMWVlZYqLi5Onp6e8vb0VHx+v06dPt8oxAgCAK49DA1K3\nbt20aNEi5ebmav/+/Ro1apTGjh2rw4cPS5IWL16s1NRUrVmzRjk5OXJ3d1dkZKSqq6uNOZKSkrR1\n61Zt3LhRu3fv1okTJzR+/Hir/cTFxenw4cPasWOHtm3bpj179mjy5MmteqwAAODKYbJYLBZHF/FD\nPj4++s1vfqMnn3xSAQEBmj59umbMmCFJKi8vl5+fn9avX6/Y2FiVl5erS5cuSk9P14MPPihJ+vLL\nLxUUFKTs7GyFhoYqLy9P/fv31759+zR06FBJUkZGhsaMGaPjx48rICDggnXU1NSopqbG+FxRUaHu\n3burvLxcnp6eLfwrAMC142TlSaVkpqhzh87q6NbR0eXAASprKlV6tlQLwxeqa8euzTp3RUWFvLy8\n7P773WbWINXX12vDhg2qqqpSWFiYCgoKVFRUpIiICGOMl5eXQkJClJ2dLUnKzc1VbW2t1Zh+/fqp\nR48expjs7Gx5e3sb4UiSIiIi5OTkpJycnIvWs3DhQnl5eRlb9+7dm/uQAQBAG+XwgHTo0CF5eHjI\nzc1NTz31lDZv3qz+/furqKhIkuTn52c13s/Pz+grKiqSq6urvL29LznG19fXqt/Z2Vk+Pj7GmAtJ\nSUlReXm5sR07duwnHysAALgyODu6gL59++rAgQMqLy/Xe++9pyeeeEK7d+92dFlyc3OTm5ubo8sA\nAAAO4PAzSK6ururdu7eGDBmihQsXatCgQVq+fLn8/f0lqdEdacXFxUafv7+/zp07J7PZfMkxJSUl\nVv11dXUqKyszxgAAAPyQwwOSrYaGBtXU1CgwMFD+/v7KzMw0+ioqKpSTk6OwsDBJ0pAhQ+Ti4mI1\n5siRIyosLDTGhIWFyWw2Kzc31xiTlZWlhoYGhYSEtNJRAQCAK4lDL7GlpKQoOjpaPXr0UGVlpdLT\n07Vr1y5t375dJpNJ06ZN04IFC9SnTx8FBgZq9uzZCggI0Lhx4yR9v2g7Pj5eycnJ8vHxkaenp6ZM\nmaKwsDCFhoZKkoKCghQVFaVJkyZpzZo1qq2tVWJiomJjYy96BxsAALi2OTQglZSU6PHHH9fJkyfl\n5eWl4OBgbd++XXfffbckaebMmaqqqtLkyZNlNps1YsQIZWRkqH379sYcS5culZOTk2JiYlRTU6PI\nyEitWrXKaj9paWlKTExUeHi4MTY1NbVVjxUAAFw52txzkNqqy32OAgDg0ngOEngOEgAAwBWAgAQA\nAGCDgAQAAGCDgAQAAGDD7oCUkZGhjz/+2Pi8cuVK3XLLLfr5z3+uU6dONWtxAAAAjmB3QPrVr36l\niooKSd+/R2369OkaM2aMCgoKlJyc3OwFAgAAtDa7n4NUUFCg/v37S5Lef/993XvvvXrllVf06aef\nasyYMc1eIAAAQGuz+wySq6urzpw5I0n66KOPNHr0aEmSj4+PcWYJAADgSmb3GaQRI0YoOTlZw4cP\n1yeffKI///nPkqSvvvpK3bp1a/YCAQAAWpvdZ5DeeOMNOTs767333tPq1at1ww03SJI+/PBDRUVF\nNXuBAAAArc3uM0g9evTQtm3bGrUvXbq0WQoCAABwNLvPILVr104lJSWN2ktLS9WuXbtmKQoAAMCR\n7A5IF3u3bU1NjVxdXX9yQQAAAI7W5EtsqampkiSTyaQ//OEP8vDwMPrq6+u1Z88e9evXr/krBAAA\naGVNDkjn1xhZLBatWbPG6nKaq6urbrzxRq1Zs6b5KwQAAGhlTQ5IBQUFkqS77rpLmzZtUqdOnVqs\nKAAAAEey+y62nTt3tkQdAAAAbYbdAam+vl7r169XZmamSkpK1NDQYNWflZXVbMUBAAA4gt0BaerU\nqVq/fr3uueceDRgwQCaTqSXqAgAAcBi7A9KGDRv07rvv8mJaAABw1bqsl9X27t27JWoBAABoE+wO\nSNOnT9fy5csv+sBIAACAK53dl9g+/vhj7dy5Ux9++KFuvvlmubi4WPVv2rSp2YoDAABwBLsDkre3\ntx544IGWqAUAAKBNsDsgrVu3riXqAAAAaDPsXoMEAABwtbP7DJIkvffee3r33XdVWFioc+fOWfV9\n+umnzVIYAACAo9h9Bik1NVUTJ06Un5+fPvvsM/2///f/1LlzZ33zzTeKjo5uiRoBAABald0BadWq\nVfrd736nFStWyNXVVTNnztSOHTv07LPPqry8vCVqBAAAaFV2B6TCwkINGzZMktShQwdVVlZKkn7x\ni1/onXfead7qAAAAHMDugOTv76+ysjJJUo8ePbR3715JUkFBAQ+PBAAAVwW7A9KoUaP0wQcfSJIm\nTpyopKQk3X333XrkkUd4PhIAALgq2H0X2+9+9zs1NDRIkhISEtS5c2f94x//0P33369f/vKXzV4g\nAABAa7M7IDk5OcnJ6f9OPMXGxio2NrZZiwIAAHCky3pQ5KlTp/Taa68pPj5e8fHxWrJkibEuyR4L\nFy7Ubbfdpo4dO8rX11fjxo3TkSNHrMZMmDBBJpPJaouKirIaU11dbZzN8vDwUExMjIqLi63GlJWV\nKS4uTp6envL29lZ8fLxOnz5t/8EDAICrnt0Bac+ePQoMDFRqaqpOnTqlU6dOKTU1VYGBgdqzZ49d\nc+3evVsJCQnau3evduzYodraWo0ePVpVVVVW46KionTy5Eljs71bLikpSVu3btXGjRu1e/dunThx\nQuPHj7caExcXp8OHD2vHjh3atm2b9uzZo8mTJ9t7+AAA4Bpg9yW2hIQEPfzww1q9erXatWsnSaqv\nr9czzzyjhIQEHTp0qMlzZWRkWH1ev369fH19lZubqzvuuMNod3Nzk7+//wXnKC8v19q1a5Wenq5R\no0ZJ+v59cUFBQdq7d69CQ0OVl5enjIwM7du3T0OHDpUkrVixQmPGjNFrr72mgIAAu34DAABwdbP7\nDFJ+fr6mT59uhCNJateunZKTk5Wfn/+Tijn/oEkfHx+r9l27dsnX11d9+/bV008/rdLSUqMvNzdX\ntbW1ioiIMNr69eunHj16KDs7W5KUnZ0tb29vIxxJUkREhJycnJSTk3PBWmpqalRRUWG1AQCAa4Pd\nAWnw4MG9bO1mAAAgAElEQVTKy8tr1J6Xl6dBgwZddiENDQ2aNm2ahg8frgEDBhjtUVFReuutt5SZ\nmalXX31Vu3fvVnR0tOrr6yVJRUVFcnV1lbe3t9V8fn5+KioqMsb4+vpa9Ts7O8vHx8cYY2vhwoXy\n8vIytu7du1/2sQEAgCuL3ZfYnn32WU2dOlX5+fkKDQ2VJO3du1crV67UokWLdPDgQWNscHBwk+dN\nSEjQF198oY8//tiq/Yd3yA0cOFDBwcG66aabtGvXLoWHh9tbfpOlpKQoOTnZ+FxRUUFIAgDgGmF3\nQHr00UclSTNnzrxgn8lkksVikclkMs7y/JjExERj4XS3bt0uObZXr166/vrrlZ+fr/DwcPn7++vc\nuXMym81WZ5GKi4uNdUv+/v4qKSmxmqeurk5lZWUXXdvk5uYmNze3JtUPAACuLnYHpIKCgmbbucVi\n0ZQpU7R582bt2rVLgYGBP/qd48ePq7S0VF27dpUkDRkyRC4uLsrMzFRMTIwk6ciRIyosLFRYWJgk\nKSwsTGazWbm5uRoyZIgkKSsrSw0NDQoJCWm24wEAAFcHuwNSz549m23nCQkJSk9P11/+8hd17NjR\nWA/k5eWlDh066PTp05o3b55iYmLk7++vo0ePaubMmerdu7ciIyONsfHx8UpOTpaPj488PT01ZcoU\nhYWFGZcAg4KCFBUVpUmTJmnNmjWqra1VYmKiYmNjuYMNAAA00qSA9MEHHyg6OlouLi7Ge9gu5v77\n72/yzlevXi1JGjlypFX7unXrNGHCBLVr104HDx7Um2++KbPZrICAAI0ePVovvfSS1eWvpUuXysnJ\nSTExMaqpqVFkZKRWrVplNWdaWpoSExMVHh5ujE1NTW1yrQAA4Nphslgslh8b5OTkZNwJ9sPXjDSa\nzI51R1eaiooKeXl5qby8XJ6eno4uBwCuGicrTyolM0WdO3RWR7eOji4HDlBZU6nSs6VaGL5QXTt2\nbda5L/fvd5POIJ1/Oa3tvwEAAK5Gl/UuNgAAgKuZ3QHp2Wef1RtvvNGo/Y033tC0adOapSgAAABH\nsjsgvf/++xoxYkSj9mHDhum9995rlqIAAAAcye6AVFpaqo4dGy+i8/T01HfffdcsRQEAADiS3QGp\nd+/e+vDDDxu1f/jhh+rVq1ezFAUAAOBIdj8oMjk5WYmJifr22281atQoSVJmZqaWLFmiZcuWNXuB\nAAAArc3ugPTkk0+qpqZGL7/8sl566SVJ0o033qjVq1fr8ccfb/YCAQAAWpvdAUmSnn76aT399NP6\n9ttv1aFDB3l4eDR3XQAAAA5zWQHpvC5dujRXHQAAAG1GkwLS4MGDlZmZqU6dOunWW2+VyWS66NhP\nP/202YoDAABwhCYFpLFjxxovhx07duwlAxIAAMCVrkkBae7cuca/X3zxxZaqBQAAoE2w+zlIvXr1\nUmlpaaN2s9nMc5AAAMBVwe6A9K9//Uv19fWN2mtqanT8+PFmKQoAAMCRmnwX2wcffGD8e/v27fLy\n8jI+19fXKzMzU4GBgc1bHQAAgAM0OSCNGzfO+PcTTzxh1efi4qIbb7xRS5Ysab7KAAAAHKTJAamh\noUGSFBgYqP3796tz584tVhQAAIAj2bUGqba2Vr169VJZWVlL1QMAAOBwdgUkFxcXHTx4sKVqAQAA\naBPsvovtscce09q1a1uiFgAAgDbB7nex1dXV6Y9//KM++ugjDRkyRO7u7lb9r7/+erMVBwAA4Ah2\nB6QvvvhCgwcPliR99dVXVn28ggQAAFwN7A5IO3fubIk6AAAA2gy71yABAABc7ew+gyRJ+/fv17vv\nvqvCwkKdO3fOqm/Tpk3NUhgAAICj2H0GacOGDRo2bJjy8vK0efNm1dbW6vDhw8rKyrJ6/QgAAMCV\nyu6A9Morr2jp0qXaunWrXF1dtXz5cn355Zd6+OGH1aNHj5aoEQAAoFXZfYnt6NGjuueeeyRJrq6u\nqqqqkslkUlJSkkaNGqV58+Y1e5FXvfJy6cwZR1cBR7ruOokzsADQZtgdkDp16qTKykpJ0g033KAv\nvvhCAwcOlNls1hn+yNuvvFx66SXpu+8cXQkc6frrpdmzCUkA0EbYHZDuuOMO7dixQwMHDtRDDz2k\nqVOnKisrSzt27FB4eHhL1Hh1O3Pm+3DUocP3ZxFw7Tn/38CZMwQkAGgj7A5Ib7zxhqqrqyVJzz//\nvFxcXPSPf/xDMTExeuGFF5q9wGvGdddJHTs6ugo4ytmzjq4AAPADdgckHx8f499OTk6aNWtWsxYE\nAADgaE2+i62hoUGLFy/W8OHDddttt2nWrFk6y//rBQAAV6EmB6SXX35Zzz33nDp27KgbbrhBy5cv\nV0JCQkvWBgAA4BBNDkhvvfWWVq1apYyMDG3ZskVbt25VWlqaGhoaLnvnCxcu1G233aaOHTvK19dX\n48aN05EjR6zGWCwWzZkzR127dlWHDh0UERGhr7/+2mpMdXW1EhIS1LlzZ3l4eCgmJkbFxcVWY8rK\nyhQXFydPT095e3srPj5ep0+fvuzaAQDA1avJAamwsFDR0dHG54iICJlMJp04ceKyd757924lJCRo\n79692rFjh2prazV69GhVVVUZYxYvXqzU1FStWbNGOTk5cnd3V2RkpLFQXJKSkpK0detWbdy4Ubt3\n79aJEyc0fvx4q33FxcXp8OHD2rFjh7Zt26Y9e/Zo8uTJl107AAC4ejV5kXZdXZ3at29v1ebi4qLa\n2trL3nlGRobV5/Xr18vX11e5ubm64447ZLFYtGzZMr3wwgsaO3aspO/PZPn5+WnLli2KjY1VeXm5\n1q5dq/T0dI0aNUqStG7dOgUFBWnv3r0KDQ1VXl6eMjIytG/fPg0dOlSStGLFCo0ZM0avvfaaAgIC\nLvsYAADA1afJAclisWjChAlyc3Mz2qqrq/XUU0/J3d3daPspL6stLy+X9H93yhUUFKioqEgRERHG\nGC8vL4WEhCg7O1uxsbHKzc1VbW2t1Zh+/fqpR48eys7OVmhoqLKzs+Xt7W2EI+n7M2BOTk7KycnR\nAw880KiWmpoa1dTUGJ8rKiou+7gAAMCVpckB6YknnmjU9thjjzVbIQ0NDZo2bZqGDx+uAQMGSJKK\niookSX5+flZj/fz8jL6ioiK5urrK29v7kmN8fX2t+p2dneXj42OMsbVw4UJemwIAwDWqyQFp3bp1\nLVmHEhIS9MUXX+jjjz9u0f00VUpKipKTk43PFRUV6t69uwMrAgAAraXJi7RbUmJiorZt26adO3eq\nW7duRru/v78kNbojrbi42Ojz9/fXuXPnZDabLzmmpKTEqr+urk5lZWXGGFtubm7y9PS02gAAwLXB\noQHJYrEoMTFRmzdvVlZWlgIDA636AwMD5e/vr8zMTKOtoqJCOTk5CgsLkyQNGTJELi4uVmOOHDmi\nwsJCY0xYWJjMZrNyc3ONMVlZWWpoaFBISEhLHiIAALgC2f2qkeaUkJCg9PR0/eUvf1HHjh2N9UBe\nXl7q0KGDTCaTpk2bpgULFqhPnz4KDAzU7NmzFRAQoHHjxhlj4+PjlZycLB8fH3l6emrKlCkKCwtT\naGioJCkoKEhRUVGaNGmS1qxZo9raWiUmJio2NpY72AAAQCMODUirV6+WJI0cOdKqfd26dZowYYIk\naebMmaqqqtLkyZNlNps1YsQIZWRkWD1yYOnSpXJyclJMTIxqamoUGRmpVatWWc2ZlpamxMREhYeH\nG2NTU1Nb9PgAAMCVqUkBafDgwcrMzFSnTp00f/58zZgxQ9ddd91P3rnFYvnRMSaTSfPnz9f8+fMv\nOqZ9+/ZauXKlVq5cedExPj4+Sk9Pv6w6AQDAtaVJa5Dy8vKMp1vPmzePV3QAAICrWpPOIN1yyy2a\nOHGiRowYIYvFotdee00eHh4XHDtnzpxmLRAAAKC1NSkgrV+/XnPnztW2bdtkMpn04Ycfytm58VdN\nJhMBCQAAXPGaFJD69u2rDRs2SJKcnJyUmZnZ6MnUAAAAVwu772JraGhoiToAAADajMu6zf/o0aNa\ntmyZ8vLyJEn9+/fX1KlTddNNNzVrcQAAAI5g95O0t2/frv79++uTTz5RcHCwgoODlZOTo5tvvlk7\nduxoiRoBAABald1nkGbNmqWkpCQtWrSoUfuvf/1r3X333c1WHAAAgCPYfQYpLy9P8fHxjdqffPJJ\n/fOf/2yWogAAABzJ7oDUpUsXHThwoFH7gQMHuLMNAABcFey+xDZp0iRNnjxZ33zzjYYNGyZJ+vvf\n/65XX31VycnJzV4gAABAa7M7IM2ePVsdO3bUkiVLlJKSIkkKCAjQiy++qGeffbbZCwQAAGhtdgck\nk8mkpKQkJSUlqbKyUpLUsWPHZi8MAADAUS7rOUjnEYwAAMDVyO5F2gAAAFc7AhIAAIANAhIAAIAN\nuwJSbW2twsPD9fXXX7dUPQAAAA5nV0BycXHRwYMHW6oWAACANsHuS2yPPfaY1q5d2xK1AAAAtAl2\n3+ZfV1enP/7xj/roo480ZMgQubu7W/W//vrrzVYcAACAI9gdkL744gsNHjxYkvTVV19Z9ZlMpuap\nCgAAwIHsDkg7d+5siToAAADajMu+zT8/P1/bt2/X2bNnJUkWi6XZigIAAHAkuwNSaWmpwsPD9bOf\n/UxjxozRyZMnJUnx8fGaPn16sxcIAADQ2uwOSElJSXJxcVFhYaGuu+46o/2RRx5RRkZGsxYHAADg\nCHavQfrb3/6m7du3q1u3blbtffr00b///e9mKwwAAMBR7D6DVFVVZXXm6LyysjK5ubk1S1EAAACO\nZHdAuv322/XWW28Zn00mkxoaGrR48WLdddddzVocAACAI9h9iW3x4sUKDw/X/v37de7cOc2cOVOH\nDx9WWVmZ/v73v7dEjQAAAK3K7jNIAwYM0FdffaURI0Zo7Nixqqqq0vjx4/XZZ5/ppptuaokaAQAA\nWpXdZ5AkycvLS88//3xz1wIAANAmXFZAOnXqlNauXau8vDxJUv/+/TVx4kT5+Pg0a3EAAACOYPcl\ntj179ujGG29UamqqTp06pVOnTik1NVWBgYHas2dPS9QIAADQquw+g5SQkKBHHnlEq1evVrt27SRJ\n9fX1euaZZ5SQkKBDhw41e5EAAACtye4zSPn5+Zo+fboRjiSpXbt2Sk5OVn5+vl1z7dmzR/fdd58C\nAgJkMpm0ZcsWq/4JEybIZDJZbVFRUVZjqqurlZCQoM6dO8vDw0MxMTEqLi62GlNWVqa4uDh5enrK\n29tb8fHxOn36tJ1HDgAArhV2n0EaPHiw8vLy1LdvX6v2vLw8DRo0yK65qqqqNGjQID355JMaP378\nBcdERUVp3bp1xmfbh1EmJSXpr3/9qzZu3CgvLy8lJiZq/PjxVo8ciIuL08mTJ7Vjxw7V1tZq4sSJ\nmjx5stLT0+2qF7hq1ZVL9WccXQUcqd11krOXo6sA2owmBaSDBw8a/3722Wc1depU5efnKzQ0VJK0\nd+9erVy5UosWLbJr59HR0YqOjr7kGDc3N/n7+1+wr7y8XGvXrlV6erpGjRolSVq3bp2CgoK0d+9e\nhYaGKi8vTxkZGdq3b5+GDh0qSVqxYoXGjBmj1157TQEBAXbVDFx16sqlf70k1X7n6ErgSC7XSzfO\nJiQB/6tJAemWW26RyWSSxWIx2mbOnNlo3M9//nM98sgjzVedpF27dsnX11edOnXSqFGjtGDBAnXu\n3FmSlJubq9raWkVERBjj+/Xrpx49eig7O1uhoaHKzs6Wt7e3EY4kKSIiQk5OTsrJydEDDzxwwf3W\n1NSopqbG+FxRUdGsxwW0GfVnvg9HTh0kp8avEcI1oOF//xuoP0NAAv5XkwJSQUFBS9dxQVFRURo/\nfrwCAwN19OhRPffcc4qOjlZ2drbatWunoqIiubq6ytvb2+p7fn5+KioqkiQVFRXJ19fXqt/Z2Vk+\nPj7GmAtZuHCh5s2b1/wHBbRVTtdJzh0dXQUcoU5Sw1lHVwG0KU0KSD179mzpOi4oNjbW+PfAgQMV\nHBysm266Sbt27VJ4eHiL7jslJUXJycnG54qKCnXv3r1F9wkAANqGy3pQ5IkTJ/Txxx+rpKREDQ0N\nVn3PPvtssxR2Ib169dL111+v/Px8hYeHy9/fX+fOnZPZbLY6i1RcXGysW/L391dJSYnVPHV1dSor\nK7vo2ibp+7VPtgvCAQDAtcHugLR+/Xr98pe/lKurqzp37iyTyWT0mUymFg1Ix48fV2lpqbp27SpJ\nGjJkiFxcXJSZmamYmBhJ0pEjR1RYWKiwsDBJUlhYmMxms3JzczVkyBBJUlZWlhoaGhQSEtJitQIA\ngCuX3QFp9uzZmjNnjlJSUuTkZPdjlKycPn3a6tlJBQUFOnDggHx8fOTj46N58+YpJiZG/v7+Onr0\nqGbOnKnevXsrMjJS0vfvhIuPj1dycrJ8fHzk6empKVOmKCwszLjDLigoSFFRUZo0aZLWrFmj2tpa\nJSYmKjY2ljvYAADABdkdkM6cOaPY2NifHI4kaf/+/brrrruMz+fX/DzxxBNavXq1Dh48qDfffFNm\ns1kBAQEaPXq0XnrpJatLX0uXLpWTk5NiYmJUU1OjyMhIrVq1ymo/aWlpSkxMVHh4uDE2NTX1J9cP\nAACuTnYHpPj4eG3cuFGzZs36yTsfOXKk1aMDbG3fvv1H52jfvr1WrlyplStXXnSMj48PD4UEAABN\nZndAWrhwoe69915lZGRo4MCBcnFxsep//fXXm604AAAAR7isgLR9+3bjVSO2i7QBAACudHYHpCVL\nluiPf/yjJkyY0ALlAAAAOJ7dK63d3Nw0fPjwlqgFAACgTbA7IE2dOlUrVqxoiVoAAADaBLsvsX3y\nySfKysrStm3bdPPNNzdapL1p06ZmKw4AAMAR7A5I3t7eGj9+fEvUAgAA0CbYHZDWrVvXEnUAAAC0\nGT/9cdgAAABXGbvPIAUGBl7yeUfffPPNTyoIAADA0ewOSNOmTbP6XFtbq88++0wZGRn61a9+1WyF\nAQAAOIrdAWnq1KkXbF+5cqX279//kwsCAABwtGZbgxQdHa3333+/uaYDAABwmGYLSO+99558fHya\nazoAAACHsfsS26233mq1SNtisaioqEjffvutVq1a1azFAQAAOILdAWncuHFWn52cnNSlSxeNHDlS\n/fr1a7bCAAAAHMXugDR37tyWqAMAAKDN4EGRAAAANpp8BsnJyemSD4iUJJPJpLq6up9cFAAAgCM1\nOSBt3rz5on3Z2dlKTU1VQ0NDsxQFAADgSE0OSGPHjm3UduTIEc2aNUtbt25VXFyc5s+f36zFAQAA\nOMJlrUE6ceKEJk2apIEDB6qurk4HDhzQm2++qZ49ezZ3fQAAAK3OroBUXl6uX//61+rdu7cOHz6s\nzMxMbd26VQMGDGip+gAAAFpdky+xLV68WK+++qr8/f31zjvvXPCSGwAAwNWgyQFp1qxZ6tChg3r3\n7q0333xTb7755gXHbdq0qdmKAwAAcIQmB6THH3/8R2/zBwAAuBo0OSCtX7++BcsAAABoO3iSNgAA\ngA0CEgAAgA0CEgAAgA0CEgAAgA0CEgAAgA0CEgAAgA0CEgAAgA0CEgAAgA2HBqQ9e/bovvvuU0BA\ngEwmk7Zs2WLVb7FYNGfOHHXt2lUdOnRQRESEvv76a6sx1dXVSkhIUOfOneXh4aGYmBgVFxdbjSkr\nK1NcXJw8PT3l7e2t+Ph4nT59usWPDwAAXJkcGpCqqqo0aNAgrVy58oL9ixcvVmpqqtasWaOcnBy5\nu7srMjJS1dXVxpikpCRt3bpVGzdu1O7du3XixAmNHz/eap64uDgdPnxYO3bs0LZt27Rnzx5Nnjy5\nRY8NAABcuZr8qpGWEB0drejo6Av2WSwWLVu2TC+88ILGjh0rSXrrrbfk5+enLVu2KDY2VuXl5Vq7\ndq3S09M1atQoSdK6desUFBSkvXv3KjQ0VHl5ecrIyNC+ffs0dOhQSdKKFSs0ZswYvfbaawoICGid\ngwUAAFeMNrsGqaCgQEVFRYqIiDDavLy8FBISouzsbElSbm6uamtrrcb069dPPXr0MMZkZ2fL29vb\nCEeSFBERIScnJ+Xk5Fx0/zU1NaqoqLDaAADAtaHNBqSioiJJkp+fn1W7n5+f0VdUVCRXV1d5e3tf\ncoyvr69Vv7Ozs3x8fIwxF7Jw4UJ5eXkZW/fu3X/yMQEAgCtDmw1IjpaSkqLy8nJjO3bsmKNLAgAA\nraTNBiR/f39JanRHWnFxsdHn7++vc+fOyWw2X3JMSUmJVX9dXZ3KysqMMRfi5uYmT09Pqw0AAFwb\n2mxACgwMlL+/vzIzM422iooK5eTkKCwsTJI0ZMgQubi4WI05cuSICgsLjTFhYWEym83Kzc01xmRl\nZamhoUEhISGtdDQAAOBK4tC72E6fPq38/Hzjc0FBgQ4cOCAfHx/16NFD06ZN04IFC9SnTx8FBgZq\n9uzZCggI0Lhx4yR9v2g7Pj5eycnJ8vHxkaenp6ZMmaKwsDCFhoZKkoKCghQVFaVJkyZpzZo1qq2t\nVWJiomJjY7mDDQAAXJBDA9L+/ft11113GZ+Tk5MlSU888YTWr1+vmTNnqqqqSpMnT5bZbNaIESOU\nkZGh9u3bG99ZunSpnJycFBMTo5qaGkVGRmrVqlVW+0lLS1NiYqLCw8ONsampqa1zkAAA4Irj0IA0\ncuRIWSyWi/abTCbNnz9f8+fPv+iY9u3ba+XKlRd92KQk+fj4KD09/SfVCgAArh1tdg0SAACAoxCQ\nAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAA\nbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQ\nAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAA\nbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbBCQAAAAbLTpgPTiiy/KZDJZbf369TP6LRaL5syZo65d\nu6pDhw6KiIjQ119/bTVHdXW1EhIS1LlzZ3l4eCgmJkbFxcWtfSgAAOAK0qYDkiTdfPPNOnnypLF9\n/PHHRt/ixYuVmpqqNWvWKCcnR+7u7oqMjFR1dbUxJikpSVu3btXGjRu1e/dunThxQuPHj3fEoQAA\ngCuEs6ML+DHOzs7y9/dv1G6xWLRs2TK98MILGjt2rCTprbfekp+fn7Zs2aLY2FiVl5dr7dq1Sk9P\n16hRoyRJ69atU1BQkPbu3avQ0NCL7rempkY1NTXG54qKimY+MgAA0Fa1+TNIX3/9tQICAtSrVy/F\nxcWpsLBQklRQUKCioiJFREQYY728vBQSEqLs7GxJUm5urmpra63G9OvXTz169DDGXMzChQvl5eVl\nbN27d2+BowMAAG1Rmw5IISEhWr9+vTIyMrR69WoVFBTo9ttvV2VlpYqKiiRJfn5+Vt/x8/Mz+oqK\niuTq6ipvb++LjrmYlJQUlZeXG9uxY8ea8cgAAEBb1qYvsUVHRxv/Dg4OVkhIiHr27Kl3331XQUFB\nLbpvNzc3ubm5teg+AABA29SmzyDZ8vb21s9+9jPl5+cb65Js70grLi42+vz9/XXu3DmZzeaLjgEA\nALB1RQWk06dPKz8/X127dlVgYKD8/f2VmZlp9FdUVCgnJ0dhYWGSpCFDhsjFxcVqzJEjR1RYWGiM\nAQAAsNWmL7HNmDFD9913n3r27KkTJ05o7ty5cnZ21qOPPiqTyaRp06ZpwYIF6tOnjwIDAzV79mwF\nBARo3Lhxkr5ftB0fH6/k5GT5+PjI09NTU6ZMUVhY2CXvYAMAANe2Nh2Qjh8/rkcffVSlpaXq0qWL\nRowYob1796pLly6SpJkzZ6qqqkqTJ0+W2WzWiBEjlJGRofbt2xtzLF26VE5OToqJiVFNTY0iIyO1\natUqRx0SAAC4ArTpgLRhw4ZL9ptMJs2fP1/z58+/6Jj27dtr5cqVWrlyZXOXBwAArlJX1BokAACA\n1kBAAgAAsEFAAgAAsEFAAgAAsEFAAgAAsEFAAgAAsEFAAgAAsEFAAgAAsEFAAgAAsEFAAgAAsEFA\nAgAAsEFAAgAAsEFAAgAAsEFAAgAAsEFAAgAAsEFAAgAAsEFAAgAAsEFAAgAAsEFAAgAAsEFAAgAA\nsEFAAgAAsEFAAgAAsEFAAgAAsEFAAgAAsEFAAgAAsEFAAgAAsEFAAgAAsEFAAgAAsEFAAgAAsEFA\nAv5/e3ceFsWR/gH8C4wzgzCAgggKjgcjxAsVowKJGi9EwIusGhER47XreqFoWFAUDzwwiHdURFER\nr3ghG1fBA8V4gBwKQkTwxBuEgMIC7+8Pl/7RcwgYcUisz/PwPEz1213VPTU11dXVPQzDMAwjh3WQ\nGIZhGIZh5LAOEsMwDMMwjBzWQWIYhmEYhpHDOkgMwzAMwzByPqsO0saNG9GyZUuIxWL06NEDV69e\nVXeRGIZhGIaphz6bDtL+/fvh5eUFf39/JCYmwtraGg4ODnj27Jm6i8YwDMMwTD3z2XSQfvzxR0ya\nNAmenp5o164dtmzZgoYNG2LHjh3qLhrDMAzDMPWMQN0F+BRKS0uRkJAAHx8fLk1TUxP9+/fH5cuX\nla5TUlKCkpIS7vXr168BAAUFBR+3cIWFQGkpkJ8PVMmP+Yy8efOuDhQWAjo6nz7/kkLg91JAMx/Q\nZHXws1TxBqgoBQoKAdGnr4OFhYUoLS5Ffmk+SgSsDn6O3pS9QWlZKQoLCqFDH7cOVn5vE1Gt1vss\nOkgvXrxAeXk5mjZtyktv2rQpbt++rXSdwMBALF68WCHd3Ny8TsrIMNi3T90lYD57rA4y6rWvDutg\nYWEh9PX1axz/WXSQPoSPjw+8vLy41xUVFXj16hUMDQ2hoaGhxpL99RQUFMDc3BwPHjyAnp6euovD\nfHNdO2wAABlNSURBVIZYHWTUjdXBukNEKCwsRLNmzWq13mfRQTIyMoKWlhaePn3KS3/69ClMTEyU\nriMSiSASiXhpBgYGdVZGBtDT02MNA6NWrA4y6sbqYN2ozchRpc9ikrZQKISNjQ1iYmK4tIqKCsTE\nxMDW1laNJWMYhmEYpj76LEaQAMDLywseHh7o1q0bunfvjrVr16KoqAienp7qLhrDMAzDMPWM1qJF\nixapuxCfQocOHWBgYIBly5YhKCgIALB3715YWlqquWQMAGhpaaFPnz4QCD6bPjtTz7A6yKgbq4P1\niwbV9r43hmEYhmGYv7jPYg4SwzAMwzBMbbAOEsMwDMMwjBzWQWIYhmEYhpHDOkgMwzAMwzByWAdJ\nzTQ0NHD06NGPus1Fixahc+fOCmlNmzbl8hs/fjyGDRv2UfP9lM6dOwcNDQ3k5+d/1NiqXr58CWNj\nY+Tk5HxgKT+Onj174vDhw2otQ13o06cPZs2a9dFjq1qwYAEmT55c6/U+B2lpaTAzM0NRUZG6i8L8\nT02+D1i79AkRU2eePXtGU6dOJXNzcxIKhdS0aVMaOHAgXbx4kYvJzc2lt2/fftR8CwsL6cWLF9zr\ntLQ0AkBHjhzh8svPz6e8vLyPmm91evfuTTNnzqxRHAACQCKRiGQyGS1fvpwqKiq4mJKSEsrNzeWl\nqXL27FkCUOv9nT17Nk2cOLFW61R1+PBhsrGxIX19fWrYsCFZW1tTeHg4L6asrIz8/PyoZcuWJBaL\nqXXr1hQQEMDbrxMnTpCFhQWVl5d/cFlqKj4+njQ1NWnw4MEKy2p6HCvjKv+MjIzI0dGRUlJSeHEv\nX76kgoKCGpWrpnWnqtzcXJJIJJSTk1Or9ZR5+/YtWVtbEwC6ceMGl/7ixQtycHAgU1NTEgqFZGZm\nRtOmTaPXr1//4TzfZ/LkydS6dWsSi8VkZGREQ4YMofT0dF5MRkYGDRkyhAwNDUkikZC9vT3Fxsby\nYlxdXSkgIKBOy/qpeXh4EAAKDAzkpR85coTq+1deZTv9Pn+0Xapq3759BICGDh3KS9+0aRN17NiR\nJBIJSSQS6tmzJ0VHR/NiPmW7pC5sBKkOubq64saNG9i1axcyMzNx/Phx9OnTBy9fvuRiTExMFH7S\n5I/S1dWFoaEh9zorKwsAMHToUC4/fX39ev3TKZMmTUJubi4yMjLg4+ODhQsXYsuWLdxyoVAIExOT\nOvtdvOLiYoSGhuL777+v1XoPHjzg/m/cuDF8fX1x+fJlpKSkwNPTE56enjh16hQXs3LlSmzevBkb\nNmxAeno6Vq5ciVWrVmH9+vVcjKOjIwoLC/Hvf//7j+9YNUJDQzF9+nRcuHABjx8//kPbysjIQG5u\nLk6dOoWSkhI4OTmhtLSUW964cWNIJJI/WmSVtm/fDjs7O0il0hqvk5eXh99//10hfd68eUp/x0lT\nUxNDhw7F8ePHkZmZiZ07d+LMmTOYOnVqrcr6/PlzvH37tsbxNjY2CAsLQ3p6Ok6dOgUiwsCBA1Fe\nXs7FODs7o6ysDLGxsUhISIC1tTWcnZ3x5MkTLsbT0xObN29GWVlZrcpb34nFYqxcuRJ5eXkfdbtV\n6686qGqX7t+/X+tt5eTkYO7cufj6668VlpmZmWHFihVISEjA9evX0bdvXwwdOhS3bt3iYj5lu6Q2\n6u6h/VXl5eURADp37tx74yB3xnDp0iWytrYmkUhEX375JR07dox31lp5dn7mzBmysbEhbW1tsrW1\npdu3b3Pb8Pf3J2tra+5/VDmbr3zLPTw8eGcN5eXltHLlSmrTpg0JhUIyNzenpUuXcsvnzZtHMpmM\ntLW1qVWrVuTn50elpaUKeYaHh5NUKiU9PT0aNWoUN0JQeVZX9S87O1vpMVE2WmBjY0PDhw/nXsuP\nZuTk5JCzszMZGBhQw4YNqV27dnTy5EmlsUVFRTRo0CCys7NTORpy8OBBatKkidJl8u7du0dLly4l\nmUxGw4YNe29sly5dyM/Pj3vt5OREEyZM4MWMGDGC3NzceGmenp40duzYGpXnQxUWFpKuri7dvn2b\nRo0aRcuWLeOWZWdnK7x/Hh4eSrejbKTpxIkTBICSk5O5NPn3eePGjWRhYUEikYiMjY3J1dVVZWxU\nVBTp6enRnj17VO5P+/btacOGDdXu93//+1+Kioqib7/9lkQiESUlJfGWR0dHk5WVFd26dUthBEmZ\nkJAQMjMzqzbfqnbu3EkGBgY0ZcoUio+Pr9W6RETJyckEgO7cuUNERM+fPycAdOHCBS6moKCAANDp\n06e5tJKSEhKJRHTmzJla51lfeXh4kLOzM1lZWZG3tzeXrmwE6dChQ9SuXTsSCoUklUopKCiIt1wq\nlVJAQAC5u7uTRCIhDw8P7rOwf/9++uqrr0gsFlO3bt0oIyODrl69SjY2NqSjo0ODBg2iZ8+ecdu6\nevUq9e/fnwwNDUlPT4969epFCQkJvPzkvw/kqWqXNDU1qV+/fhQeHk5FRUXVHqOysjKys7Oj7du3\nK3wXqNKoUSPavn07L+1TtEvqxEaQ6oiuri50dXVx9OhRlJSU1GidgoICuLi4oGPHjkhMTMTixYsx\nb948pbG+vr5Ys2YNrl+/DoFAgAkTJiiNmzt3LsLCwgAAubm5yM3NVRrn4+ODFStWYMGCBUhLS8P+\n/ft5P+QrkUiwc+dOpKWlISQkBNu2bUNwcDBvG1lZWTh69CiioqIQFRWF8+fPY8WKFQCAkJAQ2Nra\nciNDubm5MDc3r/aYEBHi4uKQnp4OoVCoMm7atGkoKSnBhQsXkJqaipUrV0JXV1chLj8/HwMGDEBF\nRQVOnz6tchQtLi4ONjY2KvMrKirC7t270b9/f7Rq1QrR0dGYM2cOduzYoXI/YmJikJGRgV69enHp\ndnZ2iImJQWZmJgAgOTkZFy9ehKOjI2/97t27Iy4uTmV5PoYDBw7AysoKlpaWGDt2LHbs2AH633Nk\nzc3NufkGlSNDISEhNdru69evERERAQAq38Pr169jxowZCAgIQEZGBn755RfecaoqIiIC3333Hfbu\n3Qs3NzelMa9evUJaWhq6deumslypqamYM2cOzMzMMG7cODRp0gRnz56FtbU1F/P06VNMmjQJu3fv\nRsOGDavd18ePH+Pnn39G7969q42tys3NDXv27EFeXh769u0LS0tLLF++nDciqUpRURHCwsLQqlUr\n7jNlaGgIS0tLhIeHo6ioCGVlZdiyZQuMjY159VooFKJz5851Xrc+NS0tLSxfvhzr16/Hw4cPlcYk\nJCRg5MiRGD16NFJTU7Fo0SIsWLAAO3fu5MUFBQXB2toaN27cwIIFC7h0f39/+Pn5ITExEQKBAGPG\njMG8efMQEhKCuLg43LlzBwsXLuTiCwsL4eHhgYsXL+LXX3+FTCbD4MGDUVhYWOP9UtUupaWloXv3\n7vDz80PTpk0xYcIEnD9/nvv8ygsICICxsXGNRsjLy8sRGRmJoqIihd8u/RTtklqpt3/213bo0CFq\n1KgRicVisrOzIx8fH94ZNBH/jGHz5s1kaGhIb9684ZZv27ZN5QhSpZMnTxIAbr2qI0hEys+cqp41\nFBQUkEgkom3bttV431avXk02Njbca39/f2rYsCFvTom3tzf16NGDe12bOUgNGjQgHR0datCgAQEg\nsVhMly5d4mLkRyk6duxIixYtUrq9ytj09HTq1KkTubq6UklJyXvLMHToUIWRHSKic+fOkaenJ+nq\n6lLr1q1p4cKF3Fm7Mvn5+aSjo0MCgYBEIhGFhobylpeXl9P8+fNJQ0ODBAIBaWho0PLlyxW2c+zY\nMdLU1KzT6/12dna0du1aIno3qmJkZERnz57lltd2DpKOjg7p6OhwI05DhgzhxVWtD4cPHyY9PT2V\nc5IqYzds2ED6+vrVjszeuHGDAND9+/d56S9evKC1a9dSly5dSCgU0rBhw+jw4cNK60NFRQUNGjSI\nlixZQkT/P4qmbARp9OjRpK2tTQDIxcWF9xmurfz8fNq6dSt9/fXXpKWlxY0MFBcX8+I2btzIHV9L\nS0uFevjgwQOysbEhDQ0N0tLSIlNTU0pMTFTIb/jw4TR+/PgPLm99U7Vt69mzJ/c5lm8Hx4wZQwMG\nDOCt6+3tTe3ateNeS6VShVHhynpQdTSlci5PTEwMlxYYGEiWlpYqy1leXk4SiYROnDjBpaGaESRV\n7VKliooKio2NpfHjx5NEIqFWrVqRv78/3b17l4uJi4uj5s2b0/Pnz4lI8WpCpZSUFNLR0SEtLS3S\n19fnRuSr+hTtkjqxEaQ65OrqisePH+P48eMYNGgQzp07h65duyqcoVTKyMhAp06dIBaLubTu3bsr\nje3UqRP3v6mpKQDg2bNnH1TO9PR0lJSUoF+/fipj9u/fD3t7e5iYmEBXVxd+fn4K171btmzJm1Ni\namr6wWVyc3NDUlISLl26BEdHR/j6+sLOzk5l/IwZM7B06VLY29vD398fKSkpCjEDBgyAhYUF9u/f\n/97RKAB48+YN732o1KdPH0RGRiIoKAhZWVlYvHgx2rRpo3I7EokESUlJuHbtGpYtWwYvLy+cO3eO\nW37gwAHs3bsXERERSExMxK5duxAUFIRdu3bxtqOtrY2Kiooaj0bWVkZGBq5evYrvvvsOACAQCDBq\n1CiEhoZ+8Dbj4uKQkJCAnTt3om3btrw5ZPIGDBgAqVSK1q1bw93dHXv37kVxcTEv5tChQ5g9ezZO\nnz5d7QjNmzdvAEDhPVy/fj1mzZoFXV1d3LlzB0eOHMGIESOU1of169ejsLAQPj4+1e5rcHAwEhMT\ncezYMWRlZcHLy6vadVTR19fHpEmTcOHCBcTHxyM7Oxvjxo3jzV0D3n1Gbty4gfPnz6Nt27YYOXIk\nN4+JiDBt2jQYGxsjLi4OV69exbBhw+Di4qIwiqytra1wrP8qVq5ciV27diE9PV1hWXp6Ouzt7Xlp\n9vb2+O2333hzuVSNQlZtg5s2bQoA6NixIy+tavtXORopk8mgr68PPT09/P7777WaP6SqXaqkoaGB\nb775BmFhYXj48CFsbW2xePFizJ49G8C7USx3d3ds27YNRkZG783L0tISSUlJuHLlCv7+97/Dw8MD\naWlpvJi6bpfUjXWQ6phYLMaAAQOwYMECxMfHY/z48fD39//D223QoAH3f+VE5YqKig/alra29nuX\nX758GW5ubhg8eDCioqJw48YN+Pr6KkxYrFqmynJ9aJn09fVhYWGBL7/8EgcOHMCGDRtw5swZlfET\nJ07E3bt34e7ujtTUVHTr1o030RkAnJyccOHCBYUPuTJGRkZKJ3ieOHECTk5OmDlzJrp27Yrg4GDe\npFd5mpqasLCwQOfOnTFnzhx8++23CAwM5JZ7e3tj/vz5GD16NDp27Ah3d3fMnj2bFwO8u2Sko6NT\n7Xv1oUJDQ1FWVoZmzZpBIBBAIBBg8+bNOHz4MF6/fv1B22zVqhUsLS3h4eGBiRMnYtSoUSpjJRIJ\nEhMTsW/fPpiammLhwoWwtrbmPZqhS5cuaNKkCe/SnyqVjb/8ezh58mQsWbIET548Qfv27eHp6YnY\n2Fil9TQ2NhaXL1+GSCSCQCCAhYUFgHdfmB4eHrxYExMTWFlZYciQIfjpp5+wefNmlZezq/P27Vsc\nPHgQLi4u+Oqrr2BkZIRNmzYpnMDo6+tDJpOhV69eOHToEG7fvo0jR45wZY+KikJkZCTs7e3RtWtX\nbNq0Cdra2gqd71evXqFJkyYfVNb6rlevXnBwcKhRJ1cVHR0dpenK2mD5tKr1ysPDA0lJSQgJCUF8\nfDySkpJgaGhYq4nfqtqlqhITEzFr1izIZDLExMTAy8uLa0+ysrKQk5MDFxcX7nMeHh6O48ePQyAQ\ncDf0AO8uv1pYWMDGxgaBgYGwtrZWuKxe1+2SurEO0ifWrl07lc8dsbS0RGpqKq83fu3atTovk0wm\ng7a2NmJiYpQuj4+Ph1Qqha+vL7p16waZTIZ79+7VOh+hUMg7M6spXV1dzJw5E3Pnzn3vF6O5uTmm\nTp2Kn3/+GXPmzMG2bdt4y1esWAEPDw/069ev2k5Sly5dlMY4Ozvj4MGDyM3NxcSJExEZGQkzMzM4\nOjoiIiKi2jNx+bOt4uJihV/u1tLSUvjCvnnzJrp06fLebX+osrIyhIeHY82aNUhKSuL+kpOT0axZ\nM+zbtw/A/88f+pD3cNq0abh58yb3Ba6MQCBA//79sWrVKqSkpCAnJwexsbHc8jZt2uDs2bM4duwY\npk+f/t782rRpAz09PYX3sFmzZvDz80NmZiZ++eUXCIVCjBgxAlKpFD/88APvLp1169YhOTmZOx7R\n0dEA3o2mLlu2TGXele9dbc6q6X9z7SZNmgQTExN4eXmhQ4cOSElJ4c7g33fHHxGBiLg8i4uLoaGh\nAS0tLV6cpqbmJ61b9cGKFStw4sQJXL58mZf+xRdf4NKlS7y0S5cuoW3btgrH7WO4dOkSZsyYgcGD\nB6N9+/YQiUR48eJFrbahql16+PAhVqxYgfbt28POzg6PHj1CaGgoHj58iDVr1uCLL74AAFhZWSE1\nNZX3OR8yZAi++eYbJCUlvXdeqLKRor963WEdpDry8uVL9O3bF3v27EFKSgqys7Nx8OBBrFq1CkOH\nDlW6zpgxY1BRUYHJkydzt+8GBQUBQJ3dzg68G+WaP38+5s2bh/DwcGRlZeHXX3/lLq/IZDLcv38f\nkZGRyMrKwrp16977RadKy5YtceXKFeTk5ODFixe1Gl2aMmUKMjMzVT6YbNasWTh16hSys7ORmJiI\ns2fPco1CVUFBQXBzc0Pfvn1x+/Ztlfk5ODjg1q1bKs/WGjVqhH/84x+4cuUKbt68CWtra8ybNw/u\n7u5cTGBgIE6fPo27d+8iPT0da9aswe7duzF27FguxsXFBUuXLsXJkyeRk5ODI0eO4Mcff8Tw4cN5\n+cXFxWHgwIHvPUYfKioqCnl5efj+++/RoUMH3p+rqytXD6RSKTQ0NBAVFYXnz58rvR1elYYNG2LS\npEnw9/dX2smNiorCunXrkJSUhHv37iE8PBwVFRWwtLTkxbVt2xZnz57F4cOH3/vgSE1NTfTv3x8X\nL15UGWNnZ4effvoJT548werVq5GUlARra2ukpqYCAFq0aME7Fm3btgXwrvNlZmYGAIiOjkZYWBhu\n3ryJnJwcnDx5ElOnToW9vT1atmxZ4+OzZ88eODg4oLi4GAcOHMC9e/cQGBgIKysrhdi7d+8iMDAQ\nCQkJuH//PuLj4/G3v/0N2traGDx4MADA1tYWBgYGGDduHJKTk5GZmQlvb29kZ2fDycmJ21ZOTg4e\nPXqE/v3717isfzYdO3aEm5sb1q1bx0ufM2cOYmJisGTJEmRmZmLXrl3YsGED5s6dWyflkMlk2L17\nN9LT03HlyhW4ubnVeuRFVbsklUpx5MgRTJs2Dbm5uTh48CCcnZ0VTr7EYrHCZ9zAwAASiQQdOnTg\nToJ8fHxw4cIF5OTkIDU1FT4+Pjh37pzCTRF12S7VC2qc//SX9vbtW/rhhx+oa9eu3IMCLS0tyc/P\njzfZEkpu8+/UqRMJhUKysbGhiIgIAsDdxq9somzlhNTK2+ZrO0mb6N2EwaVLl5JUKqUGDRpQixYt\neJOFvb29ydDQkHR1dWnUqFEUHBxM+vr63HL5PImIgoODSSqVcq8zMjKoZ8+e3GTW2tzmT0Q0ZcoU\nat++PZWXlysch3/+85/Upk0bEolE1KRJE3J3d+celqnsmE2fPp1MTU0pIyNDaRmIiLp3705btmxR\nuVxeeXk5b3u+vr5kYWFBYrGYGjVqRLa2thQZGclbp6CggGbOnEktWrTgHhTp6+vLmzT88OFDatCg\nAT148KDGZakNZ2dnpQ+GJCK6cuUK7/b8gIAAMjExIQ0NjVrd5k9EdP/+fRIIBLR//34i4r/PcXFx\n1Lt3b2rUqBFpa2tTp06duDj5WKJ3Dz81NjYmLy8vlfsVHR1NzZs3r9UE0kePHql8yKOySdqxsbFk\na2tL+vr6JBaLSSaT0fz58xX2HQCFhYV9UL7KYh0dHcnY2JgaNGhAZmZmNGbMGN6jPoiIrl27RgMH\nDqTGjRurfNjf8uXLycHBoUb5/lkom3ScnZ1NQqFQ5W3+lW3e6tWreculUikFBwcrbEu+Hiir82Fh\nYbw2MjExkbp168bVk4MHDypsX/77QBll7ZL8Q0JrQ9nxmjBhAkmlUhIKhdSkSRPq168f/ec//+HF\n1HW7VB9oEFVzMZ9Rq71798LT0xOvX7/+y17nra9OnjwJb29v3Lx5E5qa6htsnT9/PvLy8rB161a1\nleHPiIjQo0cPzJ49m5t8rg7Z2dlo27Yt0tLSIJPJ1FYOeaWlpZDJZIiIiFCYrMzUX6xd+nQE1Ycw\nn1J4eDhat26N5s2bIzk5GfPnz8fIkSNZ50gNnJyc8Ntvv+HRo0c1emZTXTE2Nv5Dd0V9rjQ0NLB1\n61bukpm6REdHY/LkyfWqcwS8e/ryv/71L9Y5+pNh7dKnw0aQ6plVq1Zh06ZNePLkCUxNTTFs2DAs\nW7asRg+pYxiGYRjm42AdJIZhGIZhGDnsLjaGYRiGYRg5rIPEMAzDMAwjh3WQGIZhGIZh5LAOEsMw\nDMMwjBzWQWIYhmEYhpHDOkgMwzAMwzByWAeJYRiGYRhGDusgMQzDMAzDyPk/vLsbMcjH/UgAAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a180bdc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2114, 1516, 3842]\n"
     ]
    }
   ],
   "source": [
    "red_zone = cog_takers[cog_takers['FinalScore'] <= 38]\n",
    "orange_zone = cog_takers[((cog_takers['FinalScore'] > 38) & (cog_takers['FinalScore'] <= 43))]\n",
    "green_zone = cog_takers[cog_takers['FinalScore'] > 43]\n",
    "\n",
    "objects = ('Significant Risk (<38)', 'At Risk (<43, >38)', 'Normal (>43)')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [red_zone.shape[0],orange_zone.shape[0], green_zone.shape[0]]\n",
    " \n",
    "barlist=plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "\n",
    "barlist[0].set_color('#FF0000')\n",
    "barlist[1].set_color('#FFBF00')\n",
    "barlist[2].set_color('g')\n",
    "\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Number of Participants')\n",
    "plt.title('AlzU CFT Performance')\n",
    " \n",
    "plt.show()\n",
    "\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2: Pre-Process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = all_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For those that have not taken CFT, replace value with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_cft_score = cog_takers['FinalScore'].mean()\n",
    "\n",
    "X['FinalScore'].fillna(avg_cft_score, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-process the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Convert the alzU columns to ints, and Replace \"NaN\" and empty strings with the mean of column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many lessons did you complete on AlzU.org?_Response\n",
      "[nan '1' '2' '3' '4' '']\n",
      "[-1 '1' '2' '3' '4' '']\n",
      "62: How many lessons did you complete on AlzU.org?_Response: float64\n",
      "[ 2.65112782  1.          2.          3.          4.        ]\n",
      "Please select the reasons why you have not yet completed the full 10 lesson course on AlzU.org. Select ALL that apply_Response\n",
      "[nan '0' '3' '' '7' '1' '2' '5' '4' '6']\n",
      "[-1 '0' '3' '' '7' '1' '2' '5' '4' '6']\n",
      "63: Please select the reasons why you have not yet completed the full 10 lesson course on AlzU.org. Select ALL that apply_Response: float64\n",
      "[ 1.35351882  0.          3.          7.          1.          2.          5.\n",
      "  4.          6.        ]\n",
      "Please select the reasons why you have not yet completed the full 10 lesson course on AlzU.org. Select ALL that apply_Other (please specify)\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Saw a doctor to discuss ways to lower AD risk?\n",
      "[nan '' '5' '4' '3' '2' '1']\n",
      "[-1 '' '5' '4' '3' '2' '1']\n",
      "65: Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Saw a doctor to discuss ways to lower AD risk?: float64\n",
      "[ 2.81190926  5.          4.          3.          2.          1.        ]\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Participated in an AD prevention research study other than this one?\n",
      "[nan '' '5' '3' '2' '4' '1']\n",
      "[-1 '' '5' '3' '2' '4' '1']\n",
      "66: Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Participated in an AD prevention research study other than this one?: float64\n",
      "[ 2.512772  5.        3.        2.        4.        1.      ]\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Saw a doctor to be evaluated for memory loss?\n",
      "[nan '' '4' '3' '2' '5' '1']\n",
      "[-1 '' '4' '3' '2' '5' '1']\n",
      "67: Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Saw a doctor to be evaluated for memory loss?: float64\n",
      "[ 2.5819209  4.         3.         2.         5.         1.       ]\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Saw a doctor to discuss ways to prevent memory loss?\n",
      "[nan '' '5' '4' '3' '2' '1']\n",
      "[-1 '' '5' '4' '3' '2' '1']\n",
      "68: Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Saw a doctor to discuss ways to prevent memory loss?: float64\n",
      "[ 2.66007533  5.          4.          3.          2.          1.        ]\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Saw a doctor to discuss an AD research study for a family member or friend?\n",
      "[nan '' '3' '2' '4' '5' '1']\n",
      "[-1 '' '3' '2' '4' '5' '1']\n",
      "69: Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Saw a doctor to discuss an AD research study for a family member or friend?: float64\n",
      "[ 2.35137702  3.          2.          4.          5.          1.        ]\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Was screened for, or enrolled in, an AD prevention clinical trial?\n",
      "[nan '' '5' '4' '3' '2' '1']\n",
      "[-1 '' '5' '4' '3' '2' '1']\n",
      "70: Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Was screened for, or enrolled in, an AD prevention clinical trial?: float64\n",
      "[ 2.3269962  5.         4.         3.         2.         1.       ]\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Was screened for, or enrolled in, the Early Study AD prevention clinical trial?\n",
      "[nan '' '4' '2' '3' '5' '1']\n",
      "[-1 '' '4' '2' '3' '5' '1']\n",
      "71: Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Was screened for, or enrolled in, the Early Study AD prevention clinical trial?: float64\n",
      "[ 2.29619048  4.          2.          3.          5.          1.        ]\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Was screened for, or enrolled in, the Generation Study AD prevention clinical trial?\n",
      "[nan '' '4' '2' '5' '3' '1']\n",
      "[-1 '' '4' '2' '5' '3' '1']\n",
      "72: Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Was screened for, or enrolled in, the Generation Study AD prevention clinical trial?: float64\n",
      "[ 2.23215985  4.          2.          5.          3.          1.        ]\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Joined the AD prevention registry endALZnow.org?\n",
      "[nan '' '5' '2' '3' '4' '1']\n",
      "[-1 '' '5' '2' '3' '4' '1']\n",
      "73: Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Joined the AD prevention registry endALZnow.org?: float64\n",
      "[ 2.6873805  5.         2.         3.         4.         1.       ]\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Joined the AD prevention registry BrainHealthRegistry.org?\n",
      "[nan '' '5' '2' '3' '4' '1']\n",
      "[-1 '' '5' '2' '3' '4' '1']\n",
      "74: Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Joined the AD prevention registry BrainHealthRegistry.org?: float64\n",
      "[ 2.56184084  5.          2.          3.          4.          1.        ]\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Joined the Global Alzheimer's Platform \"TRC PAD\" AD prevention registry?\n",
      "[nan '' '4' '2' '3' '5' '1']\n",
      "[-1 '' '4' '2' '3' '5' '1']\n",
      "75: Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Joined the Global Alzheimer's Platform \"TRC PAD\" AD prevention registry?: float64\n",
      "[ 2.22617902  4.          2.          3.          5.          1.        ]\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Made a dietary change to improve my brain health?\n",
      "[nan '' '5' '3' '2' '4' '1']\n",
      "[-1 '' '5' '3' '2' '4' '1']\n",
      "76: Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Made a dietary change to improve my brain health?: float64\n",
      "[ 3.88011418  5.          3.          2.          4.          1.        ]\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Increased exercise to improve my brain health?\n",
      "[nan '' '5' '3' '4' '2' '1']\n",
      "[-1 '' '5' '3' '4' '2' '1']\n",
      "77: Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Increased exercise to improve my brain health?: float64\n",
      "[ 4.07142857  5.          3.          4.          2.          1.        ]\n",
      "What would you be willing to do or to undergo in order to learn about your risk for developing AD someday in the future?_Take tests of my thinking and memory.\n",
      "[nan '' '5' '4' '2' '3' '1']\n",
      "[-1 '' '5' '4' '2' '3' '1']\n",
      "78: What would you be willing to do or to undergo in order to learn about your risk for developing AD someday in the future?_Take tests of my thinking and memory.: float64\n",
      "[ 3.5507109  5.         4.         2.         3.         1.       ]\n",
      "What would you be willing to do or to undergo in order to learn about your risk for developing AD someday in the future?_Get a blood test.\n",
      "[nan '' '5' '4' '1' '3' '2']\n",
      "[-1 '' '5' '4' '1' '3' '2']\n",
      "79: What would you be willing to do or to undergo in order to learn about your risk for developing AD someday in the future?_Get a blood test.: float64\n",
      "[ 2.74451859  5.          4.          1.          3.          2.        ]\n",
      "What would you be willing to do or to undergo in order to learn about your risk for developing AD someday in the future?_Get a brain scan (picture of the brain, like an MRI or cat scan).\n",
      "[nan '' '5' '2' '1' '3' '4']\n",
      "[-1 '' '5' '2' '1' '3' '4']\n",
      "80: What would you be willing to do or to undergo in order to learn about your risk for developing AD someday in the future?_Get a brain scan (picture of the brain, like an MRI or cat scan).: float64\n",
      "[ 2.66920152  5.          2.          1.          3.          4.        ]\n",
      "What would you be willing to do or to undergo in order to learn about your risk for developing AD someday in the future?_Get a genetic test to determine whether I have an Alzheimer’s risk gene.\n",
      "[nan '' '5' '3' '2' '1' '4']\n",
      "[-1 '' '5' '3' '2' '1' '4']\n",
      "81: What would you be willing to do or to undergo in order to learn about your risk for developing AD someday in the future?_Get a genetic test to determine whether I have an Alzheimer’s risk gene.: float64\n",
      "[ 2.74976213  5.          3.          2.          1.          4.        ]\n",
      "Please rate how likely it is that you would participate in the following types of AD research studies:_Requires answering questions on a computer and taking tests of memory skills?\n",
      "[nan '' '5' '4' '3' '1' '2']\n",
      "[-1 '' '5' '4' '3' '1' '2']\n",
      "82: Please rate how likely it is that you would participate in the following types of AD research studies:_Requires answering questions on a computer and taking tests of memory skills?: float64\n",
      "[ 4.37464522  5.          4.          3.          1.          2.        ]\n",
      "Please rate how likely it is that you would participate in the following types of AD research studies:_Randomly assigns half to receive a medicine and the other half to receive an inactive version?\n",
      "[nan '' '1' '5' '3' '4' '2']\n",
      "[-1 '' '1' '5' '3' '4' '2']\n",
      "83: Please rate how likely it is that you would participate in the following types of AD research studies:_Randomly assigns half to receive a medicine and the other half to receive an inactive version?: float64\n",
      "[ 2.91168091  1.          5.          3.          4.          2.        ]\n",
      "Please rate how likely it is that you would participate in the following types of AD research studies:_Randomly assigns half to make a dietary and exercise change, and the other half to continue as usual?\n",
      "[nan '' '4' '2' '5' '3' '1']\n",
      "[-1 '' '4' '2' '5' '3' '1']\n",
      "84: Please rate how likely it is that you would participate in the following types of AD research studies:_Randomly assigns half to make a dietary and exercise change, and the other half to continue as usual?: float64\n",
      "[ 3.74496644  4.          2.          5.          3.          1.        ]\n",
      "Please rate how helpful or harmful each of the following would be._Seeing your doctor to discuss ways to lower AD risk\n",
      "[nan '' '5' '4' '3' '2' '1']\n",
      "[-1 '' '5' '4' '3' '2' '1']\n",
      "85: Please rate how helpful or harmful each of the following would be._Seeing your doctor to discuss ways to lower AD risk: float64\n",
      "[ 4.02097235  5.          4.          3.          2.          1.        ]\n",
      "Please rate how helpful or harmful each of the following would be._Participate in an AD prevention research study\n",
      "[nan '' '5' '4' '3' '2' '1']\n",
      "[-1 '' '5' '4' '3' '2' '1']\n",
      "86: Please rate how helpful or harmful each of the following would be._Participate in an AD prevention research study: float64\n",
      "[ 4.13390313  5.          4.          3.          2.          1.        ]\n",
      "Please rate your level of agreement with the following questions._There is a strong possibility that I will develop AD\n",
      "[nan '' '4' '3' '5' '2' '1' '0']\n",
      "[-1 '' '4' '3' '5' '2' '1' '0']\n",
      "87: Please rate your level of agreement with the following questions._There is a strong possibility that I will develop AD: float64\n",
      "[ 3.19016083  4.          3.          5.          2.          1.          0.        ]\n",
      "Please rate your level of agreement with the following questions._Changing my lifestyle and health habits can help me reduce my chance of developing AD\n",
      "[nan '' '5' '4' '3' '2' '0' '1']\n",
      "[-1 '' '5' '4' '3' '2' '0' '1']\n",
      "88: Please rate your level of agreement with the following questions._Changing my lifestyle and health habits can help me reduce my chance of developing AD: float64\n",
      "[ 4.09726157  5.          4.          3.          2.          0.          1.        ]\n",
      "Please rate your level of agreement with the following questions._I have a lot to gain by changing my lifestyle and health behavior\n",
      "[nan '' '5' '3' '2' '4' '1' '0']\n",
      "[-1 '' '5' '3' '2' '4' '1' '0']\n",
      "89: Please rate your level of agreement with the following questions._I have a lot to gain by changing my lifestyle and health behavior: float64\n",
      "[ 4.08506616  5.          3.          2.          4.          1.          0.        ]\n",
      "Please rate your level of agreement with the following questions._I feel that my chances of developing AD in the future are high\n",
      "[nan '' '4' '2' '3' '5' '1' '0']\n",
      "[-1 '' '4' '2' '3' '5' '1' '0']\n",
      "90: Please rate your level of agreement with the following questions._I feel that my chances of developing AD in the future are high: float64\n",
      "[ 3.17786187  4.          2.          3.          5.          1.          0.        ]\n",
      "Please rate your level of agreement with the following questions._I am too busy to change my lifestyle and health habits\n",
      "[nan '' '2' '3' '1' '4' '5' '0']\n",
      "[-1 '' '2' '3' '1' '4' '5' '0']\n",
      "91: Please rate your level of agreement with the following questions._I am too busy to change my lifestyle and health habits: float64\n",
      "[ 2.10984848  2.          3.          1.          4.          5.          0.        ]\n",
      "Please rate your level of agreement with the following questions._Family responsibilities make it hard for me to change my lifestyle and behavior\n",
      "[nan '' '2' '1' '3' '4' '5' '0']\n",
      "[-1 '' '2' '1' '3' '4' '5' '0']\n",
      "92: Please rate your level of agreement with the following questions._Family responsibilities make it hard for me to change my lifestyle and behavior: float64\n",
      "[ 2.27039848  2.          1.          3.          4.          5.          0.        ]\n",
      "Please rate your level of agreement with the following questions._When I think about AD my heart beats faster\n",
      "[nan '' '4' '3' '5' '2' '1' '0']\n",
      "[-1 '' '4' '3' '5' '2' '1' '0']\n",
      "93: Please rate your level of agreement with the following questions._When I think about AD my heart beats faster: float64\n",
      "[ 2.72718631  4.          3.          5.          2.          1.          0.        ]\n",
      "Please rate your level of agreement with the following questions._When I think about AD I feel nauseous\n",
      "[nan '' '2' '5' '1' '3' '4' '0']\n",
      "[-1 '' '2' '5' '1' '3' '4' '0']\n",
      "94: Please rate your level of agreement with the following questions._When I think about AD I feel nauseous: float64\n",
      "[ 2.37320574  2.          5.          1.          3.          4.          0.        ]\n",
      "Please rate your level of agreement with the following questions._The thought of AD scares me\n",
      "[nan '' '5' '3' '4' '2' '1' '0']\n",
      "[-1 '' '5' '3' '4' '2' '1' '0']\n",
      "95: Please rate your level of agreement with the following questions._The thought of AD scares me: float64\n",
      "[ 3.69391635  5.          3.          4.          2.          1.          0.        ]\n",
      "Please rate your level of agreement with the following questions._Changing lifestyle and behavior interferes with my schedule\n",
      "[nan '' '2' '1' '3' '4' '5' '0']\n",
      "[-1 '' '2' '1' '3' '4' '5' '0']\n",
      "96: Please rate your level of agreement with the following questions._Changing lifestyle and behavior interferes with my schedule: float64\n",
      "[ 2.23709369  2.          1.          3.          4.          5.          0.        ]\n",
      "Please rate your level of agreement with the following questions._My chances of developing AD are great.\n",
      "[nan '' '4' '3' '5' '2' '1' '0']\n",
      "[-1 '' '4' '3' '5' '2' '1' '0']\n",
      "97: Please rate your level of agreement with the following questions._My chances of developing AD are great.: float64\n",
      "[ 3.03244275  4.          3.          5.          2.          1.          0.        ]\n",
      "Please rate your level of agreement with the following questions._I am certain that I can change my lifestyle and behavior so I can reduce the risk of developing AD\n",
      "[nan '' '4' '3' '5' '2' '0' '1']\n",
      "[-1 '' '4' '3' '5' '2' '0' '1']\n",
      "98: Please rate your level of agreement with the following questions._I am certain that I can change my lifestyle and behavior so I can reduce the risk of developing AD: float64\n",
      "[ 3.79867047  4.          3.          5.          2.          0.          1.        ]\n",
      "How much do you weigh without your clothes and shoes in pounds?_Open-Ended Response\n",
      "Have you ever been told by a doctor or other health professional that you have diabetes or have high sugar levels in your blood or urine?_Response\n",
      "[nan '' '2' '1']\n",
      "[-1 '' '2' '1']\n",
      "100: Have you ever been told by a doctor or other health professional that you have diabetes or have high sugar levels in your blood or urine?_Response: float64\n",
      "[ 1.84184184  2.          1.        ]\n",
      "Have you ever been told by a doctor or other health professional that you have high cholesterol levels in the past 2 years or your cholesterol level is higher than 240mg/dL?_Response\n",
      "[nan '' '2' '1']\n",
      "[-1 '' '2' '1']\n",
      "101: Have you ever been told by a doctor or other health professional that you have high cholesterol levels in the past 2 years or your cholesterol level is higher than 240mg/dL?_Response: float64\n",
      "[ 1.71971972  2.          1.        ]\n",
      "If you recall your most recent cholesterol results, please enter here:_Total Cholesterol\n",
      "[nan '' '155' '170' '137' '191' '209' '187' '216' '188' '2' '197' '185'\n",
      " '222' '127' '171' '234' '196' '192' '223' '262' '119' '200' '126' '0'\n",
      " '251' '181' '210' '135' '178' '229' '217' '202' '160' '175' '242' '193'\n",
      " '198' '205' '176' '164' '140' '163' '226' '270' '225' '129' '183' '158'\n",
      " '298' '150' '203' '227' '215' '174' '219' '241' '239' '117' '6' '179'\n",
      " '134' '165' '1' '245' '182' '110' '201' '220' '199' '190' '180' '194'\n",
      " '157' '60' '233' '237' '260' '240' '100' '128' '108' '208' '211' '213'\n",
      " '212' '294' '256' '90' '275' '186' '265' '390' '111' '152' '161' '255'\n",
      " '142' '118' '101' '133' '148' '230' '114' '249' '273' '169' '102' '248'\n",
      " '206' '244' '305' '280' '153' '316' '228' '288' '277' '250' '145' '103'\n",
      " '257' '5' '7' '184' '149' '235' '109' '264' '120' '136' '293' '130' '115'\n",
      " '204' '246' '340' '224' '303' '143' '207' '132' '167']\n",
      "[-1 '' '155' '170' '137' '191' '209' '187' '216' '188' '2' '197' '185'\n",
      " '222' '127' '171' '234' '196' '192' '223' '262' '119' '200' '126' '0'\n",
      " '251' '181' '210' '135' '178' '229' '217' '202' '160' '175' '242' '193'\n",
      " '198' '205' '176' '164' '140' '163' '226' '270' '225' '129' '183' '158'\n",
      " '298' '150' '203' '227' '215' '174' '219' '241' '239' '117' '6' '179'\n",
      " '134' '165' '1' '245' '182' '110' '201' '220' '199' '190' '180' '194'\n",
      " '157' '60' '233' '237' '260' '240' '100' '128' '108' '208' '211' '213'\n",
      " '212' '294' '256' '90' '275' '186' '265' '390' '111' '152' '161' '255'\n",
      " '142' '118' '101' '133' '148' '230' '114' '249' '273' '169' '102' '248'\n",
      " '206' '244' '305' '280' '153' '316' '228' '288' '277' '250' '145' '103'\n",
      " '257' '5' '7' '184' '149' '235' '109' '264' '120' '136' '293' '130' '115'\n",
      " '204' '246' '340' '224' '303' '143' '207' '132' '167']\n",
      "102: If you recall your most recent cholesterol results, please enter here:_Total Cholesterol: float64\n",
      "[ 187.965625  155.        170.        137.        191.        209.        187.\n",
      "  216.        188.          2.        197.        185.        222.        127.\n",
      "  171.        234.        196.        192.        223.        262.        119.\n",
      "  200.        126.          0.        251.        181.        210.        135.\n",
      "  178.        229.        217.        202.        160.        175.        242.\n",
      "  193.        198.        205.        176.        164.        140.        163.\n",
      "  226.        270.        225.        129.        183.        158.        298.\n",
      "  150.        203.        227.        215.        174.        219.        241.\n",
      "  239.        117.          6.        179.        134.        165.          1.\n",
      "  245.        182.        110.        201.        220.        199.        190.\n",
      "  180.        194.        157.         60.        233.        237.        260.\n",
      "  240.        100.        128.        108.        208.        211.        213.\n",
      "  212.        294.        256.         90.        275.        186.        265.\n",
      "  390.        111.        152.        161.        255.        142.        118.\n",
      "  101.        133.        148.        230.        114.        249.        273.\n",
      "  169.        102.        248.        206.        244.        305.        280.\n",
      "  153.        316.        228.        288.        277.        250.        145.\n",
      "  103.        257.          5.          7.        184.        149.        235.\n",
      "  109.        264.        120.        136.        293.        130.        115.\n",
      "  204.        246.        340.        224.        303.        143.        207.\n",
      "  132.        167.      ]\n",
      "If you recall your most recent cholesterol results, please enter here:_LDL (\"bad\" cholesterol)\n",
      "[nan '' '76' '116' '72' '127' '115' '97' '121' '128' '86' '131' '81' '123'\n",
      " '109' '85' '122' '124' '106' '136' '160' '40' '52' '0' '118' '94' '110'\n",
      " '177' '144' '91' '49' '104' '83' '120' '117' '99' '66' '146' '199' '151'\n",
      " '62' '100' '80' '56' '206' '137' '153' '84' '70' '113' '4' '71' '164' '75'\n",
      " '168' '65' '102' '68' '169' '73' '93' '50' '140' '77' '135' '152' '171'\n",
      " '112' '133' '107' '96' '44' '179' '333' '53' '59' '132' '126' '149' '105'\n",
      " '89' '138' '12712' '192' '64' '98' '82' '42' '155' '194' '150' '63' '224'\n",
      " '180' '125' '88' '79' '95' '101' '191' '103' '3' '90' '114' '78' '87' '35'\n",
      " '129' '165' '47' '67' '211' '45' '41' '51' '147' '154' '61']\n",
      "[-1 '' '76' '116' '72' '127' '115' '97' '121' '128' '86' '131' '81' '123'\n",
      " '109' '85' '122' '124' '106' '136' '160' '40' '52' '0' '118' '94' '110'\n",
      " '177' '144' '91' '49' '104' '83' '120' '117' '99' '66' '146' '199' '151'\n",
      " '62' '100' '80' '56' '206' '137' '153' '84' '70' '113' '4' '71' '164' '75'\n",
      " '168' '65' '102' '68' '169' '73' '93' '50' '140' '77' '135' '152' '171'\n",
      " '112' '133' '107' '96' '44' '179' '333' '53' '59' '132' '126' '149' '105'\n",
      " '89' '138' '12712' '192' '64' '98' '82' '42' '155' '194' '150' '63' '224'\n",
      " '180' '125' '88' '79' '95' '101' '191' '103' '3' '90' '114' '78' '87' '35'\n",
      " '129' '165' '47' '67' '211' '45' '41' '51' '147' '154' '61']\n",
      "103: If you recall your most recent cholesterol results, please enter here:_LDL (\"bad\" cholesterol): float64\n",
      "[  1.63502304e+02   7.60000000e+01   1.16000000e+02   7.20000000e+01\n",
      "   1.27000000e+02   1.15000000e+02   9.70000000e+01   1.21000000e+02\n",
      "   1.28000000e+02   8.60000000e+01   1.31000000e+02   8.10000000e+01\n",
      "   1.23000000e+02   1.09000000e+02   8.50000000e+01   1.22000000e+02\n",
      "   1.24000000e+02   1.06000000e+02   1.36000000e+02   1.60000000e+02\n",
      "   4.00000000e+01   5.20000000e+01   0.00000000e+00   1.18000000e+02\n",
      "   9.40000000e+01   1.10000000e+02   1.77000000e+02   1.44000000e+02\n",
      "   9.10000000e+01   4.90000000e+01   1.04000000e+02   8.30000000e+01\n",
      "   1.20000000e+02   1.17000000e+02   9.90000000e+01   6.60000000e+01\n",
      "   1.46000000e+02   1.99000000e+02   1.51000000e+02   6.20000000e+01\n",
      "   1.00000000e+02   8.00000000e+01   5.60000000e+01   2.06000000e+02\n",
      "   1.37000000e+02   1.53000000e+02   8.40000000e+01   7.00000000e+01\n",
      "   1.13000000e+02   4.00000000e+00   7.10000000e+01   1.64000000e+02\n",
      "   7.50000000e+01   1.68000000e+02   6.50000000e+01   1.02000000e+02\n",
      "   6.80000000e+01   1.69000000e+02   7.30000000e+01   9.30000000e+01\n",
      "   5.00000000e+01   1.40000000e+02   7.70000000e+01   1.35000000e+02\n",
      "   1.52000000e+02   1.71000000e+02   1.12000000e+02   1.33000000e+02\n",
      "   1.07000000e+02   9.60000000e+01   4.40000000e+01   1.79000000e+02\n",
      "   3.33000000e+02   5.30000000e+01   5.90000000e+01   1.32000000e+02\n",
      "   1.26000000e+02   1.49000000e+02   1.05000000e+02   8.90000000e+01\n",
      "   1.38000000e+02   1.27120000e+04   1.92000000e+02   6.40000000e+01\n",
      "   9.80000000e+01   8.20000000e+01   4.20000000e+01   1.55000000e+02\n",
      "   1.94000000e+02   1.50000000e+02   6.30000000e+01   2.24000000e+02\n",
      "   1.80000000e+02   1.25000000e+02   8.80000000e+01   7.90000000e+01\n",
      "   9.50000000e+01   1.01000000e+02   1.91000000e+02   1.03000000e+02\n",
      "   3.00000000e+00   9.00000000e+01   1.14000000e+02   7.80000000e+01\n",
      "   8.70000000e+01   3.50000000e+01   1.29000000e+02   1.65000000e+02\n",
      "   4.70000000e+01   6.70000000e+01   2.11000000e+02   4.50000000e+01\n",
      "   4.10000000e+01   5.10000000e+01   1.47000000e+02   1.54000000e+02\n",
      "   6.10000000e+01]\n",
      "If you recall your most recent cholesterol results, please enter here:_HDL (\"good\" cholesterol)\n",
      "[nan '' '40' '73' '45' '37' '68' '90' '83' '103' '52' '79' '74' '72' '99'\n",
      " '96' '54' '61' '77' '76' '60' '63' '0' '120' '42' '58' '50' '95' '70' '64'\n",
      " '91' '46' '71' '66' '80' '56' '47' '36' '39' '67' '81' '62' '43' '123'\n",
      " '65' '112' '1' '44' '93' '85' '75' '102' '32' '49' '94' '78' '59' '98'\n",
      " '953' '104' '97' '135' '10' '84' '48' '92' '88' '82' '55' '113' '100'\n",
      " '110' '114' '108' '170' '86' '53' '87' '69' '2' '35' '116' '144' '129'\n",
      " '89' '162' '82112' '51']\n",
      "[-1 '' '40' '73' '45' '37' '68' '90' '83' '103' '52' '79' '74' '72' '99'\n",
      " '96' '54' '61' '77' '76' '60' '63' '0' '120' '42' '58' '50' '95' '70' '64'\n",
      " '91' '46' '71' '66' '80' '56' '47' '36' '39' '67' '81' '62' '43' '123'\n",
      " '65' '112' '1' '44' '93' '85' '75' '102' '32' '49' '94' '78' '59' '98'\n",
      " '953' '104' '97' '135' '10' '84' '48' '92' '88' '82' '55' '113' '100'\n",
      " '110' '114' '108' '170' '86' '53' '87' '69' '2' '35' '116' '144' '129'\n",
      " '89' '162' '82112' '51']\n",
      "104: If you recall your most recent cholesterol results, please enter here:_HDL (\"good\" cholesterol): float64\n",
      "[  4.41008969e+02   4.00000000e+01   7.30000000e+01   4.50000000e+01\n",
      "   3.70000000e+01   6.80000000e+01   9.00000000e+01   8.30000000e+01\n",
      "   1.03000000e+02   5.20000000e+01   7.90000000e+01   7.40000000e+01\n",
      "   7.20000000e+01   9.90000000e+01   9.60000000e+01   5.40000000e+01\n",
      "   6.10000000e+01   7.70000000e+01   7.60000000e+01   6.00000000e+01\n",
      "   6.30000000e+01   0.00000000e+00   1.20000000e+02   4.20000000e+01\n",
      "   5.80000000e+01   5.00000000e+01   9.50000000e+01   7.00000000e+01\n",
      "   6.40000000e+01   9.10000000e+01   4.60000000e+01   7.10000000e+01\n",
      "   6.60000000e+01   8.00000000e+01   5.60000000e+01   4.70000000e+01\n",
      "   3.60000000e+01   3.90000000e+01   6.70000000e+01   8.10000000e+01\n",
      "   6.20000000e+01   4.30000000e+01   1.23000000e+02   6.50000000e+01\n",
      "   1.12000000e+02   1.00000000e+00   4.40000000e+01   9.30000000e+01\n",
      "   8.50000000e+01   7.50000000e+01   1.02000000e+02   3.20000000e+01\n",
      "   4.90000000e+01   9.40000000e+01   7.80000000e+01   5.90000000e+01\n",
      "   9.80000000e+01   9.53000000e+02   1.04000000e+02   9.70000000e+01\n",
      "   1.35000000e+02   1.00000000e+01   8.40000000e+01   4.80000000e+01\n",
      "   9.20000000e+01   8.80000000e+01   8.20000000e+01   5.50000000e+01\n",
      "   1.13000000e+02   1.00000000e+02   1.10000000e+02   1.14000000e+02\n",
      "   1.08000000e+02   1.70000000e+02   8.60000000e+01   5.30000000e+01\n",
      "   8.70000000e+01   6.90000000e+01   2.00000000e+00   3.50000000e+01\n",
      "   1.16000000e+02   1.44000000e+02   1.29000000e+02   8.90000000e+01\n",
      "   1.62000000e+02   8.21120000e+04   5.10000000e+01]\n",
      "If you recall your most recent cholesterol results, please enter here:_Triglycerides\n",
      "[nan '' '185' '71' '99' '153' '133' '58' '61' '90' '102' '106' '98' '63'\n",
      " '53' '94' '56' '0' '39' '83' '51' '201' '109' '69' '332' '80' '67' '154'\n",
      " '97' '86' '55' '96' '138' '120' '191' '84' '124' '194' '79' '320' '60'\n",
      " '68' '2' '122' '82' '75' '144' '187' '251' '57' '108' '95' '62' '127'\n",
      " '118' '65' '73' '224' '155' '400' '74' '47' '85' '130' '159' '123' '177'\n",
      " '43' '115' '10' '46' '149' '31' '48' '92' '198' '101' '126' '87' '72'\n",
      " '180' '66' '54' '345' '135' '104' '270' '52' '93125' '78' '100' '111' '50'\n",
      " '44' '1' '125' '140' '103' '89' '114' '292' '105' '179' '93' '88' '41'\n",
      " '275' '110' '157' '36' '116' '167' '77' '113' '70' '1800' '280' '197']\n",
      "[-1 '' '185' '71' '99' '153' '133' '58' '61' '90' '102' '106' '98' '63'\n",
      " '53' '94' '56' '0' '39' '83' '51' '201' '109' '69' '332' '80' '67' '154'\n",
      " '97' '86' '55' '96' '138' '120' '191' '84' '124' '194' '79' '320' '60'\n",
      " '68' '2' '122' '82' '75' '144' '187' '251' '57' '108' '95' '62' '127'\n",
      " '118' '65' '73' '224' '155' '400' '74' '47' '85' '130' '159' '123' '177'\n",
      " '43' '115' '10' '46' '149' '31' '48' '92' '198' '101' '126' '87' '72'\n",
      " '180' '66' '54' '345' '135' '104' '270' '52' '93125' '78' '100' '111' '50'\n",
      " '44' '1' '125' '140' '103' '89' '114' '292' '105' '179' '93' '88' '41'\n",
      " '275' '110' '157' '36' '116' '167' '77' '113' '70' '1800' '280' '197']\n",
      "105: If you recall your most recent cholesterol results, please enter here:_Triglycerides: float64\n",
      "[  5.83350254e+02   1.85000000e+02   7.10000000e+01   9.90000000e+01\n",
      "   1.53000000e+02   1.33000000e+02   5.80000000e+01   6.10000000e+01\n",
      "   9.00000000e+01   1.02000000e+02   1.06000000e+02   9.80000000e+01\n",
      "   6.30000000e+01   5.30000000e+01   9.40000000e+01   5.60000000e+01\n",
      "   0.00000000e+00   3.90000000e+01   8.30000000e+01   5.10000000e+01\n",
      "   2.01000000e+02   1.09000000e+02   6.90000000e+01   3.32000000e+02\n",
      "   8.00000000e+01   6.70000000e+01   1.54000000e+02   9.70000000e+01\n",
      "   8.60000000e+01   5.50000000e+01   9.60000000e+01   1.38000000e+02\n",
      "   1.20000000e+02   1.91000000e+02   8.40000000e+01   1.24000000e+02\n",
      "   1.94000000e+02   7.90000000e+01   3.20000000e+02   6.00000000e+01\n",
      "   6.80000000e+01   2.00000000e+00   1.22000000e+02   8.20000000e+01\n",
      "   7.50000000e+01   1.44000000e+02   1.87000000e+02   2.51000000e+02\n",
      "   5.70000000e+01   1.08000000e+02   9.50000000e+01   6.20000000e+01\n",
      "   1.27000000e+02   1.18000000e+02   6.50000000e+01   7.30000000e+01\n",
      "   2.24000000e+02   1.55000000e+02   4.00000000e+02   7.40000000e+01\n",
      "   4.70000000e+01   8.50000000e+01   1.30000000e+02   1.59000000e+02\n",
      "   1.23000000e+02   1.77000000e+02   4.30000000e+01   1.15000000e+02\n",
      "   1.00000000e+01   4.60000000e+01   1.49000000e+02   3.10000000e+01\n",
      "   4.80000000e+01   9.20000000e+01   1.98000000e+02   1.01000000e+02\n",
      "   1.26000000e+02   8.70000000e+01   7.20000000e+01   1.80000000e+02\n",
      "   6.60000000e+01   5.40000000e+01   3.45000000e+02   1.35000000e+02\n",
      "   1.04000000e+02   2.70000000e+02   5.20000000e+01   9.31250000e+04\n",
      "   7.80000000e+01   1.00000000e+02   1.11000000e+02   5.00000000e+01\n",
      "   4.40000000e+01   1.00000000e+00   1.25000000e+02   1.40000000e+02\n",
      "   1.03000000e+02   8.90000000e+01   1.14000000e+02   2.92000000e+02\n",
      "   1.05000000e+02   1.79000000e+02   9.30000000e+01   8.80000000e+01\n",
      "   4.10000000e+01   2.75000000e+02   1.10000000e+02   1.57000000e+02\n",
      "   3.60000000e+01   1.16000000e+02   1.67000000e+02   7.70000000e+01\n",
      "   1.13000000e+02   7.00000000e+01   1.80000000e+03   2.80000000e+02\n",
      "   1.97000000e+02]\n",
      "If you recall your most recent blood pressure, please enter here. This is recorded as a two numbers, e.g., 130/80. Please enter the larger number (called Systolic) first, and the smaller number (called Diastolic), second._Systolic Blood Pressure\n",
      "[nan '' '160' '118' '128' '106' '109' '135' '130' '126' '140' '127' '95'\n",
      " '120' '110' '115' '114' '122' '90' '86' '108' '105' '125' '100' '80' '123'\n",
      " '132' '124' '0' '138' '146' '116' '12060' '121' '131' '150' '142' '119'\n",
      " '92' '139' '117' '145' '104' '112' '82' '134' '133' '137' '155' '111'\n",
      " '141' '107' '113' '102' '98' '101' '136' '164' '129' '60' '78' '156' '161'\n",
      " '97' '158' '96' '144' '162' '70' '157' '91' '171' '143' '149' '148' '94'\n",
      " '103' '84']\n",
      "[-1 '' '160' '118' '128' '106' '109' '135' '130' '126' '140' '127' '95'\n",
      " '120' '110' '115' '114' '122' '90' '86' '108' '105' '125' '100' '80' '123'\n",
      " '132' '124' '0' '138' '146' '116' '12060' '121' '131' '150' '142' '119'\n",
      " '92' '139' '117' '145' '104' '112' '82' '134' '133' '137' '155' '111'\n",
      " '141' '107' '113' '102' '98' '101' '136' '164' '129' '60' '78' '156' '161'\n",
      " '97' '158' '96' '144' '162' '70' '157' '91' '171' '143' '149' '148' '94'\n",
      " '103' '84']\n",
      "106: If you recall your most recent blood pressure, please enter here. This is recorded as a two numbers, e.g., 130/80. Please enter the larger number (called Systolic) first, and the smaller number (called Diastolic), second._Systolic Blood Pressure: float64\n",
      "[   136.94986072    160.            118.            128.            106.\n",
      "    109.            135.            130.            126.            140.\n",
      "    127.             95.            120.            110.            115.\n",
      "    114.            122.             90.             86.            108.\n",
      "    105.            125.            100.             80.            123.\n",
      "    132.            124.              0.            138.            146.\n",
      "    116.          12060.            121.            131.            150.\n",
      "    142.            119.             92.            139.            117.\n",
      "    145.            104.            112.             82.            134.\n",
      "    133.            137.            155.            111.            141.\n",
      "    107.            113.            102.             98.            101.\n",
      "    136.            164.            129.             60.             78.\n",
      "    156.            161.             97.            158.             96.\n",
      "    144.            162.             70.            157.             91.\n",
      "    171.            143.            149.            148.             94.\n",
      "    103.             84.        ]\n",
      "If you recall your most recent blood pressure, please enter here. This is recorded as a two numbers, e.g., 130/80. Please enter the larger number (called Systolic) first, and the smaller number (called Diastolic), second._Diastolic Blood Pressure\n",
      "[nan '' '80' '75' '60' '69' '72' '78' '68' '79' '70' '65' '85' '66' '82'\n",
      " '53' '84' '59' '71' '90' '110' '67' '0' '74' '56' '55' '76' '63' '100'\n",
      " '88' '62' '40' '39' '64' '61' '104' '89' '73' '77' '81' '94' '105' '50'\n",
      " '83' '57' '120' '46' '95' '101' '86' '98' '58' '121' '47']\n",
      "[-1 '' '80' '75' '60' '69' '72' '78' '68' '79' '70' '65' '85' '66' '82'\n",
      " '53' '84' '59' '71' '90' '110' '67' '0' '74' '56' '55' '76' '63' '100'\n",
      " '88' '62' '40' '39' '64' '61' '104' '89' '73' '77' '81' '94' '105' '50'\n",
      " '83' '57' '120' '46' '95' '101' '86' '98' '58' '121' '47']\n",
      "107: If you recall your most recent blood pressure, please enter here. This is recorded as a two numbers, e.g., 130/80. Please enter the larger number (called Systolic) first, and the smaller number (called Diastolic), second._Diastolic Blood Pressure: float64\n",
      "[  73.80168776   80.           75.           60.           69.           72.\n",
      "   78.           68.           79.           70.           65.           85.\n",
      "   66.           82.           53.           84.           59.           71.\n",
      "   90.          110.           67.            0.           74.           56.\n",
      "   55.           76.           63.          100.           88.           62.\n",
      "   40.           39.           64.           61.          104.           89.\n",
      "   73.           77.           81.           94.          105.           50.\n",
      "   83.           57.          120.           46.           95.          101.\n",
      "   86.           98.           58.          121.           47.        ]\n",
      "Have you ever had a head injury where you lost consciousness for more than 15 minutes?_Response\n",
      "[nan '' '2' '1']\n",
      "[-1 '' '2' '1']\n",
      "108: Have you ever had a head injury where you lost consciousness for more than 15 minutes?_Response: float64\n",
      "[ 1.93393393  2.          1.        ]\n",
      "Check best answer for each description._I was bothered by things that usually don’t bother me.\n",
      "[nan '' '0' '1' '2' '3']\n",
      "[-1 '' '0' '1' '2' '3']\n",
      "109: Check best answer for each description._I was bothered by things that usually don’t bother me.: float64\n",
      "[ 0.70153846  0.          1.          2.          3.        ]\n",
      "Check best answer for each description._I had trouble keeping my mind on what I was doing.\n",
      "[nan '' '1' '0' '2' '3']\n",
      "[-1 '' '1' '0' '2' '3']\n",
      "110: Check best answer for each description._I had trouble keeping my mind on what I was doing.: float64\n",
      "[ 1.07897436  1.          0.          2.          3.        ]\n",
      "Check best answer for each description._I felt depressed.\n",
      "[nan '' '0' '1' '2' '3']\n",
      "[-1 '' '0' '1' '2' '3']\n",
      "111: Check best answer for each description._I felt depressed.: float64\n",
      "[ 0.81333333  0.          1.          2.          3.        ]\n",
      "Check best answer for each description._I felt that everything I did was an effort.\n",
      "[nan '' '0' '1' '2' '3']\n",
      "[-1 '' '0' '1' '2' '3']\n",
      "112: Check best answer for each description._I felt that everything I did was an effort.: float64\n",
      "[ 0.83179487  0.          1.          2.          3.        ]\n",
      "Check best answer for each description._I felt hopeful about the future.\n",
      "[nan '' '3' '2' '0' '1']\n",
      "[-1 '' '3' '2' '0' '1']\n",
      "113: Check best answer for each description._I felt hopeful about the future.: float64\n",
      "[ 2.27692308  3.          2.          0.          1.        ]\n",
      "Check best answer for each description._I felt fearful.\n",
      "[nan '' '0' '1' '2' '3']\n",
      "[-1 '' '0' '1' '2' '3']\n",
      "114: Check best answer for each description._I felt fearful.: float64\n",
      "[ 0.65025641  0.          1.          2.          3.        ]\n",
      "Check best answer for each description._My sleep was restless.\n",
      "[nan '' '1' '2' '3' '0']\n",
      "[-1 '' '1' '2' '3' '0']\n",
      "115: Check best answer for each description._My sleep was restless.: float64\n",
      "[ 1.37230769  1.          2.          3.          0.        ]\n",
      "Check best answer for each description._I was happy.\n",
      "[nan '' '3' '2' '1' '0']\n",
      "[-1 '' '3' '2' '1' '0']\n",
      "116: Check best answer for each description._I was happy.: float64\n",
      "[ 2.45538462  3.          2.          1.          0.        ]\n",
      "Check best answer for each description._I felt lonely.\n",
      "[nan '' '0' '1' '2' '3']\n",
      "[-1 '' '0' '1' '2' '3']\n",
      "117: Check best answer for each description._I felt lonely.: float64\n",
      "[ 0.82358974  0.          1.          2.          3.        ]\n",
      "Check best answer for each description._I could not “get going”\n",
      "[nan '' '0' '1' '2' '3']\n",
      "[-1 '' '0' '1' '2' '3']\n",
      "118: Check best answer for each description._I could not “get going”: float64\n",
      "[ 1.03076923  0.          1.          2.          3.        ]\n",
      "During the last 7 days, on how many days did you do vigorous physical activities like heavy lifting, digging, aerobics, or fast bicycling? Think about only those physical activities that you did for at least 10 minutes at a time. Please answer in days per week._Open-Ended Response\n",
      "[nan '' '6' '3' '0' '4' '5' '7' '1' '2']\n",
      "[-1 '' '6' '3' '0' '4' '5' '7' '1' '2']\n",
      "119: During the last 7 days, on how many days did you do vigorous physical activities like heavy lifting, digging, aerobics, or fast bicycling? Think about only those physical activities that you did for at least 10 minutes at a time. Please answer in days per week._Open-Ended Response: float64\n",
      "[ 2.12486188  6.          3.          0.          4.          5.          7.\n",
      "  1.          2.        ]\n",
      "How much time in total did you usually spend on one of those days doing vigorous physical activities? Please answer in minutes per day._Open-Ended Response\n",
      "Again, think only about those physical activities that you did for at least 10 minutes at a time. During the last 7 days, on how many days did you do moderate physical activities like carrying light loads, bicycling at a regular pace, or double tennis? Please do not include walking, and please answer in days per week._Open-Ended Response\n",
      "[nan '' '7' '2' '0' '5' '4' '3' '1' '6']\n",
      "[-1 '' '7' '2' '0' '5' '4' '3' '1' '6']\n",
      "121: Again, think only about those physical activities that you did for at least 10 minutes at a time. During the last 7 days, on how many days did you do moderate physical activities like carrying light loads, bicycling at a regular pace, or double tennis? Please do not include walking, and please answer in days per week._Open-Ended Response: float64\n",
      "[ 2.6441989  7.         2.         0.         5.         4.         3.         1.\n",
      "  6.       ]\n",
      "How much time in total did you usually spend on one of those days doing moderate physical activities? Please answer in minutes per day._Open-Ended Response\n",
      "During the last 7 days, on how many days did you walk for at least 10 minutes at a time? This includes walking at work and at home, walking to travel from place to place, and any other walking that you did solely for recreation, sport, exercise or leisure. Please answer in days per week._Open-Ended Response\n",
      "[nan '' '7' '4' '3' '2' '6' '5' '1' '0']\n",
      "[-1 '' '7' '4' '3' '2' '6' '5' '1' '0']\n",
      "123: During the last 7 days, on how many days did you walk for at least 10 minutes at a time? This includes walking at work and at home, walking to travel from place to place, and any other walking that you did solely for recreation, sport, exercise or leisure. Please answer in days per week._Open-Ended Response: float64\n",
      "[ 4.38895028  7.          4.          3.          2.          6.          5.\n",
      "  1.          0.        ]\n",
      "How much time in total did you usually spend walking on one of those days? Please answer in minutes per day._Open-Ended Response\n",
      "These questions ask about the amount and intensity of physical activity that you usually do._I rarely or never do any physical activities\n",
      "[nan '' '0' '1']\n",
      "[-1 '' '0' '1']\n",
      "125: These questions ask about the amount and intensity of physical activity that you usually do._I rarely or never do any physical activities: float64\n",
      "[ 0.16537181  0.          1.        ]\n",
      "These questions ask about the amount and intensity of physical activity that you usually do._I do some light or moderate physical activities, but not every week\n",
      "[nan '' '0' '1']\n",
      "[-1 '' '0' '1']\n",
      "126: These questions ask about the amount and intensity of physical activity that you usually do._I do some light or moderate physical activities, but not every week: float64\n",
      "[ 0.37274775  0.          1.        ]\n",
      "These questions ask about the amount and intensity of physical activity that you usually do._I do some light physical activity every week\n",
      "[nan '' '1' '0']\n",
      "[-1 '' '1' '0']\n",
      "127: These questions ask about the amount and intensity of physical activity that you usually do._I do some light physical activity every week: float64\n",
      "[ 0.88765295  1.          0.        ]\n",
      "These questions ask about the amount and intensity of physical activity that you usually do._I do moderate physical activities every week, but less than 30 minutes a day or 5 days a week\n",
      "[nan '' '0' '1']\n",
      "[-1 '' '0' '1']\n",
      "128: These questions ask about the amount and intensity of physical activity that you usually do._I do moderate physical activities every week, but less than 30 minutes a day or 5 days a week: float64\n",
      "[ 0.50506187  0.          1.        ]\n",
      "These questions ask about the amount and intensity of physical activity that you usually do._I do vigorous physical activities every week, but less than 20 minutes a day or 3 days a week\n",
      "[nan '' '0' '1']\n",
      "[-1 '' '0' '1']\n",
      "129: These questions ask about the amount and intensity of physical activity that you usually do._I do vigorous physical activities every week, but less than 20 minutes a day or 3 days a week: float64\n",
      "[ 0.25141563  0.          1.        ]\n",
      "These questions ask about the amount and intensity of physical activity that you usually do._I do 30 minutes or more a day of moderate physical activities, 5 or more days a week\n",
      "[nan '' '1' '0']\n",
      "[-1 '' '1' '0']\n",
      "130: These questions ask about the amount and intensity of physical activity that you usually do._I do 30 minutes or more a day of moderate physical activities, 5 or more days a week: float64\n",
      "[ 0.43883277  1.          0.        ]\n",
      "These questions ask about the amount and intensity of physical activity that you usually do._I do 20 minutes or more a day of vigorous physical activities, 3 or more days a week\n",
      "[nan '' '1' '0']\n",
      "[-1 '' '1' '0']\n",
      "131: These questions ask about the amount and intensity of physical activity that you usually do._I do 20 minutes or more a day of vigorous physical activities, 3 or more days a week: float64\n",
      "[ 0.32122588  1.          0.        ]\n",
      "These questions ask about the amount and intensity of physical activity that you usually do._I do activities to increase muscle strength, such as lifting weights or calisthenics, once a week or more\n",
      "[nan '' '0' '1']\n",
      "[-1 '' '0' '1']\n",
      "132: These questions ask about the amount and intensity of physical activity that you usually do._I do activities to increase muscle strength, such as lifting weights or calisthenics, once a week or more: float64\n",
      "[ 0.49103139  0.          1.        ]\n",
      "These questions ask about the amount and intensity of physical activity that you usually do._I do activities to improve flexibility, such as stretching or yoga, once a week or more\n",
      "[nan '' '1' '0']\n",
      "[-1 '' '1' '0']\n",
      "133: These questions ask about the amount and intensity of physical activity that you usually do._I do activities to improve flexibility, such as stretching or yoga, once a week or more: float64\n",
      "[ 0.56565657  1.          0.        ]\n",
      "These questions ask about the amount and intensity of physical activity that you usually do._Other (please specify more comments about any of your answers above)\n",
      "During the past year, how much time did you spend reading each day, including online reading?_hours per day:\n",
      "[nan '' '5' '3' '4' '2' '1']\n",
      "[-1 '' '5' '3' '4' '2' '1']\n",
      "135: During the past year, how much time did you spend reading each day, including online reading?_hours per day:: float64\n",
      "[ 3.58473625  5.          3.          4.          2.          1.        ]\n",
      "During the past year, how often were you engaging in..._Reading books (including online)\n",
      "[nan '' '5' '4' '2' '3' '1']\n",
      "[-1 '' '5' '4' '2' '3' '1']\n",
      "136: During the past year, how often were you engaging in..._Reading books (including online): float64\n",
      "[ 3.47586981  5.          4.          2.          3.          1.        ]\n",
      "During the past year, how often were you engaging in..._Reading newspaper (including online)\n",
      "[nan '' '5' '3' '4' '2' '1']\n",
      "[-1 '' '5' '3' '4' '2' '1']\n",
      "137: During the past year, how often were you engaging in..._Reading newspaper (including online): float64\n",
      "[ 3.63748597  5.          3.          4.          2.          1.        ]\n",
      "During the past year, how often were you engaging in..._Reading magazines (including online)\n",
      "[nan '' '3' '4' '5' '1' '2']\n",
      "[-1 '' '3' '4' '5' '1' '2']\n",
      "138: During the past year, how often were you engaging in..._Reading magazines (including online): float64\n",
      "[ 3.1661055  3.         4.         5.         1.         2.       ]\n",
      "During the past year, how often were you engaging in..._Playing games (word game, checkers, mind teasers, etc)\n",
      "[nan '' '5' '2' '4' '1' '3']\n",
      "[-1 '' '5' '2' '4' '1' '3']\n",
      "139: During the past year, how often were you engaging in..._Playing games (word game, checkers, mind teasers, etc): float64\n",
      "[ 3.50056117  5.          2.          4.          1.          3.        ]\n",
      "During the past year, how often were you engaging in..._Writing letters or emails\n",
      "[nan '' '5' '4' '3' '1' '2']\n",
      "[-1 '' '5' '4' '3' '1' '2']\n",
      "140: During the past year, how often were you engaging in..._Writing letters or emails: float64\n",
      "[ 4.10213244  5.          4.          3.          1.          2.        ]\n",
      "During the past year, how often were you engaging in..._Use online social network activities\n",
      "[nan '' '4' '5' '1' '2' '3']\n",
      "[-1 '' '4' '5' '1' '2' '3']\n",
      "141: During the past year, how often were you engaging in..._Use online social network activities: float64\n",
      "[ 3.79124579  4.          5.          1.          2.          3.        ]\n",
      "During the past year, how often were you engaging in..._Participating in ‘brain training’ activities\n",
      "[nan '' '2' '5' '4' '1' '3']\n",
      "[-1 '' '2' '5' '4' '1' '3']\n",
      "142: During the past year, how often were you engaging in..._Participating in ‘brain training’ activities: float64\n",
      "[ 2.65207632  2.          5.          4.          1.          3.        ]\n",
      "During the past year, how often were you engaging in..._Visiting a museum\n",
      "[nan '' '2' '4' '1' '3' '5']\n",
      "[-1 '' '2' '4' '1' '3' '5']\n",
      "143: During the past year, how often were you engaging in..._Visiting a museum: float64\n",
      "[ 1.44219978  2.          4.          1.          3.          5.        ]\n",
      "During the past year, how often were you engaging in..._Attending a concert, play or musical\n",
      "[nan '' '2' '3' '1' '5' '4']\n",
      "[-1 '' '2' '3' '1' '5' '4']\n",
      "144: During the past year, how often were you engaging in..._Attending a concert, play or musical: float64\n",
      "[ 1.68237935  2.          3.          1.          5.          4.        ]\n",
      "During the past year, how often were you engaging in..._Visiting a library\n",
      "[nan '' '3' '2' '4' '1' '5']\n",
      "[-1 '' '3' '2' '4' '1' '5']\n",
      "145: During the past year, how often were you engaging in..._Visiting a library: float64\n",
      "[ 1.74859708  3.          2.          4.          1.          5.        ]\n",
      "How many of your friends do you see or hear from at least once a month?_Response\n",
      "[nan '' '5' '6' '4' '2' '3' '1']\n",
      "[-1 '' '5' '6' '4' '2' '3' '1']\n",
      "146: How many of your friends do you see or hear from at least once a month?_Response: float64\n",
      "[ 4.21509009  5.          6.          4.          2.          3.          1.        ]\n",
      "Are you satisfied with your relationships with friends and relatives?_Response\n",
      "[nan '' '1' '0']\n",
      "[-1 '' '1' '0']\n",
      "147: Are you satisfied with your relationships with friends and relatives?_Response: float64\n",
      "[ 0.78040541  1.          0.        ]\n",
      "How often do you participate in religious services or social, political or community groups?_Response\n",
      "[nan '' '1' '0']\n",
      "[-1 '' '1' '0']\n",
      "148: How often do you participate in religious services or social, political or community groups?_Response: float64\n",
      "[ 0.39977477  1.          0.        ]\n",
      "Do you live alone or with other people?_Response\n",
      "[nan '' '0' '1']\n",
      "[-1 '' '0' '1']\n",
      "149: Do you live alone or with other people?_Response: float64\n",
      "[ 0.23648649  0.          1.        ]\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Green Leafy Vegetables (1 cup leafy, 1/2 c. for cooked/raw chopped)\n",
      "[nan '' '7' '8' '15' '4' '1' '3' '10' '5' '6' '14' '0' '2' '43' '12' '50'\n",
      " '18' '9' '20' '11' '21' '28' '25' '30' '40' '35' '24' '33' '774']\n",
      "[-1 '' '7' '8' '15' '4' '1' '3' '10' '5' '6' '14' '0' '2' '43' '12' '50'\n",
      " '18' '9' '20' '11' '21' '28' '25' '30' '40' '35' '24' '33' '774']\n",
      "150: How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Green Leafy Vegetables (1 cup leafy, 1/2 c. for cooked/raw chopped): float64\n",
      "[   6.85612366    7.            8.           15.            4.            1.\n",
      "    3.           10.            5.            6.           14.            0.\n",
      "    2.           43.           12.           50.           18.            9.\n",
      "   20.           11.           21.           28.           25.           30.\n",
      "   40.           35.           24.           33.          774.        ]\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Other Vegetables (1/2 c, e.g. broccoli, carrots, string beans)\n",
      "[nan '' '7' '5' '10' '3' '12' '6' '4' '21' '14' '0' '1' '2' '8' '15' '9'\n",
      " '50' '11' '16' '20' '30' '33' '24' '28' '22' '52']\n",
      "[-1 '' '7' '5' '10' '3' '12' '6' '4' '21' '14' '0' '1' '2' '8' '15' '9'\n",
      " '50' '11' '16' '20' '30' '33' '24' '28' '22' '52']\n",
      "151: How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Other Vegetables (1/2 c, e.g. broccoli, carrots, string beans): float64\n",
      "[  6.07866508   7.           5.          10.           3.          12.           6.\n",
      "   4.          21.          14.           0.           1.           2.           8.\n",
      "  15.           9.          50.          11.          16.          20.          30.\n",
      "  33.          24.          28.          22.          52.        ]\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Berries (1/2 c, e.g. strawberries, blueberries)\n",
      "[nan '' '5' '3' '4' '7' '2' '6' '14' '10' '1' '0' '20' '28' '8' '12' '21'\n",
      " '9' '25' '500' '35']\n",
      "[-1 '' '5' '3' '4' '7' '2' '6' '14' '10' '1' '0' '20' '28' '8' '12' '21'\n",
      " '9' '25' '500' '35']\n",
      "152: How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Berries (1/2 c, e.g. strawberries, blueberries): float64\n",
      "[   4.72705602    5.            3.            4.            7.            2.\n",
      "    6.           14.           10.            1.            0.           20.\n",
      "   28.            8.           12.           21.            9.           25.\n",
      "  500.           35.        ]\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Other Fruits (1/2 c)\n",
      "[nan '' '7' '2' '4' '1' '3' '14' '10' '5' '6' '0' '20' '8' '31' '12' '73'\n",
      " '9' '21' '28' '18' '16' '35']\n",
      "[-1 '' '7' '2' '4' '1' '3' '14' '10' '5' '6' '0' '20' '8' '31' '12' '73'\n",
      " '9' '21' '28' '18' '16' '35']\n",
      "153: How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Other Fruits (1/2 c): float64\n",
      "[  4.85171569   7.           2.           4.           1.           3.          14.\n",
      "  10.           5.           6.           0.          20.           8.          31.\n",
      "  12.          73.           9.          21.          28.          18.          16.\n",
      "  35.        ]\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Nuts (handful or 1/4-1/3 c.)\n",
      "[nan '' '7' '1' '21' '5' '4' '3' '6' '2' '0' '14' '13' '10' '20' '1072'\n",
      " '12' '11' '9' '8' '28']\n",
      "[-1 '' '7' '1' '21' '5' '4' '3' '6' '2' '0' '14' '13' '10' '20' '1072' '12'\n",
      " '11' '9' '8' '28']\n",
      "154: How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Nuts (handful or 1/4-1/3 c.): float64\n",
      "[  5.37469880e+00   7.00000000e+00   1.00000000e+00   2.10000000e+01\n",
      "   5.00000000e+00   4.00000000e+00   3.00000000e+00   6.00000000e+00\n",
      "   2.00000000e+00   0.00000000e+00   1.40000000e+01   1.30000000e+01\n",
      "   1.00000000e+01   2.00000000e+01   1.07200000e+03   1.20000000e+01\n",
      "   1.10000000e+01   9.00000000e+00   8.00000000e+00   2.80000000e+01]\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Olive oil (1 tbs.)\n",
      "[nan '' '4' '7' '3' '21' '1' '6' '8' '0' '2' '5' '14' '10' '20' '30' '77'\n",
      " '9' '12' '15' '758' '37' '60']\n",
      "[-1 '' '4' '7' '3' '21' '1' '6' '8' '0' '2' '5' '14' '10' '20' '30' '77'\n",
      " '9' '12' '15' '758' '37' '60']\n",
      "155: How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Olive oil (1 tbs.): float64\n",
      "[   5.45783133    4.            7.            3.           21.            1.\n",
      "    6.            8.            0.            2.            5.           14.\n",
      "   10.           20.           30.           77.            9.           12.\n",
      "   15.          758.           37.           60.        ]\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Butter, Cream (1 tablespoon)\n",
      "[nan '' '3' '14' '7' '1' '2' '21' '5' '0' '4' '8' '12' '6' '9' '10' '20'\n",
      " '23' '1.11111E+77' '100' '40' '15' '13']\n",
      "[-1 '' '3' '14' '7' '1' '2' '21' '5' '0' '4' '8' '12' '6' '9' '10' '20'\n",
      " '23' '1.11111E+77' '100' '40' '15' '13']\n",
      "156: How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Butter, Cream (1 tablespoon): float64\n",
      "[   3.82275449    3.           14.            7.            1.            2.\n",
      "   21.            5.            0.            4.            8.           12.\n",
      "    6.            9.           10.           20.           23.          100.\n",
      "   40.           15.           13.        ]\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Regular Cheese (1 oz.)\n",
      "[nan '' '4' '3' '0' '1' '14' '5' '6' '7' '2' '21' '10' '282' '20' '37' '34'\n",
      " '8' '53' '35' '-1' '75' '45' '77']\n",
      "[-1 '' '4' '3' '0' '1' '14' '5' '6' '7' '2' '21' '10' '282' '20' '37' '34'\n",
      " '8' '53' '35' '-1' '75' '45' '77']\n",
      "157: How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Regular Cheese (1 oz.): float64\n",
      "[   4.10456731    4.            3.            0.            1.           14.\n",
      "    5.            6.            7.            2.           21.           10.\n",
      "  282.           20.           37.           34.            8.           53.\n",
      "   35.           75.           45.           77.        ]\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Whole grains (1 slice bread, 3/4 cup pasta/cereal)\n",
      "[nan '' '4' '3' '7' '0' '5' '6' '2' '14' '10' '1' '8' '9' '25' '15' '21'\n",
      " '12' '19' '11' '20' '16' '50' '28']\n",
      "[-1 '' '4' '3' '7' '0' '5' '6' '2' '14' '10' '1' '8' '9' '25' '15' '21'\n",
      " '12' '19' '11' '20' '16' '50' '28']\n",
      "158: How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Whole grains (1 slice bread, 3/4 cup pasta/cereal): float64\n",
      "[  4.78391357   4.           3.           7.           0.           5.           6.\n",
      "   2.          14.          10.           1.           8.           9.          25.\n",
      "  15.          21.          12.          19.          11.          20.          16.\n",
      "  50.          28.        ]\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Fish (3 oz, not fried, not shell)\n",
      "[nan '' '1' '2' '5' '4' '6' '3' '7' '12' '0' '9' '43' '23' '11' '24' '8'\n",
      " '10' '15']\n",
      "[-1 '' '1' '2' '5' '4' '6' '3' '7' '12' '0' '9' '43' '23' '11' '24' '8'\n",
      " '10' '15']\n",
      "159: How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Fish (3 oz, not fried, not shell): float64\n",
      "[  1.73452381   1.           2.           5.           4.           6.           3.\n",
      "   7.          12.           0.           9.          43.          23.          11.\n",
      "  24.           8.          10.          15.        ]\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Beans (1/2 c.)\n",
      "[nan '' '1' '2' '0' '4' '5' '7' '3' '6' '14' '12' '10' '8']\n",
      "[-1 '' '1' '2' '0' '4' '5' '7' '3' '6' '14' '12' '10' '8']\n",
      "160: How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Beans (1/2 c.): float64\n",
      "[  1.9088729   1.          2.          0.          4.          5.          7.\n",
      "   3.          6.         14.         12.         10.          8.       ]\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Poultry (3 oz, not fried)\n",
      "[nan '' '3' '2' '4' '5' '0' '6' '1' '7' '12' '8' '9' '10' '25' '21' '16'\n",
      " '20' '14']\n",
      "[-1 '' '3' '2' '4' '5' '0' '6' '1' '7' '12' '8' '9' '10' '25' '21' '16'\n",
      " '20' '14']\n",
      "161: How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Poultry (3 oz, not fried): float64\n",
      "[  3.0562201   3.          2.          4.          5.          0.          6.\n",
      "   1.          7.         12.          8.          9.         10.         25.\n",
      "  21.         16.         20.         14.       ]\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Red meat (3 oz steak, ham, burgers)\n",
      "[nan '' '2' '3' '5' '0' '1' '4' '12' '9' '6' '15' '7' '10' '18' '8' '20']\n",
      "[-1 '' '2' '3' '5' '0' '1' '4' '12' '9' '6' '15' '7' '10' '18' '8' '20']\n",
      "162: How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Red meat (3 oz steak, ham, burgers): float64\n",
      "[  1.90833333   2.           3.           5.           0.           1.           4.\n",
      "  12.           9.           6.          15.           7.          10.          18.\n",
      "   8.          20.        ]\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Fast foods\n",
      "[nan '' '0' '2' '1' '3' '4' '10' '22' '5' '7']\n",
      "[-1 '' '0' '2' '1' '3' '4' '10' '22' '5' '7']\n",
      "163: How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Fast foods: float64\n",
      "[  0.8764988   0.          2.          1.          3.          4.         10.\n",
      "  22.          5.          7.       ]\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Pastries & Sweets\n",
      "[nan '' '0' '2' '4' '7' '3' '1' '5' '6' '8' '10' '12' '14' '20' '16' '21'\n",
      " '15' '9']\n",
      "[-1 '' '0' '2' '4' '7' '3' '1' '5' '6' '8' '10' '12' '14' '20' '16' '21'\n",
      " '15' '9']\n",
      "164: How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Pastries & Sweets: float64\n",
      "[  2.92095808   0.           2.           4.           7.           3.           1.\n",
      "   5.           6.           8.          10.          12.          14.          20.\n",
      "  16.          21.          15.           9.        ]\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Wine (glasses per week; 1 glass = 5 oz)\n",
      "[nan '' '0' '1' '2' '5' '10' '6' '7' '14' '3' '9' '4' '12' '20' '21' '26'\n",
      " '8' '18' '15' '25' '100']\n",
      "[-1 '' '0' '1' '2' '5' '10' '6' '7' '14' '3' '9' '4' '12' '20' '21' '26'\n",
      " '8' '18' '15' '25' '100']\n",
      "165: How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Wine (glasses per week; 1 glass = 5 oz): float64\n",
      "[   2.14595899    0.            1.            2.            5.           10.\n",
      "    6.            7.           14.            3.            9.            4.\n",
      "   12.           20.           21.           26.            8.           18.\n",
      "   15.           25.          100.        ]\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Other alcohol (serving = 1.5 oz liquor or 12 oz beer)\n",
      "[nan '' '1' '0' '2' '3' '4' '14' '15' '7' '5' '10' '21' '6' '8' '11' '12'\n",
      " '25' '48']\n",
      "[-1 '' '1' '0' '2' '3' '4' '14' '15' '7' '5' '10' '21' '6' '8' '11' '12'\n",
      " '25' '48']\n",
      "166: How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Other alcohol (serving = 1.5 oz liquor or 12 oz beer): float64\n",
      "[  1.25943971   1.           0.           2.           3.           4.          14.\n",
      "  15.           7.           5.          10.          21.           6.           8.\n",
      "  11.          12.          25.          48.        ]\n",
      "On average, what percent of your diet is made up of carbohydrates?_Response\n",
      "[nan '' '1' '2' '3' '6' '4' '5']\n",
      "[-1 '' '1' '2' '3' '6' '4' '5']\n",
      "167: On average, what percent of your diet is made up of carbohydrates?_Response: float64\n",
      "[ 2.71875  1.       2.       3.       6.       4.       5.     ]\n",
      "How many nights per week do you fast (meaning no calories at all) from dinner until breakfast lasting at least ~12 hours? (Please enter a number from 0-7)_Open-Ended Response\n",
      "[nan '' '3' '0' '7' '5' '4' '6' '1' '2']\n",
      "[-1 '' '3' '0' '7' '5' '4' '6' '1' '2']\n",
      "168: How many nights per week do you fast (meaning no calories at all) from dinner until breakfast lasting at least ~12 hours? (Please enter a number from 0-7)_Open-Ended Response: float64\n",
      "[ 3.16094675  3.          0.          7.          5.          4.          6.\n",
      "  1.          2.        ]\n",
      "In the past 12 months, how often did you eat fish or seafood that is not fried?_Response\n",
      "[nan '' '5' '7' '6' '9' '8' '4' '2' '1' '3' '10' '11']\n",
      "[-1 '' '5' '7' '6' '9' '8' '4' '2' '1' '3' '10' '11']\n",
      "169: In the past 12 months, how often did you eat fish or seafood that is not fried?_Response: float64\n",
      "[  5.18461538   5.           7.           6.           9.           8.           4.\n",
      "   2.           1.           3.          10.          11.        ]\n",
      "<https://www.alzu.org/assets/images/alcohol-volume.PNG>_Response\n",
      "[nan '' '1' '2' '0' '3' '4']\n",
      "[-1 '' '1' '2' '0' '3' '4']\n",
      "170: <https://www.alzu.org/assets/images/alcohol-volume.PNG>_Response: float64\n",
      "[ 1.80828402  1.          2.          0.          3.          4.        ]\n",
      "<https://www.alzu.org/assets/images/alcohol-volume.PNG>_Other (please specify)\n",
      "How many drinks do you have on a typical day when you are drinking?_Response\n",
      "[nan '' '1' '0' '2' '3' '4' '5' '6' '7']\n",
      "[-1 '' '1' '0' '2' '3' '4' '5' '6' '7']\n",
      "172: How many drinks do you have on a typical day when you are drinking?_Response: float64\n",
      "[ 1.28776978  1.          0.          2.          3.          4.          5.\n",
      "  6.          7.        ]\n",
      "Do you, or have you ever, smoked cigarettes, cigars, pipes or any other tobacco products?_Response\n",
      "[nan '' '2' '3' '1']\n",
      "[-1 '' '2' '3' '1']\n",
      "173: Do you, or have you ever, smoked cigarettes, cigars, pipes or any other tobacco products?_Response: float64\n",
      "[ 2.5443787  2.         3.         1.       ]\n",
      "Have you ever been involved in occupations that require you to mix, apply or load any pesticides, herbicides, weed killers, fumigants or fungicides?_Response\n",
      "[nan '' '2' '1']\n",
      "[-1 '' '2' '1']\n",
      "174: Have you ever been involved in occupations that require you to mix, apply or load any pesticides, herbicides, weed killers, fumigants or fungicides?_Response: float64\n",
      "[ 1.95502959  2.          1.        ]\n",
      "On average, how many hours per night do you sleep?_Open-Ended Response\n"
     ]
    }
   ],
   "source": [
    "idx_of_first_alzu_q = 62\n",
    "idx_of_last_non_prompt_alz_u_q = 175\n",
    "open_ended_alzu_indices = [64, 99, 120, 122, 124, 134, 171,175] #columns where they could enter in anything \n",
    "\n",
    "for col_idx in range(idx_of_first_alzu_q, idx_of_last_non_prompt_alz_u_q + 1):\n",
    "    col_name = cols[col_idx]\n",
    "    print(col_name)\n",
    "    if (col_idx in open_ended_alzu_indices):\n",
    "        continue\n",
    "    print(X[col_name].unique())\n",
    "    \n",
    "    # first convert all nan and empty to -1, so that the conversion of the column to astype int doesn't break\n",
    "    X[col_name].fillna(-1, inplace=True)\n",
    "    print(X[col_name].unique())\n",
    "    X[col_name].replace([''], [-1], inplace=True)\n",
    "    X[col_name].replace(['1.11111E+77'], [-1], inplace=True) # handle the bizarre entry that was breaking this\n",
    "    X[col_name] = (X[col_name]).astype(int)\n",
    "    \n",
    "    X[col_name].replace([-1], [np.NaN], inplace=True)\n",
    "    column_mean = X[col_name].mean()\n",
    "    X[col_name].fillna(column_mean, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(str(col_idx) + \": \" + col_name + \": \" +str(X[col_name].dtype))\n",
    "    print(X[col_name].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform some true false columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transform_true_false_col(col_name):\n",
    "    replaced_NaNs = X[col_name].fillna(-1)\n",
    "    replaced_t_f = replaced_NaNs.replace([False,True],[0,1])    \n",
    "    replaced_t_f = replaced_t_f.astype(int)\n",
    "    replaced_t_f.replace([-1], [np.NaN], inplace=True)\n",
    "    column_mean = replaced_t_f.mean()\n",
    "    replaced_t_f.fillna(column_mean, inplace=True)\n",
    "    return replaced_t_f\n",
    "\n",
    "\n",
    "X['MemConcern'] = transform_true_false_col('MemConcern')\n",
    "X['ForgetFriends'] = transform_true_false_col('ForgetFriends')\n",
    "X['PutThings'] = transform_true_false_col('PutThings')\n",
    "X['ForgetWords'] = transform_true_false_col('ForgetWords')\n",
    "X['LoseWay'] = transform_true_false_col('LoseWay')\n",
    "X['IsMemoryWorse'] = transform_true_false_col('IsMemoryWorse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform some yes no and other string columns...Taking some liberties here with how to encode them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X['FamilyHistory'].fillna(-1, inplace=True)\n",
    "X['FamilyHistory'].replace(['', 'no', 'yes'], [-1,0,1], inplace=True)\n",
    "X['FamilyHistory'].replace([-1], [np.NaN], inplace=True)\n",
    "\n",
    "X['FamilyHistoryAge'].fillna(-1, inplace=True)\n",
    "X['FamilyHistoryAge'].replace(['', 'Select', 'none', 'mild', 'other', 'alzh'], [-1,-1,0,1,2,3], inplace=True)\n",
    "X['FamilyHistoryAge'].replace([-1], [np.NaN], inplace=True)\n",
    "\n",
    "X['Supplements'].fillna(-1, inplace=True)\n",
    "X['Supplements'].replace(['Select', 'No', 'Yes'], [-1,0,1], inplace=True)\n",
    "X['Supplements'].replace([-1], [np.NaN], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns that we know are not good for ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X.drop(['Joined', 'User ID', 'First Name', 'Email', 'Lesson Group', 'UserID', 'FirstName', 'Respondent ID_', 'Collector ID_', 'IP Address_', 'Email Address_', 'First Name', 'Last Name_', 'Gender_y', 'DoB', 'joined_Open-Ended Response', 'email_Open-Ended Response', 'Start Date_', 'End Date_', 'First Name_', 'Custom Data 1_'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns from the CFT Dataset, THAT MAY BE OF USE LATER, but are just of inconvenient data types...Also we need to confirm that they do not influence the FinalScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X.drop(['RegDate','DateTaken','Homoscyteine', 'Source', 'Working', 'CompUser', 'DeviceUsed'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X.drop(['recallscore', 'placescore', 'MouseScore', 'Country', 'Postcode', 'Ethnicy', 'Interrupted', 'Functioned', 'FastInternet', 'ScreenClear', 'MaritalStatus', 'Dependents', 'Occupation', 'PrimaryIncome', 'HouseholdIncome', 'PrimaryIncomeOccupation', 'FirstPriority', 'SecondPriority', 'OtherPriority', 'ass', 'combocs'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many questions, particularly in the CFT portion, where there are no responses.  We drop those columns below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in X.columns:\n",
    "    if (X[col].dtype != 'int64' and X[col].dtype != 'float64'):\n",
    "        if(len(X[col].unique()) == 1 and X[col].unique() == ['']):\n",
    "            X.drop(col, axis=1, inplace=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the alzU columns where the format is open-ended.  Some of them have interesting data, but hard to think about how to convert them into numeric at this time.  Come back to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for open_ended_idx in open_ended_alzu_indices:\n",
    "    col_name = cols[open_ended_idx]\n",
    "    X.drop(col_name, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the written responses field for this round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.drop(memory_prompt, axis=1, inplace=True)\n",
    "X.drop(tech_prompt, axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make sure that all columns are ints or floats and convert NaN into mean for all columns\n",
    "for col in X.columns:\n",
    "    if (X[col].dtype !='int64' and X[col].dtype !='float64'):\n",
    "        print(\"PROBLEM! COLUMN IS NOT IN NUMERICAL FORMAT\")\n",
    "        print(col + \": \" + str(X[col].dtype))\n",
    "    else:\n",
    "        column_mean = X[col].mean()\n",
    "        X[col].fillna(column_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "def run_and_print_models(x_train, y_train, x_test, y_test):\n",
    "    features_importance_dict = {}\n",
    "    \n",
    "    #increments a features \"importance\" based on its weight in a model and the performance of that model\n",
    "    def update_features_dict(feature_weights, performance):\n",
    "#         print(\"FEATURE WEIGHTS\")\n",
    "#         print(feature_weights)       \n",
    "        absolute_feature_weights = np.absolute(feature_weights)\n",
    "#         print(\"ABS VALUE\")\n",
    "#         print(absolute_feature_weights)\n",
    "        sorted_feature_weights_indices = np.argsort(absolute_feature_weights) # list of feature indices, sorted ascending by absolute value of feature weight \n",
    "#         print(\"Num FEATURES: \" + str(len(feature_weights)))\n",
    "        for ranking, feature_index in enumerate(sorted_feature_weights_indices):            \n",
    "            feature_name = x_train.columns[feature_index]\n",
    "#             print(\"Feature: \")\n",
    "#             print(feature_name)\n",
    "#             print(\"Ranking: \")\n",
    "#             print(ranking)\n",
    "            feature_ranking = ranking * performance\n",
    "#             print(\"Travis Feature Ranking Rating:\")\n",
    "#             print(feature_ranking)\n",
    "#             print(feature_ranking)\n",
    "            if feature_name in features_importance_dict:\n",
    "                features_importance_dict[feature_name] += feature_ranking\n",
    "            else:\n",
    "                features_importance_dict[feature_name] = feature_ranking\n",
    "    \n",
    "    def get_top_n_features(n, feature_weights):\n",
    "        top_n_idx = np.argsort(feature_weights)[-n:] #SHOULD I BE USING ABSOLUTE VALUE?\n",
    "        top_n_features = [x_train.columns[i] for i in top_n_idx]\n",
    "        return top_n_features\n",
    "    \n",
    "    models = {\n",
    "        \"3-Nearest-Neighbors\": KNeighborsClassifier(n_neighbors=3),\n",
    "        \"Linear Regression\": LinearRegression(),\n",
    "        \"Decision Tree\": tree.DecisionTreeClassifier(),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=2,\n",
    "                                 random_state=0),\n",
    "        \"Support Vector Machines\": svm.SVC(kernel='linear')    \n",
    "    }\n",
    "    \n",
    "    for name, model in models.iteritems():\n",
    "        model.fit(x_train, y_train)\n",
    "        performance = model.score(x_test, y_test)\n",
    "        print(name + \" Classification Accuracy: \" + str(performance))\n",
    "        if (name == \"3-Nearest-Neighbors\"):\n",
    "            continue\n",
    "        elif (name == \"Support Vector Machines\"):\n",
    "            feature_weights = model.coef_[0]\n",
    "        elif(name==\"Linear Regression\"):\n",
    "            feature_weights = model.coef_\n",
    "        else:\n",
    "            feature_weights = model.feature_importances_\n",
    "#         print(name + \" Top Features: \")\n",
    "#         for idx, feat in enumerate(get_top_n_features(5, feature_weights)):\n",
    "#             print(str(idx + 1) + \": \" + feat)\n",
    "        \n",
    "        update_features_dict(feature_weights, performance)\n",
    "    import operator\n",
    "\n",
    "    sorted_x = sorted(features_importance_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for idx, feat_score_and_weight in enumerate(sorted_x):\n",
    "        if (idx > 9):\n",
    "            break\n",
    "        print(str(idx + 1) + \": \" + str(feat_score_and_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1: Two-Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify cog scores on Median (above median = 1, below median = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_two_class = X.copy()\n",
    "# median_score = X_two_class['FinalScore'].median()\n",
    "\n",
    "# X_two_class.loc[X_two_class['FinalScore'] < median_score, 'FinalScore'] = 0\n",
    "# X_two_class.loc[X_two_class['FinalScore'] >= median_score, 'FinalScore'] = 1\n",
    "\n",
    "# y_two_class = X_two_class['FinalScore']\n",
    "# X_two_class = X_two_class.drop(['FinalScore'], axis=1)\n",
    "\n",
    "# X_train_two, X_test_two, y_train_two, y_test_two = train_test_split(X_two_class,y_two_class)\n",
    "\n",
    "\n",
    "# print(X_train_two.shape)\n",
    "# print(X_test_two.shape)\n",
    "# print(y_train_two.shape)\n",
    "# print(y_test_two.shape)\n",
    "\n",
    "# print(\"Label Division...........\")\n",
    "# print(y_two_class[y_two_class == 0].count())\n",
    "# print(y_two_class[y_two_class == 1].count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run_and_print_models(X_train_two, y_train_two, X_test_two, y_test_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2: Three-Class Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split based on the scoring categories provided here: http://www.foodforthebrain.org/alzheimers-prevention/take-the-test/interpreting-results.aspx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_three_class = X.copy()\n",
    "\n",
    "# X_three_class.loc[X_three_class['FinalScore'] <= 38, 'FinalScore'] = 0\n",
    "# X_three_class.loc[((X_three_class['FinalScore'] > 38) & (X_three_class['FinalScore'] <= 43)), 'FinalScore'] = 1\n",
    "# X_three_class.loc[X_three_class['FinalScore'] > 43, 'FinalScore'] = 2\n",
    "\n",
    "# y_three_class = X_three_class['FinalScore']\n",
    "# X_three_class = X_three_class.drop(['FinalScore'], axis=1)\n",
    "\n",
    "# X_train_three, X_test_three, y_train_three, y_test_three = train_test_split(X_three_class,y_three_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run_and_print_models(X_train_three, y_train_three, X_test_three, y_test_three)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Analysis of best models for Writing Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# import nltk\n",
    "# import re\n",
    "# from collections import Counter\n",
    "# import string\n",
    "# import pprint\n",
    "\n",
    "# have_writing = all_data[((all_data[memory_prompt] != \"\") | (all_data[tech_prompt] != \"\"))].copy()\n",
    "\n",
    "# print(have_writing.shape)\n",
    "\n",
    "# writing_samples = have_writing.iloc[:,memory_prompt_idx:tech_prompt_idx + 1]\n",
    "\n",
    "# print(writing_samples.shape)\n",
    "\n",
    "# cft_scores = have_writing['FinalScore']\n",
    "\n",
    "# print(cft_scores.shape)\n",
    "\n",
    "# #replace NaN with mean\n",
    "# cft_median_score = cft_scores.median()\n",
    "# cft_mean_score = cft_scores.mean()\n",
    "\n",
    "# cft_scores.fillna(cft_mean_score, inplace=True)\n",
    "# print(cft_median_score)\n",
    "# print(cft_scores.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(cft_scores.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# have_writing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2.1: Two-class Classification using TF-IDF features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.where.html#pandas.Series.where\n",
    "# two_class_cft = cft_scores.copy()\n",
    "# two_class_cft = two_class_cft.where(two_class_cft >= cft_median_score, 0) \n",
    "# two_class_cft = two_class_cft.where(two_class_cft < cft_median_score, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ## Models to test\n",
    "# model_dict = {\n",
    "#     'Naive Bayes': MultinomialNB(),\n",
    "#     'Support Vector Machines': SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None),\n",
    "#     'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=2,\n",
    "#                                  random_state=0),\n",
    "#     'Decision Tree': tree.DecisionTreeClassifier(),\n",
    "#     \"3-Nearest-Neighbors\": KNeighborsClassifier(n_neighbors=3)\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Memory Responses Alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mem_prompt = have_writing.iloc[:,memory_prompt_idx]\n",
    "\n",
    "# print(mem_prompt.shape)\n",
    "# mem_prompt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mem_train_two, mem_test_two, score_train_two, score_test_two = train_test_split(mem_prompt,two_class_cft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# best_mem_clf = {\n",
    "#     'Name': None,\n",
    "#     'FitModel':None,\n",
    "#     'Score': 0\n",
    "# }\n",
    "# for model_name in model_dict:\n",
    "#     model = model_dict[model_name]\n",
    "#     clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', model)])\n",
    "#     clf.fit(mem_train_two, score_train_two)\n",
    "\n",
    "#     predicted = clf.predict(mem_test_two)\n",
    "#     predict_accuracy = np.mean(predicted == score_test_two)\n",
    "#     if (predict_accuracy >= best_mem_clf['Score']):\n",
    "#         best_mem_clf['Name'] = model_name\n",
    "#         best_mem_clf['FitModel'] = clf\n",
    "#         best_mem_clf['Score'] = predict_accuracy\n",
    "#     print(model_name + \" Prediction Accuracy:\")\n",
    "#     print(predict_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# best_mem_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for step in best_mem_clf['FitModel'].steps: \n",
    "#     if step[0] == 'clf':\n",
    "#         feature_importances = step[1].feature_importances_ #get_params()\n",
    "\n",
    "# feature_importances.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit Tech Responses Alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tech_prompt_responses = have_writing.iloc[:,tech_prompt_idx]\n",
    "# print(tech_prompt_responses.shape)\n",
    "# print(tech_prompt_responses.head())\n",
    "\n",
    "# tech_train_two, tech_test_two, score_train_two, score_test_two = train_test_split(tech_prompt_responses,two_class_cft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for model_name in model_dict:\n",
    "#     model = model_dict[model_name]\n",
    "#     clf = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', model)])\n",
    "#     clf.fit(tech_train_two, score_train_two)\n",
    "\n",
    "#     predicted = clf.predict(tech_test_two)\n",
    "#     predict_accuracy = np.mean(predicted == score_test_two) \n",
    "#     print(model_name + \" Prediction Accuracy:\")\n",
    "#     print(predict_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2.2: Three-class Classification using TF-IDF features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# three_class_cft = cft_scores.copy()\n",
    "\n",
    "# three_class_cft = three_class_cft.where(three_class_cft <= 38, 0)\n",
    "# three_class_cft = three_class_cft.where((three_class_cft > 38 & three_class_cft <=43), 1)\n",
    "# three_class_cft = three_class_cft.where(three_class_cft > 43, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def split_words(sample_string):\n",
    "#     return re.sub('['+string.punctuation.replace('\\'','')+']',' ',sample_string).split()\n",
    "\n",
    "# # Number of Words in Responses\n",
    "# print(len(split_words(sample_mem)))\n",
    "# print(len(split_words(sample_tech)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Number of Unique Words in Response\n",
    "# print(len(np.unique(split_words(sample_mem))))\n",
    "# print(len(np.unique(split_words(sample_tech))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #Honore's lexical richness calculation\n",
    "\n",
    "# def calc_honores(sample_string):\n",
    "#     split_string = re.sub('['+string.punctuation.replace('\\'','')+']',' ',sample_string).split()\n",
    "#     N = len(split_string) #number of words\n",
    "#     uniq_words, counts = np.unique(split_string, return_counts = True)\n",
    "#     v = len(uniq_words) # number of unique words\n",
    "#     v1 = len(np.where(counts==1)[0])\n",
    "    \n",
    "#     honores = (100*math.log(N))/(1-v1/v)\n",
    "#     return honores\n",
    "\n",
    "# print(calc_honores(sample_mem))\n",
    "# print(calc_honores(sample_tech))\n",
    "\n",
    "# print(calc_honores(\"I went to store then I went to the gym then I went to the house\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #Brunet's W index\n",
    "# def calc_brunets(sample_string):\n",
    "#     split_string = re.sub('['+string.punctuation.replace('\\'','')+']',' ',sample_string).split()\n",
    "#     N = len(split_string) #number of words\n",
    "#     uniq_words, counts = np.unique(split_string, return_counts = True)\n",
    "#     v = len(uniq_words) # number of unique words\n",
    "#     brunets = N**(v-0.165)\n",
    "#     return brunets\n",
    "\n",
    "# print(calc_brunets(sample_mem))\n",
    "# print(calc_brunets(sample_tech))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Use Renee's Correlated Features to Build a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "466544"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://raw.githubusercontent.com/dwyl/english-words/master/words.txt\n",
    "with open('words.txt','r') as words:\n",
    "    word_list = words.read().splitlines()\n",
    "\n",
    "word_list = [w.lower() for w in word_list]\n",
    "\n",
    "\n",
    "len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     /Users/travisallen/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n",
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('tagsets')\n",
    "nltk.help.upenn_tagset()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def catch(func, handle=lambda e : e, *args, **kwargs):\n",
    "    try:\n",
    "        return func(*args, **kwargs)    \n",
    "    except ZeroDivisionError as z:\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        return handle(e)\n",
    "\n",
    "\n",
    "# ## Tokenization\n",
    "\n",
    "# In[69]:\n",
    "\n",
    "\n",
    "#Mis-spellings, word length\n",
    "#rm puctuation\n",
    "#keep contractions, posessives\n",
    "def list_tokenize(response):\n",
    "    return re.sub('['+string.punctuation.replace('\\'','')+']',' ',response).split()\n",
    "\n",
    "\n",
    "# ## Information extraction nltk\n",
    "\n",
    "# In[70]:\n",
    "\n",
    "\n",
    "#information-extraction\n",
    "#https://www.nltk.org/book/ch07.html\n",
    "def ie_preprocess(document):\n",
    "    #sentence segmentation\n",
    "    sentences = nltk.sent_tokenize(document) \n",
    "    #tokenization\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    #pos tagging\n",
    "    sentences = [nltk.pos_tag(sent) for sent in sentences] \n",
    "    \n",
    "    return sentences\n",
    "\n",
    "\n",
    "# ## Uniq, V\n",
    "\n",
    "# In[71]:\n",
    "\n",
    "\n",
    "def uniq_words (response,token_list=None, counts_vector_return=False,uniq_set_return=False):\n",
    "    if token_list is None: token_list = list_tokenize(response)\n",
    "    if counts_vector_return and uniq_set_return: return np.unique(token_list,return_counts=True)\n",
    "    \n",
    "    if counts_vector_return and not uniq_set_return: return np.unique(token_list,return_counts=True)[1]\n",
    "    \n",
    "    if uniq_set_return and not counts_vector_return: return np.unique(token_list)\n",
    "    #typical case, investigating number of uniq responses\n",
    "    \n",
    "    return len(np.unique(token_list))\n",
    "        \n",
    "\n",
    "\n",
    "# ## V1 \n",
    "\n",
    "# In[72]:\n",
    "\n",
    "\n",
    "def single_appearances (response,counts=None):\n",
    "    if counts is None: counts = uniq_words(response,counts_vector_return=True)\n",
    "    return len(np.where(counts==1)[0])\n",
    "\n",
    "\n",
    "# ## N-grams\n",
    "\n",
    "# In[73]:\n",
    "\n",
    "\n",
    "#http://locallyoptimal.com/blog/2013/01/20/elegant-n-gram-generation-in-python/\n",
    "#input\n",
    "def find_bigrams(response, return_list=False):\n",
    "    input_list = list_tokenize(response)\n",
    "    bigrams = zip(input_list, input_list[1:])\n",
    "    if return_list: return [b for b in bigrams]\n",
    "    else: return bigrams\n",
    "\n",
    "\n",
    "# ## Word count\n",
    "\n",
    "# In[74]:\n",
    "\n",
    "\n",
    "def word_count(response):\n",
    "    return len(list_tokenize(response))\n",
    "\n",
    "\n",
    "# ## Sentence count\n",
    "\n",
    "# In[75]:\n",
    "\n",
    "\n",
    "def sentence_count(response):\n",
    "    return len(ie_preprocess(response))\n",
    "\n",
    "\n",
    "# ### POS tagging\n",
    "\n",
    "# In[76]:\n",
    "\n",
    "\n",
    "#information-extraction\n",
    "#https://www.nltk.org/book/ch07.html\n",
    "def ie_preprocess(document):\n",
    "    #sentence segmentation\n",
    "    sentences = nltk.sent_tokenize(document) \n",
    "    #tokenization\n",
    "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "    #pos tagging\n",
    "    sentences = [nltk.pos_tag(sent) for sent in sentences] \n",
    "    \n",
    "    return sentences\n",
    "\n",
    "\n",
    "# ## Rates\n",
    "\n",
    "# In[77]:\n",
    "\n",
    "\n",
    "def pos_rate(response,pos_response=None,tag_set=None,denom_set=None,N=None,nn=False,pn=False,vb=False,proper=None):\n",
    "    \n",
    "    if pos_response is None: pos_response = ie_preprocess(response)\n",
    "        \n",
    "    \n",
    "    if tag_set is None:\n",
    "        #common nouns, excluding proper nouns\n",
    "        if nn: tag_set = ['NN','NNS']\n",
    "        elif vb: tag_set = ['VB','VBD','VBG','VBN','VBP','VBZ'] \n",
    "        elif pn: tag_set = ['PRP','PRP$']\n",
    "        elif proper: \n",
    "            tag_set = ['PRP','PRP$','WP','WP$']\n",
    "            denom_set = ['PRP','PRP$','WP','WP$','NN','NNP','NNPS','NNS']\n",
    "            \n",
    "        \n",
    "    pos_count = sum([1 for sentence in pos_response for word in sentence if word[1] in tag_set])\n",
    "    \n",
    "    if denom_set: \n",
    "        denom_count = sum([1 for sentence in pos_response for word in sentence if word[1] in denom_set])\n",
    "    else:\n",
    "        if N is None: N = word_count(response)\n",
    "        denom_count = N\n",
    "    \n",
    "    if (denom_count == 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return pos_count/denom_count\n",
    "        \n",
    "\n",
    "#         sum([1 for sentence in pos_test for word in sentence if word[1] in ['VB','VBD','VBG','VBN','VBP','VBZ'] ])\n",
    "\n",
    "\n",
    "# ## Honore's R \n",
    "# ![image.png](attachment:image.png)\n",
    "# https://books.google.com/books?id=CwC4CwAAQBAJ&pg=PA111&lpg=PA111&dq=honore+statistic+lexical+richness&source=bl&ots=LPnM2j9oX5&sig=HGObkoMYRy6lLsgc80Y7tUMT7vk&hl=en&sa=X&ved=2ahUKEwjv0ubE7vTdAhXwYd8KHVRfCiMQ6AEwCXoECAUQAQ#v=onepage&q=honore&f=false\n",
    "# \n",
    "# http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.2.1359&rep=rep1&type=pdf\n",
    "# \n",
    "# http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.484.4648&rep=rep1&type=pdf\n",
    "# \n",
    "# viii) Honoré’s R statistic.\n",
    "# If V1 denotes the number of hapax legomena recorded, then Honoré (1979) defined his\n",
    "# statistic as:\n",
    "# \n",
    "# *R = 100log(N)/(1 - V1/V)*\n",
    "# \n",
    "# As a measure of vocabulary richness which has the virtue of being insensitive to text\n",
    "# length, it has been used in stylometric studies by Holmes (1992) and Holmes and\n",
    "# Stylometric analysis of conversational speech\n",
    "# Forsyth (1995). Values of R typically range from 1000 to 2000 with higher values\n",
    "# implying richer vocabularies in the sense that a greater number of words appear\n",
    "# infrequently.\n",
    "# \n",
    "# \n",
    "# https://pdfs.semanticscholar.org/11f9/ef33ad001f7638ba29ee8109077de92eb1bb.pdf\n",
    "# \n",
    "# \n",
    "# Assuming log == base e...fits with 1000-2000 assumption\n",
    "# \n",
    "# \n",
    "# \n",
    "\n",
    "# In[78]:\n",
    "\n",
    "\n",
    "def honore_r(response,v=None,v1=None, N=None):\n",
    "    if N is None: N = word_count(response)\n",
    "    if v is None: v = uniq_responses(response)\n",
    "    if v1 is None: \n",
    "        counts = uniq_responses(response,counts_vector_return=True)\n",
    "        v1 = len(np.where(counts==1)[0])\n",
    "    return (100*math.log(N))/(1-v1/v)\n",
    "\n",
    "\n",
    "# ## Brunet's W\n",
    "# W = N**(V −0.165)\n",
    "# \n",
    "# (vii) Brunet’s W index.\n",
    "# This index, devised by Brunet (1978) and used successfully by Holmes and Forsyth\n",
    "# (1995), is a measure of vocabulary richness which is insensitive to text length. It is\n",
    "# defined as:\n",
    "# \n",
    "# W= N^(V-0.165)\n",
    "# where N is the text length, V the number of different words and (-0.165) is a scaling\n",
    "# constant proposed by Brunet. The measure generally varies between 10 and 20 with a\n",
    "# low value indicating a lexically richer speech.\n",
    "# https://pdfs.semanticscholar.org/11f9/ef33ad001f7638ba29ee8109077de92eb1bb.pdf\n",
    "\n",
    "# In[79]:\n",
    "\n",
    "\n",
    "def brunet_w(response,N=None, v=None):\n",
    "    if N is None: N = word_count(response)\n",
    "    if v is None: v = uniq_responses(response)\n",
    "    return N**(v-0.165)\n",
    "\n",
    "\n",
    "# ## Moving window\n",
    "\n",
    "# In[80]:\n",
    "\n",
    "\n",
    "#10-window size generator\n",
    "#https://docs.python.org/release/2.3.5/lib/itertools-example.html\n",
    "def window(seq, n=10):\n",
    "    \"Returns a sliding window (of width n) over data from the iterable\"\n",
    "    \"   s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...                   \"\n",
    "    it = iter(seq)\n",
    "    result = tuple(islice(it, n))\n",
    "    if len(result) == n:\n",
    "        yield result    \n",
    "    for elem in it:\n",
    "        result = result[1:] + (elem,)\n",
    "        yield result\n",
    "\n",
    "def coord_conjunctions_init(response):\n",
    "    return sum([1 for sentence in ie_preprocess(response) if sentence[0][1] == 'CC'])\n",
    "\n",
    "def misspelt(response):\n",
    "    return sum([1 for word in list_tokenize(response) if word.lower() not in word_list])\n",
    "\n",
    "def calc_MATTR(mr):\n",
    "    window_iterable = window(list_tokenize(mr),n=min(len(list_tokenize(mr)),10))\n",
    "    return np.mean([len(np.unique(mw))/min(len(list_tokenize(mr)),10) for mw in window_iterable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # http://t-redactyl.io/blog/2017/04/using-vader-to-handle-sentiment-analysis-with-social-media-text.html\n",
    "# from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "# vader = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp 3.1: See how language features compare to non-lang for users with memory responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364,)\n"
     ]
    }
   ],
   "source": [
    "have_mem_indices = all_data.index[all_data[memory_prompt] != \"\"] #Gets the indices of rows that have memory response\n",
    "print(have_mem_indices.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'28844', u'28858', u'28867', u'28881', u'29004', u'29051', u'29056', u'29059', u'29073', u'29079',\n",
       "       ...\n",
       "       u'59079', u'59103', u'59200', u'59243', u'59321', u'59682', u'59826', u'60026', u'60056', u'60130'], dtype='object', length=364)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "have_mem_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364,)\n"
     ]
    }
   ],
   "source": [
    "mem_cft_scores = pd.Series(all_data.loc[have_mem_indices]['FinalScore'], index=have_mem_indices) #Will be used as target for both language and non-language experiments\n",
    "print(mem_cft_scores.shape)\n",
    "\n",
    "#replace NaN with mean\n",
    "mem_cft_median_score = mem_cft_scores.median()\n",
    "mem_cft_mean_score = mem_cft_scores.mean()\n",
    "mem_cft_scores.fillna(mem_cft_mean_score, inplace=True)\n",
    "\n",
    "\n",
    "### MAKE A THREE-CLASS TARGET, BASED ON CFT WEBSITE\n",
    "mem_THREE_class_cft = mem_cft_scores.copy()\n",
    "\n",
    "mem_THREE_class_cft = mem_THREE_class_cft.where(mem_THREE_class_cft > 38, 0)\n",
    "mem_THREE_class_cft = mem_THREE_class_cft.where(mem_THREE_class_cft < 43, 2)\n",
    "mem_THREE_class_cft = mem_THREE_class_cft.where(((mem_THREE_class_cft == 0) | (mem_THREE_class_cft == 2)), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold Out Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "held_out_test_mem_idx = np.random.choice(have_mem_indices,(1,int(.20*len(have_mem_indices))),replace=False)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array([['40712', '44816', '43211', '51913', '41880', '39575', '29112',\n",
    "        '54397', '29004', '52080', '44345', '57361', '29113', '49691',\n",
    "        '40020', '38603', '46323', '29136', '55057', '54236', '43644',\n",
    "        '47950', '29670', '55991', '41751', '30279', '35853', '58820',\n",
    "        '29615', '35337', '59682', '42780', '40118', '54884', '29056',\n",
    "        '32304', '51163', '43205', '32565', '29234', '53994', '58441',\n",
    "        '29084', '32601', '34097', '46015', '42587', '36881', '47461',\n",
    "        '49925', '39966', '54091', '43429', '29608', '43700', '45405',\n",
    "        '29563', '54740', '30384', '29768', '32182', '31723', '32871',\n",
    "        '50433', '40693', '39695', '46613', '41045', '40854', '38440',\n",
    "        '38649', '45884']], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# held_out_test_mem_idx = ['40712', '44816', '43211', '51913', '41880', '39575', '29112', '54397', '29004', '52080', '44345', '57361', '29113', '49691', '40020', '38603', '46323', '29136', '55057', '54236', '43644', '47950', '29670', '55991', '41751', '30279', '35853', '58820', '29615', '35337', '59682', '42780', '40118', '54884', '29056', '32304', '51163', '43205', '32565', '29234', '53994', '58441', '29084', '32601', '34097', '46015', '42587', '36881', '47461', '49925', '39966', '54091', '43429', '29608', '43700', '45405', '29563', '54740', '30384', '29768', '32182', '31723', '32871', '50433', '40693', '39695', '46613', '41045', '40854', '38440', '38649', '45884']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_mem_heldout = mem_THREE_class_cft[held_out_test_mem_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72,)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mem_heldout.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dev_mem_ix = [m for m in have_mem_indices if m not in held_out_test_mem_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_mem_idx = np.random.choice(train_dev_mem_ix,(1,int(.20*len(train_dev_mem_ix))),replace=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dev_mem_idx = ['46047', '58728', '42364', '39539', '39862', '30087', '58354',\n",
    "#         '47480', '56239', '46765', '39880', '34753', '31795', '45647',\n",
    "#         '43233', '32846', '55823', '31075', '43830', '39573', '53678',\n",
    "#         '57834', '32144', '39171', '52174', '39582', '33976', '45821',\n",
    "#         '43155', '53050', '52053', '53125', '39082', '59103', '37078',\n",
    "#         '33444', '29051', '40017', '39830', '42876', '29970', '31871',\n",
    "#         '31482', '39319', '54924', '44439', '38414', '29502', '30865',\n",
    "#         '32233', '43247', '57709', '53472', '40938', '29129', '57407',\n",
    "#         '42040', '40253']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_mem_dev = mem_THREE_class_cft[dev_mem_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58,)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mem_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_mem_idx =  [i for i in train_dev_mem_ix if i not in dev_mem_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_mem_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_mem_train = mem_THREE_class_cft[train_mem_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def prediction_accuracies(X_train, X_test, y_train, y_test):\n",
    "    ## Models to test\n",
    "    model_dict = {\n",
    "        'Naive Bayes': MultinomialNB(),\n",
    "        'Support Vector Machines': SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=2,\n",
    "                                     random_state=0),\n",
    "        'Decision Tree': tree.DecisionTreeClassifier(),\n",
    "        \"3-Nearest-Neighbors\": KNeighborsClassifier(n_neighbors=3)\n",
    "    }\n",
    "\n",
    "    for model_name in model_dict:\n",
    "        model = model_dict[model_name]\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        predicted = model.predict(X_test)\n",
    "        predict_accuracy = np.mean(predicted == y_test)\n",
    "        \n",
    "        if (model_name == 'Naive Bayes'):\n",
    "            nb_predic_acc = predict_accuracy\n",
    "        if (model_name == 'Support Vector Machines'):\n",
    "            svm_predic_acc = predict_accuracy\n",
    "        if(model_name == 'Random Forest'):\n",
    "            rf_predic_acc = predict_accuracy\n",
    "        if(model_name == 'Decision Tree'):\n",
    "            dec_acc = predict_accuracy\n",
    "        if(model_name == \"3-Nearest-Neighbors\"):\n",
    "            knn_acc = predict_accuracy\n",
    "        print(model_name + \" Prediction Accuracy:\")\n",
    "        print(predict_accuracy)\n",
    "        \n",
    "        target_names = ['Significant Risk', 'At Risk', 'Normal']\n",
    "        \n",
    "        print(classification_report(y_test, predicted, target_names=target_names))\n",
    "    return nb_predic_acc, svm_predic_acc, rf_predic_acc, dec_acc, knn_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def prediction_accuracy(model_name, X_train, X_test, y_train, y_test):\n",
    "#     model_dict = {\n",
    "#         'Naive Bayes': MultinomialNB(),\n",
    "#         'Support Vector Machines': SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42,max_iter=5, tol=None),\n",
    "#         'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=2,\n",
    "#                                      random_state=0),\n",
    "#         'Decision Tree': tree.DecisionTreeClassifier(),\n",
    "#         \"3-Nearest-Neighbors\": KNeighborsClassifier(n_neighbors=3)\n",
    "#     }\n",
    "\n",
    "#     model = model_dict[model_name]\n",
    "#     model.fit(X_train, y_train)\n",
    "\n",
    "#     predicted = model.predict(X_test)\n",
    "#     predict_accuracy = np.mean(predicted == y_test)\n",
    "\n",
    "#     return predict_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exp 3.1, Part 1: Run models on Non-Language Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mem_responses_no_text = X.loc[have_mem_indices]\n",
    "mem_responses_no_text.drop('FinalScore', axis=1, inplace=True) #Those with memory respones: all data besides text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-Nearest-Neighbors Prediction Accuracy:\n",
      "0.568965517241\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.14      0.12      0.13         8\n",
      "         At Risk       0.67      0.84      0.75        37\n",
      "          Normal       0.20      0.08      0.11        13\n",
      "\n",
      "     avg / total       0.49      0.57      0.52        58\n",
      "\n",
      "Support Vector Machines Prediction Accuracy:\n",
      "0.637931034483\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         8\n",
      "         At Risk       0.64      1.00      0.78        37\n",
      "          Normal       0.00      0.00      0.00        13\n",
      "\n",
      "     avg / total       0.41      0.64      0.50        58\n",
      "\n",
      "Naive Bayes Prediction Accuracy:\n",
      "0.448275862069\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.10      0.12      0.11         8\n",
      "         At Risk       0.67      0.59      0.63        37\n",
      "          Normal       0.20      0.23      0.21        13\n",
      "\n",
      "     avg / total       0.48      0.45      0.46        58\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/travisallen/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Prediction Accuracy:\n",
      "0.689655172414\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         8\n",
      "         At Risk       0.71      1.00      0.83        37\n",
      "          Normal       0.50      0.23      0.32        13\n",
      "\n",
      "     avg / total       0.57      0.69      0.60        58\n",
      "\n",
      "Decision Tree Prediction Accuracy:\n",
      "0.637931034483\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.11      0.12      0.12         8\n",
      "         At Risk       0.89      0.84      0.86        37\n",
      "          Normal       0.36      0.38      0.37        13\n",
      "\n",
      "     avg / total       0.66      0.64      0.65        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no_text_mem_train = mem_responses_no_text.loc[train_mem_idx]\n",
    "\n",
    "no_text_mem_dev = mem_responses_no_text.loc[dev_mem_idx]\n",
    "\n",
    "nb_no_text_mem_acc, svm_no_text_mem_acc, rf_no_text_mem_acc, dec_tree_no_text_mem_acc, knn_no_text_mem_acc = prediction_accuracies( no_text_mem_train, no_text_mem_dev, y_mem_train, y_mem_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(234, 124)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_text_mem_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "0.672413793103\n",
      "..........................................\n",
      "Lesson Count\n",
      "0.672413793103\n",
      "..........................................\n",
      "Activ. Start\n",
      "0.637931034483\n",
      "..........................................\n",
      "Activ. Compl.\n",
      "0.637931034483\n",
      "..........................................\n",
      "FullTime\n",
      "0.637931034483\n",
      "..........................................\n",
      "PartTime\n",
      "0.637931034483\n",
      "..........................................\n",
      "MemConcern\n",
      "0.637931034483\n",
      "..........................................\n",
      "ForgetFriends\n",
      "0.637931034483\n",
      "..........................................\n",
      "PutThings\n",
      "0.655172413793\n",
      "..........................................\n",
      "ForgetWords\n",
      "0.655172413793\n",
      "..........................................\n",
      "IsMemoryWorse\n",
      "0.620689655172\n",
      "..........................................\n",
      "FamilyHistory\n",
      "0.620689655172\n",
      "..........................................\n",
      "FamilyHistoryAge\n",
      "0.655172413793\n",
      "..........................................\n",
      "Supplements\n",
      "0.637931034483\n",
      "..........................................\n",
      "How many lessons did you complete on AlzU.org?_Response\n",
      "0.655172413793\n",
      "..........................................\n",
      "Please select the reasons why you have not yet completed the full 10 lesson course on AlzU.org. Select ALL that apply_Response\n",
      "0.655172413793\n",
      "..........................................\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Saw a doctor to discuss ways to lower AD risk?\n",
      "0.655172413793\n",
      "..........................................\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Participated in an AD prevention research study other than this one?\n",
      "0.655172413793\n",
      "..........................................\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Saw a doctor to be evaluated for memory loss?\n",
      "0.655172413793\n",
      "..........................................\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Saw a doctor to discuss ways to prevent memory loss?\n",
      "0.655172413793\n",
      "..........................................\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Saw a doctor to discuss an AD research study for a family member or friend?\n",
      "0.655172413793\n",
      "..........................................\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Was screened for, or enrolled in, an AD prevention clinical trial?\n",
      "0.655172413793\n",
      "..........................................\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Was screened for, or enrolled in, the Early Study AD prevention clinical trial?\n",
      "0.655172413793\n",
      "..........................................\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Was screened for, or enrolled in, the Generation Study AD prevention clinical trial?\n",
      "0.655172413793\n",
      "..........................................\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Joined the AD prevention registry endALZnow.org?\n",
      "0.655172413793\n",
      "..........................................\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Joined the AD prevention registry BrainHealthRegistry.org?\n",
      "0.655172413793\n",
      "..........................................\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Joined the Global Alzheimer's Platform \"TRC PAD\" AD prevention registry?\n",
      "0.655172413793\n",
      "..........................................\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Made a dietary change to improve my brain health?\n",
      "0.655172413793\n",
      "..........................................\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Increased exercise to improve my brain health?\n",
      "0.655172413793\n",
      "..........................................\n",
      "What would you be willing to do or to undergo in order to learn about your risk for developing AD someday in the future?_Take tests of my thinking and memory.\n",
      "0.655172413793\n",
      "..........................................\n",
      "What would you be willing to do or to undergo in order to learn about your risk for developing AD someday in the future?_Get a blood test.\n",
      "0.655172413793\n",
      "..........................................\n",
      "What would you be willing to do or to undergo in order to learn about your risk for developing AD someday in the future?_Get a brain scan (picture of the brain, like an MRI or cat scan).\n",
      "0.655172413793\n",
      "..........................................\n",
      "What would you be willing to do or to undergo in order to learn about your risk for developing AD someday in the future?_Get a genetic test to determine whether I have an Alzheimer’s risk gene.\n",
      "0.672413793103\n",
      "..........................................\n",
      "Please rate how likely it is that you would participate in the following types of AD research studies:_Requires answering questions on a computer and taking tests of memory skills?\n",
      "0.672413793103\n",
      "..........................................\n",
      "Please rate how likely it is that you would participate in the following types of AD research studies:_Randomly assigns half to receive a medicine and the other half to receive an inactive version?\n",
      "0.672413793103\n",
      "..........................................\n",
      "Please rate how likely it is that you would participate in the following types of AD research studies:_Randomly assigns half to make a dietary and exercise change, and the other half to continue as usual?\n",
      "0.672413793103\n",
      "..........................................\n",
      "Please rate how helpful or harmful each of the following would be._Seeing your doctor to discuss ways to lower AD risk\n",
      "0.672413793103\n",
      "..........................................\n",
      "Please rate how helpful or harmful each of the following would be._Participate in an AD prevention research study\n",
      "0.672413793103\n",
      "..........................................\n",
      "Please rate your level of agreement with the following questions._There is a strong possibility that I will develop AD\n",
      "0.672413793103\n",
      "..........................................\n",
      "Please rate your level of agreement with the following questions._Changing my lifestyle and health habits can help me reduce my chance of developing AD\n",
      "0.672413793103\n",
      "..........................................\n",
      "Please rate your level of agreement with the following questions._I have a lot to gain by changing my lifestyle and health behavior\n",
      "0.672413793103\n",
      "..........................................\n",
      "Please rate your level of agreement with the following questions._I feel that my chances of developing AD in the future are high\n",
      "0.672413793103\n",
      "..........................................\n",
      "Please rate your level of agreement with the following questions._I am too busy to change my lifestyle and health habits\n",
      "0.655172413793\n",
      "..........................................\n",
      "Please rate your level of agreement with the following questions._Family responsibilities make it hard for me to change my lifestyle and behavior\n",
      "0.655172413793\n",
      "..........................................\n",
      "Please rate your level of agreement with the following questions._When I think about AD my heart beats faster\n",
      "0.655172413793\n",
      "..........................................\n",
      "Please rate your level of agreement with the following questions._When I think about AD I feel nauseous\n",
      "0.637931034483\n",
      "..........................................\n",
      "Please rate your level of agreement with the following questions._The thought of AD scares me\n",
      "0.637931034483\n",
      "..........................................\n",
      "Please rate your level of agreement with the following questions._Changing lifestyle and behavior interferes with my schedule\n",
      "0.637931034483\n",
      "..........................................\n",
      "Please rate your level of agreement with the following questions._My chances of developing AD are great.\n",
      "0.637931034483\n",
      "..........................................\n",
      "Please rate your level of agreement with the following questions._I am certain that I can change my lifestyle and behavior so I can reduce the risk of developing AD\n",
      "0.655172413793\n",
      "..........................................\n",
      "Have you ever been told by a doctor or other health professional that you have diabetes or have high sugar levels in your blood or urine?_Response\n",
      "0.655172413793\n",
      "..........................................\n",
      "Have you ever been told by a doctor or other health professional that you have high cholesterol levels in the past 2 years or your cholesterol level is higher than 240mg/dL?_Response\n",
      "0.655172413793\n",
      "..........................................\n",
      "If you recall your most recent cholesterol results, please enter here:_Total Cholesterol\n",
      "0.655172413793\n",
      "..........................................\n",
      "If you recall your most recent cholesterol results, please enter here:_LDL (\"bad\" cholesterol)\n",
      "0.655172413793\n",
      "..........................................\n",
      "If you recall your most recent cholesterol results, please enter here:_HDL (\"good\" cholesterol)\n",
      "0.672413793103\n",
      "..........................................\n",
      "If you recall your most recent cholesterol results, please enter here:_Triglycerides\n",
      "0.655172413793\n",
      "..........................................\n",
      "If you recall your most recent blood pressure, please enter here. This is recorded as a two numbers, e.g., 130/80. Please enter the larger number (called Systolic) first, and the smaller number (called Diastolic), second._Systolic Blood Pressure\n",
      "0.655172413793\n",
      "..........................................\n",
      "If you recall your most recent blood pressure, please enter here. This is recorded as a two numbers, e.g., 130/80. Please enter the larger number (called Systolic) first, and the smaller number (called Diastolic), second._Diastolic Blood Pressure\n",
      "0.655172413793\n",
      "..........................................\n",
      "Have you ever had a head injury where you lost consciousness for more than 15 minutes?_Response\n",
      "0.655172413793\n",
      "..........................................\n",
      "Check best answer for each description._I was bothered by things that usually don’t bother me.\n",
      "0.655172413793\n",
      "..........................................\n",
      "Check best answer for each description._I had trouble keeping my mind on what I was doing.\n",
      "0.655172413793\n",
      "..........................................\n",
      "Check best answer for each description._I felt depressed.\n",
      "0.655172413793\n",
      "..........................................\n",
      "Check best answer for each description._I felt that everything I did was an effort.\n",
      "0.655172413793\n",
      "..........................................\n",
      "Check best answer for each description._I felt hopeful about the future.\n",
      "0.655172413793\n",
      "..........................................\n",
      "Check best answer for each description._I felt fearful.\n",
      "0.655172413793\n",
      "..........................................\n",
      "Check best answer for each description._My sleep was restless.\n",
      "0.655172413793\n",
      "..........................................\n",
      "Check best answer for each description._I was happy.\n",
      "0.655172413793\n",
      "..........................................\n",
      "Check best answer for each description._I felt lonely.\n",
      "0.672413793103\n",
      "..........................................\n",
      "Check best answer for each description._I could not “get going”\n",
      "0.672413793103\n",
      "..........................................\n",
      "During the last 7 days, on how many days did you do vigorous physical activities like heavy lifting, digging, aerobics, or fast bicycling? Think about only those physical activities that you did for at least 10 minutes at a time. Please answer in days per week._Open-Ended Response\n",
      "0.672413793103\n",
      "..........................................\n",
      "Again, think only about those physical activities that you did for at least 10 minutes at a time. During the last 7 days, on how many days did you do moderate physical activities like carrying light loads, bicycling at a regular pace, or double tennis? Please do not include walking, and please answer in days per week._Open-Ended Response\n",
      "0.655172413793\n",
      "..........................................\n",
      "During the last 7 days, on how many days did you walk for at least 10 minutes at a time? This includes walking at work and at home, walking to travel from place to place, and any other walking that you did solely for recreation, sport, exercise or leisure. Please answer in days per week._Open-Ended Response\n",
      "0.655172413793\n",
      "..........................................\n",
      "These questions ask about the amount and intensity of physical activity that you usually do._I rarely or never do any physical activities\n",
      "0.655172413793\n",
      "..........................................\n",
      "These questions ask about the amount and intensity of physical activity that you usually do._I do some light or moderate physical activities, but not every week\n",
      "0.655172413793\n",
      "..........................................\n",
      "These questions ask about the amount and intensity of physical activity that you usually do._I do some light physical activity every week\n",
      "0.655172413793\n",
      "..........................................\n",
      "These questions ask about the amount and intensity of physical activity that you usually do._I do moderate physical activities every week, but less than 30 minutes a day or 5 days a week\n",
      "0.655172413793\n",
      "..........................................\n",
      "These questions ask about the amount and intensity of physical activity that you usually do._I do vigorous physical activities every week, but less than 20 minutes a day or 3 days a week\n",
      "0.655172413793\n",
      "..........................................\n",
      "These questions ask about the amount and intensity of physical activity that you usually do._I do 30 minutes or more a day of moderate physical activities, 5 or more days a week\n",
      "0.655172413793\n",
      "..........................................\n",
      "These questions ask about the amount and intensity of physical activity that you usually do._I do 20 minutes or more a day of vigorous physical activities, 3 or more days a week\n",
      "0.655172413793\n",
      "..........................................\n",
      "These questions ask about the amount and intensity of physical activity that you usually do._I do activities to increase muscle strength, such as lifting weights or calisthenics, once a week or more\n",
      "0.655172413793\n",
      "..........................................\n",
      "These questions ask about the amount and intensity of physical activity that you usually do._I do activities to improve flexibility, such as stretching or yoga, once a week or more\n",
      "0.672413793103\n",
      "..........................................\n",
      "During the past year, how much time did you spend reading each day, including online reading?_hours per day:\n",
      "0.655172413793\n",
      "..........................................\n",
      "During the past year, how often were you engaging in..._Reading books (including online)\n",
      "0.672413793103\n",
      "..........................................\n",
      "During the past year, how often were you engaging in..._Reading newspaper (including online)\n",
      "0.672413793103\n",
      "..........................................\n",
      "During the past year, how often were you engaging in..._Reading magazines (including online)\n",
      "0.672413793103\n",
      "..........................................\n",
      "During the past year, how often were you engaging in..._Playing games (word game, checkers, mind teasers, etc)\n",
      "0.672413793103\n",
      "..........................................\n",
      "During the past year, how often were you engaging in..._Writing letters or emails\n",
      "0.655172413793\n",
      "..........................................\n",
      "During the past year, how often were you engaging in..._Use online social network activities\n",
      "0.655172413793\n",
      "..........................................\n",
      "During the past year, how often were you engaging in..._Participating in ‘brain training’ activities\n",
      "0.655172413793\n",
      "..........................................\n",
      "During the past year, how often were you engaging in..._Visiting a museum\n",
      "0.672413793103\n",
      "..........................................\n",
      "How many of your friends do you see or hear from at least once a month?_Response\n",
      "0.672413793103\n",
      "..........................................\n",
      "Are you satisfied with your relationships with friends and relatives?_Response\n",
      "0.672413793103\n",
      "..........................................\n",
      "How often do you participate in religious services or social, political or community groups?_Response\n",
      "0.672413793103\n",
      "..........................................\n",
      "Do you live alone or with other people?_Response\n",
      "0.672413793103\n",
      "..........................................\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Green Leafy Vegetables (1 cup leafy, 1/2 c. for cooked/raw chopped)\n",
      "0.672413793103\n",
      "..........................................\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Other Vegetables (1/2 c, e.g. broccoli, carrots, string beans)\n",
      "0.655172413793\n",
      "..........................................\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Berries (1/2 c, e.g. strawberries, blueberries)\n",
      "0.655172413793\n",
      "..........................................\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Other Fruits (1/2 c)\n",
      "0.655172413793\n",
      "..........................................\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Nuts (handful or 1/4-1/3 c.)\n",
      "0.672413793103\n",
      "..........................................\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Olive oil (1 tbs.)\n",
      "0.672413793103\n",
      "..........................................\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Butter, Cream (1 tablespoon)\n",
      "0.672413793103\n",
      "..........................................\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Regular Cheese (1 oz.)\n",
      "0.672413793103\n",
      "..........................................\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Whole grains (1 slice bread, 3/4 cup pasta/cereal)\n",
      "0.672413793103\n",
      "..........................................\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Fish (3 oz, not fried, not shell)\n",
      "0.672413793103\n",
      "..........................................\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Beans (1/2 c.)\n",
      "0.672413793103\n",
      "..........................................\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Poultry (3 oz, not fried)\n",
      "0.672413793103\n",
      "..........................................\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Red meat (3 oz steak, ham, burgers)\n",
      "0.672413793103\n",
      "..........................................\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Fast foods\n",
      "0.672413793103\n",
      "..........................................\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Pastries & Sweets\n",
      "0.672413793103\n",
      "..........................................\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Wine (glasses per week; 1 glass = 5 oz)\n",
      "0.672413793103\n",
      "..........................................\n",
      "How many servings of each of the following foods do you have per week? Enter a numerical value or zero._Other alcohol (serving = 1.5 oz liquor or 12 oz beer)\n",
      "0.672413793103\n",
      "..........................................\n",
      "On average, what percent of your diet is made up of carbohydrates?_Response\n",
      "0.672413793103\n",
      "..........................................\n",
      "How many nights per week do you fast (meaning no calories at all) from dinner until breakfast lasting at least ~12 hours? (Please enter a number from 0-7)_Open-Ended Response\n",
      "0.672413793103\n",
      "..........................................\n",
      "In the past 12 months, how often did you eat fish or seafood that is not fried?_Response\n",
      "0.672413793103\n",
      "..........................................\n",
      "<https://www.alzu.org/assets/images/alcohol-volume.PNG>_Response\n",
      "0.655172413793\n",
      "..........................................\n",
      "How many drinks do you have on a typical day when you are drinking?_Response\n",
      "0.672413793103\n",
      "..........................................\n",
      "Do you, or have you ever, smoked cigarettes, cigars, pipes or any other tobacco products?_Response\n",
      "0.672413793103\n",
      "..........................................\n",
      "Have you ever been involved in occupations that require you to mix, apply or load any pesticides, herbicides, weed killers, fumigants or fungicides?_Response\n",
      "0.672413793103\n",
      "..........................................\n",
      "lc_Open-Ended Response\n",
      "0.655172413793\n",
      "..........................................\n",
      "Age\n",
      "0.672413793103\n",
      "..........................................\n",
      "Days_As_Member\n",
      "0.620689655172\n",
      "..........................................\n"
     ]
    }
   ],
   "source": [
    "for no_text_mem_col in no_text_mem_train.columns:\n",
    "    dropped_X_train = no_text_mem_train.drop(no_text_mem_col, axis=1)\n",
    "    dropped_X_dev = no_text_mem_dev.drop(no_text_mem_col, axis=1)\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=2,\n",
    "                                     random_state=0)\n",
    "    model.fit(dropped_X_train, y_mem_train)\n",
    "\n",
    "    predicted = model.predict(dropped_X_dev)\n",
    "    predict_accuracy = np.mean(predicted == y_mem_dev)\n",
    "    \n",
    "    if(predict_accuracy < rf_no_text_mem_acc):\n",
    "        print(no_text_mem_col)\n",
    "        print(predict_accuracy)\n",
    "        print(\"..........................................\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exp 3.2, Part 2: Run Models on Language Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364,)\n"
     ]
    }
   ],
   "source": [
    "mem_responses = all_data.loc[have_mem_indices].iloc[:,memory_prompt_idx] #Just responses themselves\n",
    "print(mem_responses.shape)\n",
    "\n",
    "memory_response_df = mem_responses.to_frame(name='Response')\n",
    "memory_response_df['NumWords'] = memory_response_df.apply(lambda row: word_count(row['Response']), axis=1)\n",
    "memory_response_df['NumSentences'] = memory_response_df.apply(lambda row: sentence_count(row['Response'].decode('utf-8')), axis=1)\n",
    "memory_response_df['V'] = memory_response_df.apply(lambda row: uniq_words(row['Response']), axis=1)\n",
    "memory_response_df['V1'] = memory_response_df.apply(lambda row: single_appearances(row['Response']), axis=1)\n",
    "memory_response_df['MATTR'] = memory_response_df.apply(lambda row: calc_MATTR(row['Response']), axis=1)\n",
    "memory_response_df['CoordinatingConjunctions'] = memory_response_df.apply(lambda row: coord_conjunctions_init(row['Response'].decode('utf-8')), axis=1)\n",
    "memory_response_df['Misspellings'] = memory_response_df.apply(lambda row: misspelt(row['Response'].decode('utf-8')), axis=1)\n",
    "memory_response_df['NounRate'] = memory_response_df.apply(lambda row: pos_rate(row['Response'].decode('utf-8'),nn=True), axis=1)\n",
    "\n",
    "memory_response_df['VerbRate'] = memory_response_df.apply(lambda row: pos_rate(row['Response'].decode('utf-8'),vb=True), axis=1)\n",
    "\n",
    "memory_response_df['PronounRate'] = memory_response_df.apply(lambda row: pos_rate(row['Response'].decode('utf-8'),pn=True), axis=1) \n",
    "\n",
    "memory_response_df['ProperNounRate'] = memory_response_df.apply(lambda row: pos_rate(row['Response'].decode('utf-8'),proper=True), axis=1) \n",
    "\n",
    "memory_response_df.drop('Response', axis=1, inplace=True) #get rid of actual text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumWords</th>\n",
       "      <th>NumSentences</th>\n",
       "      <th>V</th>\n",
       "      <th>V1</th>\n",
       "      <th>MATTR</th>\n",
       "      <th>CoordinatingConjunctions</th>\n",
       "      <th>Misspellings</th>\n",
       "      <th>NounRate</th>\n",
       "      <th>VerbRate</th>\n",
       "      <th>PronounRate</th>\n",
       "      <th>ProperNounRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28844</th>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>27</td>\n",
       "      <td>0.968571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.204545</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28858</th>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>39</td>\n",
       "      <td>0.967857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.184615</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28867</th>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>44</td>\n",
       "      <td>0.972619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.182796</td>\n",
       "      <td>0.139785</td>\n",
       "      <td>0.382353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28881</th>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>38</td>\n",
       "      <td>0.982222</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29004</th>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>0.945161</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       NumWords  NumSentences   V  V1     MATTR  CoordinatingConjunctions  Misspellings  NounRate  VerbRate  PronounRate  ProperNounRate\n",
       "28844        44             2  34  27  0.968571                         0             1  0.181818  0.204545     0.159091        0.466667\n",
       "28858        65             4  49  39  0.967857                         0             0  0.230769  0.184615     0.123077        0.307692\n",
       "28867        93             6  60  44  0.972619                         0             0  0.225806  0.182796     0.139785        0.382353\n",
       "28881        54             2  45  38  0.982222                         0             2  0.111111  0.259259     0.148148        0.571429\n",
       "29004        40             2  30  23  0.945161                         0             0  0.150000  0.175000     0.175000        0.500000"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_response_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-Nearest-Neighbors Prediction Accuracy:\n",
      "0.603448275862\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         8\n",
      "         At Risk       0.65      0.89      0.75        37\n",
      "          Normal       0.40      0.15      0.22        13\n",
      "\n",
      "     avg / total       0.50      0.60      0.53        58\n",
      "\n",
      "Support Vector Machines Prediction Accuracy:\n",
      "0.637931034483\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         8\n",
      "         At Risk       0.64      1.00      0.78        37\n",
      "          Normal       0.00      0.00      0.00        13\n",
      "\n",
      "     avg / total       0.41      0.64      0.50        58\n",
      "\n",
      "Naive Bayes Prediction Accuracy:\n",
      "0.637931034483\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         8\n",
      "         At Risk       0.64      1.00      0.78        37\n",
      "          Normal       0.00      0.00      0.00        13\n",
      "\n",
      "     avg / total       0.41      0.64      0.50        58\n",
      "\n",
      "Random Forest Prediction Accuracy:\n",
      "0.637931034483\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         8\n",
      "         At Risk       0.64      1.00      0.78        37\n",
      "          Normal       0.00      0.00      0.00        13\n",
      "\n",
      "     avg / total       0.41      0.64      0.50        58\n",
      "\n",
      "Decision Tree Prediction Accuracy:\n",
      "0.551724137931\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.25      0.12      0.17         8\n",
      "         At Risk       0.64      0.76      0.69        37\n",
      "          Normal       0.30      0.23      0.26        13\n",
      "\n",
      "     avg / total       0.51      0.55      0.52        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_mem_train = memory_response_df.loc[train_mem_idx]\n",
    "\n",
    "text_mem_dev = memory_response_df.loc[dev_mem_idx]\n",
    "\n",
    "nb_text_mem_acc, svm_text_mem_acc, rf_text_mem_acc, dec_tree_text_mem_acc, knn_text_mem_acc = prediction_accuracies( text_mem_train, text_mem_dev, y_mem_train, y_mem_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exp 3.2, Part 3:  Combine Text and No-Text and Test Same Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_mem = mem_responses_no_text.join(memory_response_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_mem_train = combined_mem.loc[train_mem_idx]\n",
    "combined_mem_dev = combined_mem.loc[dev_mem_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#combined_mem_train, combined_mem_test, combined_score_train, combined_score_test = train_test_split(combined_mem,mem_THREE_class_cft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-Nearest-Neighbors Prediction Accuracy:\n",
      "0.551724137931\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.25      0.25      0.25         8\n",
      "         At Risk       0.67      0.81      0.73        37\n",
      "          Normal       0.00      0.00      0.00        13\n",
      "\n",
      "     avg / total       0.46      0.55      0.50        58\n",
      "\n",
      "Support Vector Machines Prediction Accuracy:\n",
      "0.637931034483\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         8\n",
      "         At Risk       0.64      1.00      0.78        37\n",
      "          Normal       0.00      0.00      0.00        13\n",
      "\n",
      "     avg / total       0.41      0.64      0.50        58\n",
      "\n",
      "Naive Bayes Prediction Accuracy:\n",
      "0.465517241379\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.12      0.12      0.12         8\n",
      "         At Risk       0.68      0.62      0.65        37\n",
      "          Normal       0.19      0.23      0.21        13\n",
      "\n",
      "     avg / total       0.49      0.47      0.48        58\n",
      "\n",
      "Random Forest Prediction Accuracy:\n",
      "0.620689655172\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         8\n",
      "         At Risk       0.66      0.95      0.78        37\n",
      "          Normal       0.20      0.08      0.11        13\n",
      "\n",
      "     avg / total       0.47      0.62      0.52        58\n",
      "\n",
      "Decision Tree Prediction Accuracy:\n",
      "0.706896551724\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.29      0.25      0.27         8\n",
      "         At Risk       0.86      0.86      0.86        37\n",
      "          Normal       0.50      0.54      0.52        13\n",
      "\n",
      "     avg / total       0.70      0.71      0.70        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_all_mem_acc, svm_all_mem_acc, rf_all_mem_acc, dec_all_text_mem_acc, knn_all_mem_acc = prediction_accuracies( combined_mem_train, combined_mem_dev, y_mem_train, y_mem_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Exp 3.2, Part 4:  Add Text Features one at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experiment, we look only at the effect on Random Forest, which showed an improved prediction accuracy for JUST Lang data and Lang + Non-Lang data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Tested: NumWords\n",
      "0.706896551724\n",
      "................................\n",
      "Feature Tested: NumSentences\n",
      "0.706896551724\n",
      "................................\n",
      "Feature Tested: V\n",
      "0.706896551724\n",
      "................................\n",
      "Feature Tested: V1\n",
      "0.706896551724\n",
      "................................\n",
      "Feature Tested: MATTR\n",
      "0.706896551724\n",
      "................................\n",
      "Feature Tested: CoordinatingConjunctions\n",
      "0.706896551724\n",
      "................................\n",
      "Feature Tested: Misspellings\n",
      "0.706896551724\n",
      "................................\n",
      "Feature Tested: VerbRate\n",
      "0.706896551724\n",
      "................................\n",
      "Feature Tested: PronounRate\n",
      "0.706896551724\n",
      "................................\n",
      "Feature Tested: ProperNounRate\n",
      "0.724137931034\n",
      "................................\n"
     ]
    }
   ],
   "source": [
    "for idx, mem_resp_col in enumerate(memory_response_df.columns):\n",
    "    feature_column = memory_response_df[mem_resp_col]\n",
    "    concatenated = mem_responses_no_text.join(feature_column)\n",
    "\n",
    "    X_train = concatenated.loc[train_mem_idx]\n",
    "    X_dev = concatenated.loc[dev_mem_idx]\n",
    "   \n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=5,\n",
    "                                     random_state=0)\n",
    "    model.fit(X_train, y_mem_train)\n",
    "\n",
    "    predicted = model.predict(X_dev)\n",
    "    predict_accuracy = np.mean(predicted == y_mem_dev)\n",
    "    \n",
    "    if (predict_accuracy > rf_no_text_mem_acc):\n",
    "        print(\"Feature Tested: \" + mem_resp_col)\n",
    "        print(predict_accuracy)\n",
    "        print(\"................................\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we take the best individually-performing feature additions and combine them with non-text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.724137931034\n"
     ]
    }
   ],
   "source": [
    "good_mem_text_features = ['NumSentences', 'V', 'MATTR', 'Misspellings', 'VerbRate']\n",
    "\n",
    "combined_good = mem_responses_no_text.join(memory_response_df[good_mem_text_features])\n",
    "\n",
    "X_train = concatenated.loc[train_mem_idx]\n",
    "X_dev = concatenated.loc[dev_mem_idx]\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5,\n",
    "                                 random_state=0)\n",
    "model.fit(X_train, y_mem_train)\n",
    "\n",
    "predicted = model.predict(X_dev)\n",
    "predict_accuracy = np.mean(predicted == y_mem_dev)\n",
    "\n",
    "print(predict_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exp 4: Do the same with Tech Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(424,)\n"
     ]
    }
   ],
   "source": [
    "have_tech_indices = all_data.index[all_data[tech_prompt] != \"\"] #Gets the indices of rows that have tech response\n",
    "print(have_tech_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(424,)\n"
     ]
    }
   ],
   "source": [
    "tech_cft_scores = pd.Series(all_data.loc[have_tech_indices]['FinalScore'], index=have_tech_indices) #Will be used as target for both language and non-language experiments\n",
    "print(tech_cft_scores.shape)\n",
    "\n",
    "#replace NaN with mean\n",
    "tech_cft_median_score = tech_cft_scores.median()\n",
    "tech_cft_mean_score = tech_cft_scores.mean()\n",
    "tech_cft_scores.fillna(tech_cft_mean_score, inplace=True)\n",
    "\n",
    "\n",
    "### MAKE A THREE-CLASS TARGET, BASED ON CFT WEBSITE\n",
    "tech_THREE_class_cft = tech_cft_scores.copy()\n",
    "\n",
    "tech_THREE_class_cft = tech_THREE_class_cft.where(tech_THREE_class_cft > 38, 0)\n",
    "tech_THREE_class_cft = tech_THREE_class_cft.where(tech_THREE_class_cft < 43, 2)\n",
    "tech_THREE_class_cft = tech_THREE_class_cft.where(((tech_THREE_class_cft == 0) | (tech_THREE_class_cft == 2)), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold Out Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "held_out_test_tech_idx = np.random.choice(have_tech_indices,(1,int(.20*len(have_tech_indices))),replace=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# held_out_test_tech_idx = ['38874', '44404', '29421', '38698', '40693', '49414', '41751',\n",
    "#         '56026', '41612', '51136', '38611', '56084', '45787', '56784',\n",
    "#         '39171', '53312', '47004', '56291', '49527', '38604', '40084',\n",
    "#         '31837', '45294', '55091', '54529', '59200', '28867', '50329',\n",
    "#         '29733', '38820', '35401', '28926', '42044', '40020', '55165',\n",
    "#         '54881', '39399', '48595', '54884', '48604', '57444', '55417',\n",
    "#         '31120', '43247', '43004', '39012', '31795', '30801', '29079',\n",
    "#         '39582', '58441', '53994', '46323', '55642', '40227', '49925',\n",
    "#         '30279', '39452', '43624', '45993', '31871', '43507', '39221',\n",
    "#         '29088', '41000', '53125', '59703', '38700', '40189', '43429',\n",
    "#         '32565', '57407', '44151', '59243', '39880', '29258', '45700',\n",
    "#         '37300', '41703', '31008', '30762', '28932', '39942', '35914']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_tech_heldout = tech_THREE_class_cft[held_out_test_tech_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84,)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tech_heldout.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dev_tech_ix = [m for m in have_tech_indices if m not in held_out_test_tech_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_tech_idx = np.random.choice(train_dev_tech_ix,(1,int(.20*len(train_dev_tech_ix))),replace=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dev_tech_idx = ['40854', '44234', '51913', '41997', '29059', '45772', '40595',\n",
    "#         '52023', '48606', '38440', '51713', '57709', '39539', '46170',\n",
    "#         '30642', '32846', '31945', '43248', '34753', '57299', '46047',\n",
    "#         '51163', '30522', '38686', '43155', '34515', '38754', '44730',\n",
    "#         '29073', '40732', '60026', '41626', '59232', '44439', '46055',\n",
    "#         '38603', '30865', '38492', '29090', '38830', '39830', '45647',\n",
    "#         '57812', '43830', '42443', '56818', '39901', '52767', '38944',\n",
    "#         '46166', '29333', '54101', '29886', '55823', '48498', '32233',\n",
    "#         '56239', '44235', '38803', '57834', '29805', '47438', '40530',\n",
    "#         '56110', '38538', '54924', '45821', '53050']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_tech_dev = tech_THREE_class_cft[dev_tech_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68,)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tech_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tech_idx =  [i for i in train_dev_tech_ix if i not in dev_tech_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_tech_train = tech_THREE_class_cft[train_tech_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exp 4.1, Part 1: Run models on Non-Language Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tech_responses_no_text = X.loc[have_tech_indices]\n",
    "tech_responses_no_text.drop('FinalScore', axis=1, inplace=True) #Those with tech respones: all data besides text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-Nearest-Neighbors Prediction Accuracy:\n",
      "0.588235294118\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         7\n",
      "         At Risk       0.73      0.80      0.76        50\n",
      "          Normal       0.00      0.00      0.00        11\n",
      "\n",
      "     avg / total       0.53      0.59      0.56        68\n",
      "\n",
      "Support Vector Machines Prediction Accuracy:\n",
      "0.161764705882\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         7\n",
      "         At Risk       0.00      0.00      0.00        50\n",
      "          Normal       0.16      1.00      0.28        11\n",
      "\n",
      "     avg / total       0.03      0.16      0.05        68\n",
      "\n",
      "Naive Bayes Prediction Accuracy:\n",
      "0.485294117647\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.21      0.43      0.29         7\n",
      "         At Risk       0.87      0.52      0.65        50\n",
      "          Normal       0.17      0.36      0.23        11\n",
      "\n",
      "     avg / total       0.69      0.49      0.54        68\n",
      "\n",
      "Random Forest Prediction Accuracy:\n",
      "0.75\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         7\n",
      "         At Risk       0.79      0.96      0.86        50\n",
      "          Normal       0.43      0.27      0.33        11\n",
      "\n",
      "     avg / total       0.65      0.75      0.69        68\n",
      "\n",
      "Decision Tree Prediction Accuracy:\n",
      "0.823529411765\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.50      0.14      0.22         7\n",
      "         At Risk       0.94      0.96      0.95        50\n",
      "          Normal       0.47      0.64      0.54        11\n",
      "\n",
      "     avg / total       0.82      0.82      0.81        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no_text_tech_train = tech_responses_no_text.loc[train_tech_idx]\n",
    "\n",
    "no_text_tech_dev = tech_responses_no_text.loc[dev_tech_idx]\n",
    "\n",
    "nb_no_text_tech_acc, svm_no_text_tech_acc, rf_no_text_tech_acc, dec_tree_no_text_tech_acc, knn_no_text_tech_acc = prediction_accuracies( no_text_tech_train, no_text_tech_dev, y_tech_train, y_tech_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Exp 4.1, Part 2: Run models on Language Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(424,)\n"
     ]
    }
   ],
   "source": [
    "tech_responses = all_data.loc[have_tech_indices].iloc[:,tech_prompt_idx] #Just responses themselves\n",
    "print(tech_responses.shape)\n",
    "\n",
    "tech_response_df = tech_responses.to_frame(name='Response')\n",
    "tech_response_df['NumWords'] = tech_response_df.apply(lambda row: word_count(row['Response']), axis=1)\n",
    "tech_response_df['NumSentences'] = tech_response_df.apply(lambda row: sentence_count(row['Response'].decode('utf-8')), axis=1)\n",
    "tech_response_df['V'] = tech_response_df.apply(lambda row: uniq_words(row['Response']), axis=1)\n",
    "tech_response_df['V1'] = tech_response_df.apply(lambda row: single_appearances(row['Response']), axis=1)\n",
    "tech_response_df['MATTR'] = tech_response_df.apply(lambda row: calc_MATTR(row['Response']), axis=1)\n",
    "tech_response_df['CoordinatingConjunctions'] = tech_response_df.apply(lambda row: coord_conjunctions_init(row['Response'].decode('utf-8')), axis=1)\n",
    "tech_response_df['Misspellings'] = tech_response_df.apply(lambda row: misspelt(row['Response'].decode('utf-8')), axis=1)\n",
    "tech_response_df['NounRate'] = tech_response_df.apply(lambda row: pos_rate(row['Response'].decode('utf-8'),nn=True), axis=1)\n",
    "\n",
    "tech_response_df['VerbRate'] = tech_response_df.apply(lambda row: pos_rate(row['Response'].decode('utf-8'),vb=True), axis=1)\n",
    "\n",
    "tech_response_df['PronounRate'] = tech_response_df.apply(lambda row: pos_rate(row['Response'].decode('utf-8'),pn=True), axis=1) \n",
    "\n",
    "tech_response_df['ProperNounRate'] = tech_response_df.apply(lambda row: pos_rate(row['Response'].decode('utf-8'),proper=True), axis=1) \n",
    "\n",
    "tech_response_df.drop('Response', axis=1, inplace=True) #get rid of actual text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-Nearest-Neighbors Prediction Accuracy:\n",
      "0.661764705882\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.20      0.29      0.24         7\n",
      "         At Risk       0.79      0.84      0.82        50\n",
      "          Normal       0.20      0.09      0.13        11\n",
      "\n",
      "     avg / total       0.64      0.66      0.64        68\n",
      "\n",
      "Support Vector Machines Prediction Accuracy:\n",
      "0.132352941176\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.09      0.86      0.17         7\n",
      "         At Risk       0.75      0.06      0.11        50\n",
      "          Normal       0.00      0.00      0.00        11\n",
      "\n",
      "     avg / total       0.56      0.13      0.10        68\n",
      "\n",
      "Naive Bayes Prediction Accuracy:\n",
      "0.735294117647\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         7\n",
      "         At Risk       0.75      1.00      0.85        50\n",
      "          Normal       0.00      0.00      0.00        11\n",
      "\n",
      "     avg / total       0.55      0.74      0.63        68\n",
      "\n",
      "Random Forest Prediction Accuracy:\n",
      "0.735294117647\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         7\n",
      "         At Risk       0.74      1.00      0.85        50\n",
      "          Normal       0.00      0.00      0.00        11\n",
      "\n",
      "     avg / total       0.54      0.74      0.62        68\n",
      "\n",
      "Decision Tree Prediction Accuracy:\n",
      "0.529411764706\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         7\n",
      "         At Risk       0.71      0.68      0.69        50\n",
      "          Normal       0.17      0.18      0.17        11\n",
      "\n",
      "     avg / total       0.55      0.53      0.54        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_tech_train = tech_response_df.loc[train_tech_idx]\n",
    "\n",
    "text_tech_dev = tech_response_df.loc[dev_tech_idx]\n",
    "\n",
    "nb_text_tech_acc, svm_text_tech_acc, rf_text_tech_acc, dec_tree_text_tech_acc, knn_text_tech_acc = prediction_accuracies( text_tech_train, text_tech_dev, y_tech_train, y_tech_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exp 4.2, Part 3:  Combine Text and No-Text and Test Same Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_tech = tech_responses_no_text.join(tech_response_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_tech_train = combined_tech.loc[train_tech_idx]\n",
    "combined_tech_dev = combined_tech.loc[dev_tech_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-Nearest-Neighbors Prediction Accuracy:\n",
      "0.558823529412\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         7\n",
      "         At Risk       0.73      0.74      0.73        50\n",
      "          Normal       0.14      0.09      0.11        11\n",
      "\n",
      "     avg / total       0.56      0.56      0.56        68\n",
      "\n",
      "Support Vector Machines Prediction Accuracy:\n",
      "0.220588235294\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         7\n",
      "         At Risk       0.50      0.12      0.19        50\n",
      "          Normal       0.16      0.82      0.27        11\n",
      "\n",
      "     avg / total       0.39      0.22      0.19        68\n",
      "\n",
      "Naive Bayes Prediction Accuracy:\n",
      "0.470588235294\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.08      0.14      0.10         7\n",
      "         At Risk       0.82      0.54      0.65        50\n",
      "          Normal       0.18      0.36      0.24        11\n",
      "\n",
      "     avg / total       0.64      0.47      0.53        68\n",
      "\n",
      "Random Forest Prediction Accuracy:\n",
      "0.764705882353\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         7\n",
      "         At Risk       0.81      0.96      0.88        50\n",
      "          Normal       0.44      0.36      0.40        11\n",
      "\n",
      "     avg / total       0.67      0.76      0.71        68\n",
      "\n",
      "Decision Tree Prediction Accuracy:\n",
      "0.823529411765\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.75      0.43      0.55         7\n",
      "         At Risk       0.86      0.96      0.91        50\n",
      "          Normal       0.62      0.45      0.53        11\n",
      "\n",
      "     avg / total       0.81      0.82      0.81        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_all_tech_acc, svm_all_tech_acc, rf_all_tech_acc, dec_all_text_tech_acc, knn_all_tech_acc = prediction_accuracies( combined_tech_train, combined_tech_dev, y_tech_train, y_tech_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Exp 4.2, Part 4:  Add Text Features one at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experiment, we look only at the effect on Random Forest, which showed an improved prediction accuracy for JUST Lang data and Lang + Non-Lang data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Tested: NumWords\n",
      "0.852941176471\n",
      "................................\n",
      "Feature Tested: NumSentences\n",
      "0.838235294118\n",
      "................................\n",
      "Feature Tested: V\n",
      "0.823529411765\n",
      "................................\n",
      "Feature Tested: V1\n",
      "0.838235294118\n",
      "................................\n",
      "Feature Tested: MATTR\n",
      "0.823529411765\n",
      "................................\n",
      "Feature Tested: CoordinatingConjunctions\n",
      "0.823529411765\n",
      "................................\n",
      "Feature Tested: Misspellings\n",
      "0.838235294118\n",
      "................................\n",
      "Feature Tested: NounRate\n",
      "0.808823529412\n",
      "................................\n",
      "Feature Tested: VerbRate\n",
      "0.823529411765\n",
      "................................\n",
      "Feature Tested: PronounRate\n",
      "0.823529411765\n",
      "................................\n",
      "Feature Tested: ProperNounRate\n",
      "0.838235294118\n",
      "................................\n"
     ]
    }
   ],
   "source": [
    "for idx, tech_resp_col in enumerate(tech_response_df.columns):\n",
    "    feature_column = tech_response_df[tech_resp_col]\n",
    "    concatenated = tech_responses_no_text.join(feature_column)\n",
    "\n",
    "    X_train = concatenated.loc[train_tech_idx]\n",
    "    X_dev = concatenated.loc[dev_tech_idx]\n",
    "   \n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=5,\n",
    "                                     random_state=0)\n",
    "    model.fit(X_train, y_tech_train)\n",
    "\n",
    "    predicted = model.predict(X_dev)\n",
    "    predict_accuracy = np.mean(predicted == y_tech_dev)\n",
    "    \n",
    "    #if (predict_accuracy > rf_no_text_tech_acc):\n",
    "    print(\"Feature Tested: \" + tech_resp_col)\n",
    "    print(predict_accuracy)\n",
    "    print(\"................................\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# FINAL EXPERIMENTS USING HELD-OUT TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory, no Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-Nearest-Neighbors Prediction Accuracy:\n",
      "0.652777777778\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.09      0.14      0.11         7\n",
      "         At Risk       0.77      0.83      0.80        53\n",
      "          Normal       0.50      0.17      0.25        12\n",
      "\n",
      "     avg / total       0.66      0.65      0.64        72\n",
      "\n",
      "Support Vector Machines Prediction Accuracy:\n",
      "0.736111111111\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         7\n",
      "         At Risk       0.74      1.00      0.85        53\n",
      "          Normal       0.00      0.00      0.00        12\n",
      "\n",
      "     avg / total       0.54      0.74      0.62        72\n",
      "\n",
      "Naive Bayes Prediction Accuracy:\n",
      "0.597222222222\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.18      0.29      0.22         7\n",
      "         At Risk       0.87      0.62      0.73        53\n",
      "          Normal       0.35      0.67      0.46        12\n",
      "\n",
      "     avg / total       0.71      0.60      0.63        72\n",
      "\n",
      "Random Forest Prediction Accuracy:\n",
      "0.75\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         7\n",
      "         At Risk       0.75      1.00      0.85        53\n",
      "          Normal       1.00      0.08      0.15        12\n",
      "\n",
      "     avg / total       0.72      0.75      0.65        72\n",
      "\n",
      "Decision Tree Prediction Accuracy:\n",
      "0.722222222222\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.38      0.43      0.40         7\n",
      "         At Risk       0.90      0.83      0.86        53\n",
      "          Normal       0.33      0.42      0.37        12\n",
      "\n",
      "     avg / total       0.75      0.72      0.74        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no_text_mem_train = mem_responses_no_text.loc[train_mem_idx]\n",
    "\n",
    "no_text_mem_test = mem_responses_no_text.loc[held_out_test_mem_idx]\n",
    "\n",
    "final_nb_no_text_mem_acc, final_svm_no_text_mem_acc, final_rf_no_text_mem_acc, final_dec_tree_no_text_mem_acc, final_knn_no_text_mem_acc = prediction_accuracies( no_text_mem_train, no_text_mem_test, y_mem_train, y_mem_heldout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#having trouble getting this from the classification report so writing this down from printed results for now\n",
    "mem_no_text_precision = (20, 0, 0, 12, 0) #nb,svm, rf, dt,knn\n",
    "mem_no_text_recall = (22, 0, 0, 11, 0)\n",
    "mem_no_text_f1 = (21, 0, 0, 12, 0)\n",
    "\n",
    "\n",
    "# mem_no_text_knn_precision, mem_no_text_knn_recall, mem_no_text_knn_f1 = 51, 60, 55\n",
    "# mem_no_text_svm_precision, mem_no_text_svm_recall, mem_no_text_svm_f1 = 46,67,54\n",
    "# mem_no_text_nb_precision, mem_no_text_nb_recall, mem_no_text_knn_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "0.736111111111\n",
      "..........................................\n",
      "Lesson Count\n",
      "0.722222222222\n",
      "..........................................\n",
      "ForgetFriends\n",
      "0.736111111111\n",
      "..........................................\n",
      "PutThings\n",
      "0.736111111111\n",
      "..........................................\n",
      "LoseWay\n",
      "0.736111111111\n",
      "..........................................\n",
      "IsMemoryWorse\n",
      "0.736111111111\n",
      "..........................................\n",
      "FamilyHistory\n",
      "0.736111111111\n",
      "..........................................\n",
      "FamilyHistoryAge\n",
      "0.736111111111\n",
      "..........................................\n",
      "Supplements\n",
      "0.736111111111\n",
      "..........................................\n",
      "How many lessons did you complete on AlzU.org?_Response\n",
      "0.722222222222\n",
      "..........................................\n",
      "Please select the reasons why you have not yet completed the full 10 lesson course on AlzU.org. Select ALL that apply_Response\n",
      "0.722222222222\n",
      "..........................................\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Saw a doctor to discuss ways to lower AD risk?\n",
      "0.722222222222\n",
      "..........................................\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Saw a doctor to discuss ways to prevent memory loss?\n",
      "0.736111111111\n",
      "..........................................\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Saw a doctor to discuss an AD research study for a family member or friend?\n",
      "0.736111111111\n",
      "..........................................\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Was screened for, or enrolled in, an AD prevention clinical trial?\n",
      "0.736111111111\n",
      "..........................................\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Was screened for, or enrolled in, the Early Study AD prevention clinical trial?\n",
      "0.736111111111\n",
      "..........................................\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Was screened for, or enrolled in, the Generation Study AD prevention clinical trial?\n",
      "0.736111111111\n",
      "..........................................\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Joined the AD prevention registry endALZnow.org?\n",
      "0.736111111111\n",
      "..........................................\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Joined the AD prevention registry BrainHealthRegistry.org?\n",
      "0.736111111111\n",
      "..........................................\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Joined the Global Alzheimer's Platform \"TRC PAD\" AD prevention registry?\n",
      "0.736111111111\n",
      "..........................................\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Made a dietary change to improve my brain health?\n",
      "0.736111111111\n",
      "..........................................\n",
      "Below are listed several behaviors related to AD. Thinking back over the past three months, please indicate to what extent you have thought about or already done something related to the following behaviors:_Increased exercise to improve my brain health?\n",
      "0.736111111111\n",
      "..........................................\n",
      "Check best answer for each description._I had trouble keeping my mind on what I was doing.\n",
      "0.736111111111\n",
      "..........................................\n",
      "Check best answer for each description._I felt depressed.\n",
      "0.736111111111\n",
      "..........................................\n",
      "Check best answer for each description._I felt that everything I did was an effort.\n",
      "0.736111111111\n",
      "..........................................\n",
      "Check best answer for each description._I felt hopeful about the future.\n",
      "0.736111111111\n",
      "..........................................\n",
      "Check best answer for each description._I felt fearful.\n",
      "0.736111111111\n",
      "..........................................\n",
      "Check best answer for each description._My sleep was restless.\n",
      "0.736111111111\n",
      "..........................................\n",
      "Check best answer for each description._I was happy.\n",
      "0.736111111111\n",
      "..........................................\n",
      "Check best answer for each description._I felt lonely.\n",
      "0.736111111111\n",
      "..........................................\n",
      "Check best answer for each description._I could not “get going”\n",
      "0.736111111111\n",
      "..........................................\n",
      "During the last 7 days, on how many days did you do vigorous physical activities like heavy lifting, digging, aerobics, or fast bicycling? Think about only those physical activities that you did for at least 10 minutes at a time. Please answer in days per week._Open-Ended Response\n",
      "0.736111111111\n",
      "..........................................\n",
      "Again, think only about those physical activities that you did for at least 10 minutes at a time. During the last 7 days, on how many days did you do moderate physical activities like carrying light loads, bicycling at a regular pace, or double tennis? Please do not include walking, and please answer in days per week._Open-Ended Response\n",
      "0.736111111111\n",
      "..........................................\n"
     ]
    }
   ],
   "source": [
    "for no_text_mem_col in no_text_mem_train.columns:\n",
    "    dropped_X_train = no_text_mem_train.drop(no_text_mem_col, axis=1)\n",
    "    dropped_X_test = no_text_mem_test.drop(no_text_mem_col, axis=1)\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=2,\n",
    "                                     random_state=0)\n",
    "    model.fit(dropped_X_train, y_mem_train)\n",
    "\n",
    "    predicted = model.predict(dropped_X_test)\n",
    "    predict_accuracy = np.mean(predicted == y_mem_heldout)\n",
    "    \n",
    "    if(predict_accuracy < final_rf_no_text_mem_acc):\n",
    "        print(no_text_mem_col)\n",
    "        print(predict_accuracy)\n",
    "        print(\"..........................................\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory, Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-Nearest-Neighbors Prediction Accuracy:\n",
      "0.569444444444\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         7\n",
      "         At Risk       0.71      0.77      0.74        53\n",
      "          Normal       0.00      0.00      0.00        12\n",
      "\n",
      "     avg / total       0.52      0.57      0.54        72\n",
      "\n",
      "Support Vector Machines Prediction Accuracy:\n",
      "0.736111111111\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         7\n",
      "         At Risk       0.74      1.00      0.85        53\n",
      "          Normal       0.00      0.00      0.00        12\n",
      "\n",
      "     avg / total       0.54      0.74      0.62        72\n",
      "\n",
      "Naive Bayes Prediction Accuracy:\n",
      "0.722222222222\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         7\n",
      "         At Risk       0.73      0.98      0.84        53\n",
      "          Normal       0.00      0.00      0.00        12\n",
      "\n",
      "     avg / total       0.54      0.72      0.62        72\n",
      "\n",
      "Random Forest Prediction Accuracy:\n",
      "0.736111111111\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         7\n",
      "         At Risk       0.74      1.00      0.85        53\n",
      "          Normal       0.00      0.00      0.00        12\n",
      "\n",
      "     avg / total       0.54      0.74      0.62        72\n",
      "\n",
      "Decision Tree Prediction Accuracy:\n",
      "0.555555555556\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.24      0.57      0.33         7\n",
      "         At Risk       0.78      0.66      0.71        53\n",
      "          Normal       0.10      0.08      0.09        12\n",
      "\n",
      "     avg / total       0.61      0.56      0.57        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_mem_train = memory_response_df.loc[train_mem_idx]\n",
    "\n",
    "text_mem_test = memory_response_df.loc[held_out_test_mem_idx]\n",
    "\n",
    "final_nb_text_mem_acc, final_svm_text_mem_acc, final_rf_text_mem_acc, final_dec_tree_text_mem_acc, final_knn_text_mem_acc = prediction_accuracies( text_mem_train, text_mem_test, y_mem_train, y_mem_heldout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mem_text_precision = (0, 0, 0, 13, 10)\n",
    "mem_text_recall = (0, 0, 0, 22, 11)\n",
    "mem_text_f1 = (0, 0, 0, 17, 11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for text_mem_col in text_mem_train.columns:\n",
    "    dropped_X_train = text_mem_train.drop(text_mem_col, axis=1)\n",
    "    dropped_X_test = text_mem_test.drop(text_mem_col, axis=1)\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=2,\n",
    "                                     random_state=0)\n",
    "    model.fit(dropped_X_train, y_mem_train)\n",
    "\n",
    "    predicted = model.predict(dropped_X_test)\n",
    "    predict_accuracy = np.mean(predicted == y_mem_heldout)\n",
    "    \n",
    "    if(predict_accuracy < final_rf_text_mem_acc):\n",
    "        print(text_mem_col)\n",
    "        print(predict_accuracy)\n",
    "        print(\"..........................................\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory, Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-Nearest-Neighbors Prediction Accuracy:\n",
      "0.652777777778\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         7\n",
      "         At Risk       0.76      0.83      0.79        53\n",
      "          Normal       0.43      0.25      0.32        12\n",
      "\n",
      "     avg / total       0.63      0.65      0.64        72\n",
      "\n",
      "Support Vector Machines Prediction Accuracy:\n",
      "0.736111111111\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         7\n",
      "         At Risk       0.74      1.00      0.85        53\n",
      "          Normal       0.00      0.00      0.00        12\n",
      "\n",
      "     avg / total       0.54      0.74      0.62        72\n",
      "\n",
      "Naive Bayes Prediction Accuracy:\n",
      "0.625\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.12      0.14      0.13         7\n",
      "         At Risk       0.90      0.66      0.76        53\n",
      "          Normal       0.36      0.75      0.49        12\n",
      "\n",
      "     avg / total       0.73      0.62      0.65        72\n",
      "\n",
      "Random Forest Prediction Accuracy:\n",
      "0.736111111111\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00         7\n",
      "         At Risk       0.75      1.00      0.85        53\n",
      "          Normal       0.00      0.00      0.00        12\n",
      "\n",
      "     avg / total       0.55      0.74      0.63        72\n",
      "\n",
      "Decision Tree Prediction Accuracy:\n",
      "0.736111111111\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.17      0.14      0.15         7\n",
      "         At Risk       0.87      0.87      0.87        53\n",
      "          Normal       0.46      0.50      0.48        12\n",
      "\n",
      "     avg / total       0.73      0.74      0.73        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_mem = mem_responses_no_text.join(memory_response_df)\n",
    "\n",
    "combined_mem_train = combined_mem.loc[train_mem_idx]\n",
    "combined_mem_test = combined_mem.loc[held_out_test_mem_idx]\n",
    "\n",
    "final_nb_all_mem_acc, final_svm_all_mem_acc, final_rf_all_mem_acc, final_dec_all_text_mem_acc, final_knn_all_mem_acc = prediction_accuracies( combined_mem_train, combined_mem_test, y_mem_train, y_mem_heldout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mem_combined_precision = (18, 0, 0, 17, 0)\n",
    "mem_combined_recall = (22, 0, 0, 24, 0)\n",
    "mem_combined_f1 = (20, 0, 0, 13, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns overlap but no suffix specified: Index([u'Gender'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-4d31a8430887>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem_resp_col\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_mem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfeature_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_mem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmem_resp_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mconcatenated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmem_responses_no_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_mem_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/travisallen/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   4553\u001b[0m         \u001b[0;31m# For SparseDataFrame's benefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4554\u001b[0m         return self._join_compat(other, on=on, how=how, lsuffix=lsuffix,\n\u001b[0;32m-> 4555\u001b[0;31m                                  rsuffix=rsuffix, sort=sort)\n\u001b[0m\u001b[1;32m   4556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4557\u001b[0m     def _join_compat(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[0;32m/Users/travisallen/anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   4567\u001b[0m             return merge(self, other, left_on=on, how=how,\n\u001b[1;32m   4568\u001b[0m                          \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4569\u001b[0;31m                          suffixes=(lsuffix, rsuffix), sort=sort)\n\u001b[0m\u001b[1;32m   4570\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4571\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/travisallen/anaconda/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[1;32m     60\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                          copy=copy, indicator=indicator)\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mmerge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_merge_doc\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m'\\nleft : DataFrame'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/travisallen/anaconda/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         llabels, rlabels = items_overlap_with_suffix(ldata.items, lsuf,\n\u001b[0;32m--> 556\u001b[0;31m                                                      rdata.items, rsuf)\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mlindexers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mleft_indexer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/travisallen/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mitems_overlap_with_suffix\u001b[0;34m(left, lsuffix, right, rsuffix)\u001b[0m\n\u001b[1;32m   4697\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlsuffix\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4698\u001b[0m             raise ValueError('columns overlap but no suffix specified: %s' %\n\u001b[0;32m-> 4699\u001b[0;31m                              to_rename)\n\u001b[0m\u001b[1;32m   4700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4701\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mlrenamer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: columns overlap but no suffix specified: Index([u'Gender'], dtype='object')"
     ]
    }
   ],
   "source": [
    "# for idx, mem_resp_col in enumerate(combined_mem.columns):\n",
    "#     feature_column = combined_mem[mem_resp_col]\n",
    "#     concatenated = mem_responses_no_text.join(feature_column)\n",
    "\n",
    "#     X_train = concatenated.loc[train_mem_idx]\n",
    "#     X_test = concatenated.loc[held_out_test_mem_idx]\n",
    "   \n",
    "#     model = tree.DecisionTreeClassifier()\n",
    "#     model.fit(X_train, y_mem_train)\n",
    "\n",
    "#     predicted = model.predict(X_test)\n",
    "#     predict_accuracy = np.mean(predicted == y_mem_heldout)\n",
    "    \n",
    "#     if (predict_accuracy > final_rf_all_mem_acc):\n",
    "#         print(\"Feature Tested: \" + mem_resp_col)\n",
    "#         print(predict_accuracy)\n",
    "#         print(\"................................\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tech, No Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-Nearest-Neighbors Prediction Accuracy:\n",
      "0.559523809524\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.11      0.08      0.10        12\n",
      "         At Risk       0.66      0.87      0.75        53\n",
      "          Normal       0.00      0.00      0.00        19\n",
      "\n",
      "     avg / total       0.43      0.56      0.49        84\n",
      "\n",
      "Support Vector Machines Prediction Accuracy:\n",
      "0.22619047619\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00        12\n",
      "         At Risk       0.00      0.00      0.00        53\n",
      "          Normal       0.23      1.00      0.37        19\n",
      "\n",
      "     avg / total       0.05      0.23      0.08        84\n",
      "\n",
      "Naive Bayes Prediction Accuracy:\n",
      "0.571428571429\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.28      0.42      0.33        12\n",
      "         At Risk       0.78      0.66      0.71        53\n",
      "          Normal       0.38      0.42      0.40        19\n",
      "\n",
      "     avg / total       0.62      0.57      0.59        84\n",
      "\n",
      "Random Forest Prediction Accuracy:\n",
      "0.654761904762\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00        12\n",
      "         At Risk       0.65      0.96      0.78        53\n",
      "          Normal       0.67      0.21      0.32        19\n",
      "\n",
      "     avg / total       0.56      0.65      0.56        84\n",
      "\n",
      "Decision Tree Prediction Accuracy:\n",
      "0.714285714286\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.33      0.25      0.29        12\n",
      "         At Risk       0.88      0.85      0.87        53\n",
      "          Normal       0.50      0.63      0.56        19\n",
      "\n",
      "     avg / total       0.72      0.71      0.71        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "no_text_tech_train = tech_responses_no_text.loc[train_tech_idx]\n",
    "\n",
    "no_text_tech_test = tech_responses_no_text.loc[held_out_test_tech_idx]\n",
    "\n",
    "final_nb_no_text_tech_acc, final_svm_no_text_tech_acc, final_rf_no_text_tech_acc, final_dec_tree_no_text_tech_acc, final_knn_no_text_tech_acc = prediction_accuracies( no_text_tech_train, no_text_tech_test, y_tech_train, y_tech_heldout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tech_no_text_precision = (18, 0, 0, 60, 20)\n",
    "tech_no_text_recall = (22, 0, 0, 33, 11)\n",
    "tech_no_text_f1 = (20, 4, 0, 0, 43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for no_text_tech_col in no_text_tech_train.columns:\n",
    "    dropped_X_train = no_text_tech_train.drop(no_text_tech_col, axis=1)\n",
    "    dropped_X_test = no_text_tech_test.drop(no_text_tech_col, axis=1)\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=2,\n",
    "                                     random_state=0)\n",
    "    model.fit(dropped_X_train, y_tech_train)\n",
    "\n",
    "    predicted = model.predict(dropped_X_test)\n",
    "    predict_accuracy = np.mean(predicted == y_tech_heldout)\n",
    "    \n",
    "    if(predict_accuracy < final_rf_no_text_tech_acc):\n",
    "        print(no_text_tech_col)\n",
    "        print(predict_accuracy)\n",
    "        print(\"..........................................\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tech, Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-Nearest-Neighbors Prediction Accuracy:\n",
      "0.595238095238\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.29      0.17      0.21        12\n",
      "         At Risk       0.64      0.87      0.74        53\n",
      "          Normal       0.40      0.11      0.17        19\n",
      "\n",
      "     avg / total       0.53      0.60      0.53        84\n",
      "\n",
      "Support Vector Machines Prediction Accuracy:\n",
      "0.214285714286\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.14      0.83      0.24        12\n",
      "         At Risk       0.67      0.15      0.25        53\n",
      "          Normal       0.00      0.00      0.00        19\n",
      "\n",
      "     avg / total       0.44      0.21      0.19        84\n",
      "\n",
      "Naive Bayes Prediction Accuracy:\n",
      "0.642857142857\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00        12\n",
      "         At Risk       0.64      1.00      0.78        53\n",
      "          Normal       1.00      0.05      0.10        19\n",
      "\n",
      "     avg / total       0.63      0.64      0.51        84\n",
      "\n",
      "Random Forest Prediction Accuracy:\n",
      "0.630952380952\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00        12\n",
      "         At Risk       0.63      1.00      0.77        53\n",
      "          Normal       0.00      0.00      0.00        19\n",
      "\n",
      "     avg / total       0.40      0.63      0.49        84\n",
      "\n",
      "Decision Tree Prediction Accuracy:\n",
      "0.511904761905\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.18      0.17      0.17        12\n",
      "         At Risk       0.66      0.72      0.68        53\n",
      "          Normal       0.20      0.16      0.18        19\n",
      "\n",
      "     avg / total       0.48      0.51      0.50        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_tech_train = tech_response_df.loc[train_tech_idx]\n",
    "\n",
    "text_tech_test = tech_response_df.loc[held_out_test_tech_idx]\n",
    "\n",
    "final_nb_text_tech_acc, final_svm_text_tech_acc, final_rf_text_tech_acc, final_dec_tree_text_tech_acc, final_knn_text_tech_acc = prediction_accuracies(text_tech_train, text_tech_test, y_tech_train, y_tech_heldout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tech_text_precision = (0, 0, 0, 8, 20)\n",
    "tech_text_recall = (0, 0, 0, 11, 11)\n",
    "tech_text_f1 = (0,0,0,10,14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tech, Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-Nearest-Neighbors Prediction Accuracy:\n",
      "0.595238095238\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.22      0.17      0.19        12\n",
      "         At Risk       0.67      0.89      0.76        53\n",
      "          Normal       0.20      0.05      0.08        19\n",
      "\n",
      "     avg / total       0.50      0.60      0.53        84\n",
      "\n",
      "Support Vector Machines Prediction Accuracy:\n",
      "0.238095238095\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00        12\n",
      "         At Risk       0.55      0.11      0.19        53\n",
      "          Normal       0.19      0.74      0.30        19\n",
      "\n",
      "     avg / total       0.39      0.24      0.19        84\n",
      "\n",
      "Naive Bayes Prediction Accuracy:\n",
      "0.547619047619\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.14      0.17      0.15        12\n",
      "         At Risk       0.69      0.68      0.69        53\n",
      "          Normal       0.44      0.42      0.43        19\n",
      "\n",
      "     avg / total       0.56      0.55      0.55        84\n",
      "\n",
      "Random Forest Prediction Accuracy:\n",
      "0.619047619048\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.00      0.00      0.00        12\n",
      "         At Risk       0.64      0.94      0.76        53\n",
      "          Normal       0.33      0.11      0.16        19\n",
      "\n",
      "     avg / total       0.48      0.62      0.52        84\n",
      "\n",
      "Decision Tree Prediction Accuracy:\n",
      "0.630952380952\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Significant Risk       0.27      0.33      0.30        12\n",
      "         At Risk       0.81      0.81      0.81        53\n",
      "          Normal       0.38      0.32      0.34        19\n",
      "\n",
      "     avg / total       0.63      0.63      0.63        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combined_tech = tech_responses_no_text.join(tech_response_df)\n",
    "\n",
    "combined_tech_train = combined_tech.loc[train_tech_idx]\n",
    "combined_tech_test = combined_tech.loc[held_out_test_tech_idx]\n",
    "\n",
    "final_nb_all_tech_acc, final_svm_all_tech_acc, final_rf_all_tech_acc, final_dec_all_text_tech_acc, final_knn_all_tech_acc = prediction_accuracies( combined_tech_train, combined_tech_test, y_tech_train, y_tech_heldout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tech_combined_precision = (25, 29, 0, 64, 20)\n",
    "tech_combined_recall = (22, 22, 0, 44, 11)\n",
    "tech_combined_f1 = (24, 25, 0, 44, 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTS FIGURES SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "N = 3\n",
    "\n",
    "act_sig_risk = mem_THREE_class_cft[mem_THREE_class_cft == 0].shape[0] + tech_THREE_class_cft[tech_THREE_class_cft == 0].shape[0]\n",
    "act_at_risk = mem_THREE_class_cft[mem_THREE_class_cft == 1].shape[0] + tech_THREE_class_cft[tech_THREE_class_cft == 1].shape[0]\n",
    "act_normal = mem_THREE_class_cft[mem_THREE_class_cft == 2].shape[0] + tech_THREE_class_cft[tech_THREE_class_cft == 2].shape[0]\n",
    "\n",
    "total_cft = mem_THREE_class_cft.shape[0] + tech_THREE_class_cft.shape[0]\n",
    "\n",
    "objects = ('Significant Risk (<38)', 'At Risk (<43, >38)', 'Normal (>43)')\n",
    "\n",
    "mem_CFT = ((act_sig_risk/total_cft)*100, (act_at_risk/total_cft)*100, (act_normal/total_cft)*100)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "width = 0.35         # the width of the bars\n",
    "p1 = ax.bar(ind, mem_CFT, width, color='r')\n",
    "\n",
    "\n",
    "expected_CFT = (6.7, 9.2, 84.1)\n",
    "p2 = ax.bar(ind + width, expected_CFT, width,\n",
    "            color='y')\n",
    "\n",
    "ax.set_title('Expected CFT Score Distribution and Actual Distribution')\n",
    "ax.set_xticks(ind + width / 2)\n",
    "ax.set_xticklabels(('Significant Risk (<38)', 'At Risk (38-43)', 'Normal (>43)'))\n",
    "\n",
    "ax.legend((p1[0], p2[0]), ('CFT Distribution in Dataset', 'Expected CFT Distribution'))\n",
    "ax.autoscale_view()\n",
    "\n",
    "plt.ylabel('% of Total')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Num_Models = 5\n",
    "\n",
    "mem_no_text = (final_nb_no_text_mem_acc*100, final_svm_no_text_mem_acc*100, final_rf_no_text_mem_acc*100, final_dec_tree_no_text_mem_acc*100, final_knn_no_text_mem_acc*100)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ind = np.arange(Num_Models)    # the x locations for the groups\n",
    "width = 0.25         # the width of the bars\n",
    "p1 = ax.bar(ind, mem_no_text, width, color='b')\n",
    "\n",
    "mem_text = (final_nb_text_mem_acc*100, final_svm_text_mem_acc*100, final_rf_text_mem_acc*100, final_dec_tree_text_mem_acc*100, final_knn_text_mem_acc*100)\n",
    "p2 = ax.bar(ind + width, mem_text, width,\n",
    "            color='g')\n",
    "\n",
    "mem_combined = (final_nb_all_mem_acc*100, final_svm_all_mem_acc*100, final_rf_all_mem_acc*100, final_dec_all_text_mem_acc*100, final_knn_all_mem_acc*100)\n",
    "p3 = ax.bar(ind + width + width, mem_combined, width,\n",
    "            color='#00FFFF')\n",
    "\n",
    "ax.set_title('Model Accuracy on \"Memory Users\"')\n",
    "ax.set_xticks(ind + width / 2)\n",
    "ax.set_xticklabels(('NB', 'SVM', 'RF', 'DecTree', 'kNN'))\n",
    "\n",
    "ax.legend((p1[0], p2[0], p3[0]), ('Non-Text Data', 'Text Data', 'Combined'), prop={'size': 6})\n",
    "ax.autoscale_view()\n",
    "ax.set_ylim(0,100)\n",
    "plt.ylabel('Prediction Accuracy (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Num_Models = 5\n",
    "\n",
    "tech_no_text = (final_nb_no_text_tech_acc*100, final_svm_no_text_tech_acc*100, final_rf_no_text_tech_acc*100, final_dec_tree_no_text_tech_acc*100, final_knn_no_text_tech_acc*100)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ind = np.arange(Num_Models)    # the x locations for the groups\n",
    "width = 0.25         # the width of the bars\n",
    "p1 = ax.bar(ind, tech_no_text, width, color='b')\n",
    "\n",
    "tech_text = (final_nb_text_tech_acc*100, final_svm_text_tech_acc*100, final_rf_text_tech_acc*100, final_dec_tree_text_tech_acc*100, final_knn_text_tech_acc*100)\n",
    "p2 = ax.bar(ind + width, tech_text, width,\n",
    "            color='g')\n",
    "\n",
    "\n",
    "tech_combined = (final_nb_all_tech_acc*100, final_svm_all_tech_acc*100, final_rf_all_tech_acc*100, final_dec_all_text_tech_acc*100, final_knn_all_tech_acc*100)\n",
    "p3 = ax.bar(ind + width + width, tech_combined, width,\n",
    "            color='#00FFFF')\n",
    "\n",
    "ax.set_title('Model Accuracy on \"Opinion Users\"')\n",
    "ax.set_xticks(ind + width / 2)\n",
    "ax.set_xticklabels(('NB', 'SVM', 'RF', 'DecTree', 'kNN'))\n",
    "\n",
    "ax.legend((p1[0], p2[0], p3[0]), ('Non-Text Data', 'Text Data', 'Combined'), prop={'size': 6})\n",
    "ax.set_ylim(0,100)\n",
    "ax.autoscale_view()\n",
    "\n",
    "plt.ylabel('Prediction Accuracy (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_bar_chart(non_tuple, text_tuple, combined_tuple, metric_string, user_type):\n",
    "    Num_Models = 5\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ind = np.arange(Num_Models)    # the x locations for the groups\n",
    "    width = 0.25         # the width of the bars\n",
    "    p1 = ax.bar(ind, non_tuple, width, color='b')\n",
    "\n",
    "    p2 = ax.bar(ind + width, text_tuple, width,\n",
    "                color='g')\n",
    "\n",
    "    p3 = ax.bar(ind + width + width, combined_tuple, width,\n",
    "                color='#00FFFF')\n",
    "\n",
    "    ax.set_title('Model ' + metric_string + ' on \"' + user_type + ' Users\"')\n",
    "    ax.set_xticks(ind + width / 2)\n",
    "    ax.set_xticklabels(('NB', 'SVM', 'RF', 'DecTree', 'kNN'))\n",
    "\n",
    "    ax.legend((p1[0], p2[0], p3[0]), ('Non-Text Data', 'Text Data', 'Combined'), prop={'size': 6})\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.autoscale_view()\n",
    "\n",
    "    plt.ylabel('Prediction ' + metric_string +  '(%)')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_bar_chart(mem_no_text_precision, mem_text_precision, mem_combined_precision, \"Precision\", \"Memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_bar_chart(tech_no_text_precision, tech_text_precision, tech_combined_precision, \"Precision\", \"Opinion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_bar_chart(mem_no_text_recall, mem_text_recall, mem_combined_recall, \"Recall\", \"Memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_bar_chart(tech_no_text_recall, tech_text_recall, tech_combined_recall, \"Recall\", \"Opinion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_bar_chart(mem_no_text_f1, mem_text_f1, mem_combined_f1, \"F1\", \"Memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_bar_chart(tech_no_text_f1, tech_text_f1, tech_combined_f1, \"F1\", \"Opinion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
